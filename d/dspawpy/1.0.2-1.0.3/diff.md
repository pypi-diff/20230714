# Comparing `tmp/dspawpy-1.0.2-py3-none-any.whl.zip` & `tmp/dspawpy-1.0.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,20 +1,20 @@
-Zip file size: 74504 bytes, number of entries: 18
--rw-rw-rw-  2.0 fat       48 b- defN 23-Jul-07 09:45 dspawpy/__init__.py
--rw-rw-rw-  2.0 fat    32126 b- defN 23-Jul-07 09:41 dspawpy/plot.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-07 09:41 dspawpy/analysis/__init__.py
--rw-rw-rw-  2.0 fat    24227 b- defN 23-Jul-07 09:41 dspawpy/analysis/aimdtools.py
--rw-rw-rw-  2.0 fat    20177 b- defN 23-Jul-07 09:41 dspawpy/analysis/vacf.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-07 09:41 dspawpy/diffusion/__init__.py
--rw-rw-rw-  2.0 fat     3986 b- defN 23-Jul-07 09:41 dspawpy/diffusion/neb.py
--rw-rw-rw-  2.0 fat    56885 b- defN 23-Jul-07 09:41 dspawpy/diffusion/nebtools.py
--rw-rw-rw-  2.0 fat    11045 b- defN 23-Jul-07 09:41 dspawpy/diffusion/pathfinder.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-07 09:41 dspawpy/io/__init__.py
--rw-rw-rw-  2.0 fat    62556 b- defN 23-Jul-07 09:41 dspawpy/io/read.py
--rw-rw-rw-  2.0 fat    10546 b- defN 23-Jul-07 09:41 dspawpy/io/structure.py
--rw-rw-rw-  2.0 fat    27763 b- defN 23-Jul-07 09:41 dspawpy/io/utils.py
--rw-rw-rw-  2.0 fat    29654 b- defN 23-Jul-07 09:41 dspawpy/io/write.py
--rw-rw-rw-  2.0 fat     6022 b- defN 23-Jul-07 09:47 dspawpy-1.0.2.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Jul-07 09:47 dspawpy-1.0.2.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Jul-07 09:47 dspawpy-1.0.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     1422 b- defN 23-Jul-07 09:47 dspawpy-1.0.2.dist-info/RECORD
-18 files, 286557 bytes uncompressed, 72200 bytes compressed:  74.8%
+Zip file size: 77593 bytes, number of entries: 18
+-rw-rw-rw-  2.0 fat       48 b- defN 23-Jul-14 08:23 dspawpy/__init__.py
+-rw-rw-rw-  2.0 fat    28329 b- defN 23-Jul-14 05:05 dspawpy/plot.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-13 01:36 dspawpy/analysis/__init__.py
+-rw-rw-rw-  2.0 fat    26263 b- defN 23-Jul-14 01:53 dspawpy/analysis/aimdtools.py
+-rw-rw-rw-  2.0 fat    20177 b- defN 23-Jul-13 01:36 dspawpy/analysis/vacf.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-13 01:36 dspawpy/diffusion/__init__.py
+-rw-rw-rw-  2.0 fat     3887 b- defN 23-Jul-14 01:54 dspawpy/diffusion/neb.py
+-rw-rw-rw-  2.0 fat    58897 b- defN 23-Jul-14 07:07 dspawpy/diffusion/nebtools.py
+-rw-rw-rw-  2.0 fat    11045 b- defN 23-Jul-13 01:36 dspawpy/diffusion/pathfinder.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jul-13 01:36 dspawpy/io/__init__.py
+-rw-rw-rw-  2.0 fat    62357 b- defN 23-Jul-14 02:00 dspawpy/io/read.py
+-rw-rw-rw-  2.0 fat    11015 b- defN 23-Jul-13 01:36 dspawpy/io/structure.py
+-rw-rw-rw-  2.0 fat    32031 b- defN 23-Jul-14 01:50 dspawpy/io/utils.py
+-rw-rw-rw-  2.0 fat    27999 b- defN 23-Jul-14 03:08 dspawpy/io/write.py
+-rw-rw-rw-  2.0 fat     7008 b- defN 23-Jul-14 08:24 dspawpy-1.0.3.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Jul-14 08:24 dspawpy-1.0.3.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 23-Jul-14 08:24 dspawpy-1.0.3.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     1422 b- defN 23-Jul-14 08:24 dspawpy-1.0.3.dist-info/RECORD
+18 files, 290578 bytes uncompressed, 75289 bytes compressed:  74.1%
```

## zipnote {}

```diff
@@ -36,20 +36,20 @@
 
 Filename: dspawpy/io/utils.py
 Comment: 
 
 Filename: dspawpy/io/write.py
 Comment: 
 
-Filename: dspawpy-1.0.2.dist-info/METADATA
+Filename: dspawpy-1.0.3.dist-info/METADATA
 Comment: 
 
-Filename: dspawpy-1.0.2.dist-info/WHEEL
+Filename: dspawpy-1.0.3.dist-info/WHEEL
 Comment: 
 
-Filename: dspawpy-1.0.2.dist-info/top_level.txt
+Filename: dspawpy-1.0.3.dist-info/top_level.txt
 Comment: 
 
-Filename: dspawpy-1.0.2.dist-info/RECORD
+Filename: dspawpy-1.0.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## dspawpy/__init__.py

```diff
@@ -1,2 +1,2 @@
 # -*- coding: utf-8 -*-
-__version__ = "1.0.2"
+__version__ = "1.0.3"
```

## dspawpy/plot.py

```diff
@@ -1,17 +1,19 @@
 # -*- coding: utf-8 -*-
 import json
 import os
+import warnings
 
 import h5py
 import matplotlib.pyplot as plt
 import numpy as np
 import pandas as pd
 import statsmodels.api as sm
 from dspawpy.io.read import load_h5
+from dspawpy.io.utils import get_absfile
 from scipy.interpolate import interp1d
 
 
 def average_along_axis(
     datafile="potential.h5",
     task: str = "potential",
     axis=2,
@@ -34,15 +36,15 @@
     smooth : bool
         是否平滑, 默认False
     smooth_frac : float
         平滑系数, 默认0.8
     raw : bool
         是否返回绘图数据到csv文件
     subtype : str
-        用于指定task数据子类，暂时只支持 TotalLocalPotential，默认None，代表绘制 TotalElectrostaticPotential
+        用于指定task数据子类，默认None，代表绘制 Potential/TotalElectrostaticPotential
     **kwargs : dict
         其他参数, 传递给 matplotlib.pyplot.plot
 
     Returns
     -------
     axes: matplotlib.axes._subplots.AxesSubplot
         可传递给其他函数进行进一步处理
@@ -50,61 +52,46 @@
     Examples
     --------
     >>> from dspawpy.plot import average_along_axis
 
     读取 potential.h5 文件中的数据，绘图并保存原始绘图数据到csv文件
 
     >>> average_along_axis(datafile='/data/home/hzw1002/dspawpy_repo/test/2.7/potential.h5', task='potential', axis=2, smooth=True, smooth_frac=0.8, raw=True)
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.7/potential.h5...
     <module 'matplotlib.pyplot' from '/data/home/hzw1002/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py'>
     """
     assert task in [
         "rho",
         "potential",
         "elf",
         "pcharge",
         "rhoBound",
-    ], "仅支持 rho, potential, elf, pcharge, rhoBound 任务类型"
-    if subtype is not None:
-        assert (
-            task == "potential" and subtype == "TotalLocalPotential"
-        ), '目前仅支持"potential"的"TotalLocalPotential"子类'
+    ], "Only support: rho, potential, elf, pcharge, rhoBound"
 
     # only for compatibility
     if isinstance(datafile, list) or isinstance(datafile, np.ndarray):
         ys = datafile  # expect np.ndarray or list
+    else:
+        absfile = get_absfile(datafile, task)
 
-    # search datafile in the given directory
-    elif os.path.isdir(datafile):
-        directory = datafile  # specified datafile is actually a directory
-        print("您指定了一个文件夹，正在查找相关h5或json文件...")
-        if os.path.exists(os.path.join(directory, f"{task}.h5")):
-            datafile = os.path.join(directory, f"{task}.h5")
-            print("Readingf {task}.h5...")
-        elif os.path.exists(os.path.join(directory, f"{task}.json")):
-            datafile = os.path.join(directory, f"{task}.json")
-            print("Readingf {task}.json...")
-        else:
-            raise FileNotFoundError(f"未找到{task}.h5/{task}.json文件！")
-
-    # parse the real datafile
-    elif datafile.endswith(".h5"):
-        hfile = datafile
+    print(f"Reading {absfile}...")
+    if absfile.endswith(".h5"):
+        hfile = absfile
         hdict = load_h5(hfile)
         grid = hdict["/AtomInfo/Grid"]
 
         if task == "rho":
             if subtype is None:
                 _key = "/Rho/TotalCharge"
             else:
                 _key = f"/Rho/{subtype}"
         elif task == "potential":
             if subtype is None:
-                _key = "/Potential/TotalElectrostaticPotential"
-            elif subtype == "TotalLocalPotential":
-                _key = f"/Potential/{subtype}"
+                subtype = "TotalElectrostaticPotential"
+            _key = f"/Potential/{subtype}"
         elif task == "elf":
             if subtype is None:
                 _key = "/ELF/TotalELF"
             else:
                 _key = f"/ELF/{subtype}"
         elif task == "pcharge":
             if subtype is None:
@@ -114,41 +101,38 @@
         elif task == "rhoBound":
             if subtype is None:
                 _key = "/Rho"
             else:
                 _key = subtype
 
         if _key not in hdict:
-            raise KeyError(f"未找到{_key}键！")
+            raise KeyError(f"No {_key} key")
 
         # DS-PAW 数据写入h5 列优先
         # h5py 从h5读取数据 默认行优先
         # np.array(data_list) 默认行优先
         # 所以这里先以 行优先 把 “h5 行优先 读进来的数据” 转成一维， 再以 列优先 转成 grid 对应的维度
         tmp_pot = np.asarray(hdict[_key]).reshape([-1, 1], order="C")
         ys = tmp_pot.reshape(grid, order="F")
 
-    elif datafile.endswith(".json"):
-        jfile = datafile
+    elif absfile.endswith(".json"):
+        jfile = absfile
         with open(jfile, "r") as f:
             jdict = json.load(f)
         grid = jdict["AtomInfo"]["Grid"]
 
         if task == "rho":
             if subtype is None:
                 ys = np.asarray(jdict["Rho"]["TotalCharge"]).reshape(grid, order="F")
             else:
                 ys = np.asarray(jdict["Rho"][subtype]).reshape(grid, order="F")
         elif task == "potential":
             if subtype is None:
-                ys = np.asarray(
-                    jdict["Potential"]["TotalElectrostaticPotential"]
-                ).reshape(grid, order="F")
-            else:
-                ys = np.asarray(jdict["Potential"][subtype]).reshape(grid, order="F")
+                subtype = "TotalElectrostaticPotential"
+            ys = np.asarray(jdict["Potential"][subtype]).reshape(grid, order="F")
         elif task == "elf":
             if subtype is None:
                 ys = np.asarray(jdict["ELF"]["TotalELF"]).reshape(grid, order="F")
             else:
                 ys = np.asarray(jdict["ELF"][subtype]).reshape(grid, order="F")
         elif task == "pcharge":
             if subtype is None:
@@ -160,15 +144,15 @@
         else:
             if subtype is None:
                 ys = np.asarray(jdict["Rho"]).reshape(grid, order="F")
             else:
                 ys = np.asarray(jdict[subtype]).reshape(grid, order="F")
 
     else:
-        raise TypeError("仅支持读取h5或json文件或直接传入数组！")
+        raise TypeError("Only suport h5/json file")
 
     all_axis = [0, 1, 2]
     all_axis.remove(axis)
     y = np.mean(ys, tuple(all_axis))
     x = np.arange(len(y))
 
     if raw:
@@ -224,40 +208,40 @@
     Examples
     ----------
     >>> from dspawpy.plot import plot_aimd
 
     读取 aimd.h5 文件内容，画出动能、总能、温度、体积的收敛过程图，并保存相应数据到 rawaimd_*.csv 中
 
     >>> plot_aimd(datafile='/data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5', flags_str='1245', raw=False, show=False, figname=None)
-    正在处理子图1
-     reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
-    正在处理子图2
-     reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
-    正在处理子图4
-     reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
-    正在处理子图5
-     reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
+    For subfigure 1
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
+    For subfigure 2
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
+    For subfigure 4
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
+    For subfigure 5
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
     """
     # 处理用户读取，按顺序去重
     temp = set()
     flags = [x for x in flags_str if x not in temp and (temp.add(x) or True)]
     if " " in flags:  # remove space
         flags.remove(" ")
 
     for flag in flags:
-        assert flag in ["1", "2", "3", "4", "5"], "读取错误！"
+        assert flag in ["1", "2", "3", "4", "5"], "flag must be in '12345'"
 
     # 开始画组合图
     N_figs = len(flags)
     fig, axes = plt.subplots(N_figs, 1, sharex=True, figsize=(6, 2 * N_figs))
     if N_figs == 1:  # 'AxesSubplot' object is not subscriptable
         axes = [axes]  # 避免上述类型错误
     fig.suptitle("DSPAW AIMD")
     for i, flag in enumerate(flags):
-        print("正在处理子图" + flag)
+        print("For subfigure " + flag)
         # 读取数据
         xs, ys = _read_aimd_converge_data(datafile, flag)
         if raw:
             pd.DataFrame({"x": xs, "y": ys}).to_csv(f"rawaimd_{flag}.csv", index=False)
 
         axes[i].plot(xs, ys)  # 绘制坐标点
         # 子图的y轴标签
@@ -271,34 +255,35 @@
             axes[i].set_ylabel("Temperature (K)")
         else:
             axes[i].set_ylabel("Volume (Angstrom^3)")
 
     plt.tight_layout()
     # save and show
     if figname:
-        os.makedirs(os.path.dirname(os.path.abspath(figname)), exist_ok=True)
-        plt.savefig(figname, dpi=300)
-        print(f"--> 图片已保存为 {os.path.abspath(figname)}")
+        absfig = os.path.abspath(figname)
+        os.makedirs(os.path.dirname(absfig), exist_ok=True)
+        plt.savefig(absfig, dpi=300)
+        print(f"==> {absfig}")
     if show:
         plt.show()
 
 
 def plot_bandunfolding(
-    datafile: str = "band.h5", ef=0.0, de=0.05, dele=0.06, raw=False
+    datafile: str = "band.h5", ef=None, de=0.05, dele=0.06, raw=False
 ):
     r"""能带反折叠任务完成后，读取 h5 或 json 文件数据绘图
 
     band.h5/band.json -> bandunfolding.png
 
     Parameters
     ----------
     datafile : str
         h5或json文件路径或包含任意这些文件的文件夹，默认 'band.h5'
     ef : float
-        费米能级，默认置于 y = 0 处
+        费米能级，默认从文件中读取 /UnfoldingBandInfo/Efermi 记录的数据
     de : float
         能带宽度，默认0.05
     dele : float
         能带间隔，默认0.06
     raw : bool
         是否输出绘图数据到rawbandunfolding.csv
 
@@ -313,50 +298,35 @@
     绘图并保存绘图数据到rawbandunfolding.csv
 
     >>> from dspawpy.plot import plot_bandunfolding
     >>> plot_bandunfolding("/data/home/hzw1002/dspawpy_repo/test/2.22/band.h5", raw=True)
     Reading /data/home/hzw1002/dspawpy_repo/test/2.22/band.h5...
     <module 'matplotlib.pyplot' from '/data/home/hzw1002/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py'>
     """
-    # search datafile in the given directory
-    if os.path.isdir(datafile):
-        directory = datafile  # specified datafile is actually a directory
-        print("您指定了一个文件夹，正在查找相关h5或json文件...")
-        if os.path.exists(os.path.join(directory, "band.h5")):
-            datafile = os.path.join(directory, "band.h5")
-            print("Reading band.h5...")
-        elif os.path.exists(os.path.join(directory, "band.json")):
-            datafile = os.path.join(directory, "band.json")
-            print("Reading band.json...")
-        else:
-            raise FileNotFoundError("未找到band.h5/band.json文件！")
-
-    if datafile.endswith(".h5"):
-        # band = load_h5(datafile)
-        import h5py
-
-        print(f"Reading {os.path.abspath(datafile)}...")
-        f = h5py.File(datafile, "r")
+    absfile = get_absfile(datafile, task="band")
+    print(f"Reading {absfile}...")
+    if absfile.endswith(".h5"):
+        f = h5py.File(absfile, "r")
+        if ef is None:
+            ef = np.array(f["/UnfoldingBandInfo/EFermi"])[0]
         number_of_band = np.array(f["/BandInfo/NumberOfBand"])[0]
-        # number_of_band = band["/BandInfo/NumberOfBand"][0]
         number_of_kpoints = np.array(f["/BandInfo/NumberOfKpoints"])[0]
-        # number_of_kpoints = band["/BandInfo/NumberOfKpoints"][0]
         data = np.array(f["/UnfoldingBandInfo/Spin1/UnfoldingBand"])
-        # data = band["/UnfoldingBandInfo/Spin1/UnfoldingBand"]
         weight = np.array(f["/UnfoldingBandInfo/Spin1/Weight"])
-        # weight = band["/UnfoldingBandInfo/Spin1/Weight"]
-    elif datafile.endswith(".json"):
-        with open(datafile, "r") as f:
+    elif absfile.endswith(".json"):
+        with open(absfile, "r") as f:
             band = json.load(f)
+        if ef is None:
+            ef = band['UnfoldingBandInfo']['EFermi']
         number_of_band = band["BandInfo"]["NumberOfBand"]
         number_of_kpoints = band["BandInfo"]["NumberOfKpoints"]
         data = band["UnfoldingBandInfo"]["Spin1"]["UnfoldingBand"]
         weight = band["UnfoldingBandInfo"]["Spin1"]["Weight"]
     else:
-        raise TypeError("仅支持读取h5或json文件！")
+        raise TypeError("Only support h5/json file")
 
     celtot = np.array(data).reshape((number_of_kpoints, number_of_band)).T
     proj_wt = np.array(weight).reshape((number_of_kpoints, number_of_band)).T
     X2, Y2, Z2, emin = getEwtData(
         number_of_kpoints, number_of_band, celtot, proj_wt, ef, de, dele
     )
 
@@ -405,41 +375,31 @@
     Examples
     --------
 
     绘图并保存绘图数据到rawoptical.csv
 
     >>> from dspawpy.plot import plot_optical
     >>> plot_optical("/data/home/hzw1002/dspawpy_repo/test/2.12/scf.h5", "AbsorptionCoefficient", 0, raw=True)
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.12/scf.h5...
     >>> plot_optical("/data/home/hzw1002/dspawpy_repo/test/2.12/optical.json", "AbsorptionCoefficient", 0, raw=True)
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.12/optical.json...
     """
-    # search datafile in the given directory
-    if os.path.isdir(datafile):
-        directory = datafile  # specified datafile is actually a directory
-        print("您指定了一个文件夹，正在查找相关h5或json文件...")
-        if os.path.exists(os.path.join(directory, "optical.h5")):
-            datafile = os.path.join(directory, "optical.h5")
-            print("Reading optical.h5...")
-        elif os.path.exists(os.path.join(directory, "optical.json")):
-            datafile = os.path.join(directory, "optical.json")
-            print("Reading optical.json...")
-        else:
-            raise FileNotFoundError("未找到optical.h5/optical.json文件！")
-
-    # parse the real datafile
-    if datafile.endswith("h5"):
-        data_all = load_h5(datafile)
+    absfile = get_absfile(datafile, task="optical")
+    print(f"Reading {absfile}...")
+    if absfile.endswith("h5"):
+        data_all = load_h5(absfile)
         energy = data_all["/OpticalInfo/EnergyAxe"]
         data = data_all["/OpticalInfo/" + key]
-    elif datafile.endswith("json"):
-        with open(datafile, "r") as fin:
+    elif absfile.endswith("json"):
+        with open(absfile, "r") as fin:
             data_all = json.load(fin)
         energy = data_all["OpticalInfo"]["EnergyAxe"]
         data = data_all["OpticalInfo"][key]
     else:
-        raise TypeError("仅支持读取h5或json文件！")
+        raise TypeError("Only support h5/json file")
 
     data = np.asarray(data).reshape(len(energy), 6)[:, index]
     inter_f = interp1d(energy, data, kind="cubic")
     energy_spline = np.linspace(energy[0], energy[-1], 2001)
     data_spline = inter_f(energy_spline)
 
     if raw:
@@ -482,52 +442,40 @@
         图片路径，默认 'phonon.png'
 
     Examples
     --------
     >>> from dspawpy.plot import plot_phonon_thermal
     >>> plot_phonon_thermal('/data/home/hzw1002/dspawpy_repo/test/2.26/phonon.h5', figname='/data/home/hzw1002/dspawpy_repo/test/out/phonon_thermal.png', show=False)
     Reading /data/home/hzw1002/dspawpy_repo/test/2.26/phonon.h5...
-    --> 图片已保存为 /data/home/hzw1002/dspawpy_repo/test/out/phonon_thermal.png
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/phonon_thermal.png
     """
-    # search datafile in the given directory
-    if os.path.isdir(datafile):
-        directory = datafile  # specified datafile is actually a directory
-        print("您指定了一个文件夹，正在查找相关h5或json文件...")
-        if os.path.exists(os.path.join(directory, "phonon.h5")):
-            datafile = os.path.join(directory, "phonon.h5")
-            print("Reading phonon.h5...")
-        elif os.path.exists(os.path.join(directory, "phonon.json")):
-            datafile = os.path.join(directory, "phonon.json")
-            print("Reading phonon.json...")
-        else:
-            raise FileNotFoundError("未找到phonon.h5/phonon.json文件！")
+    absfile = get_absfile(datafile, task="phonon")
+    print(f"Reading {absfile}...")
 
-    if datafile.endswith(".h5"):
-        hfile = datafile
+    if absfile.endswith(".h5"):
+        hfile = absfile
         ph = h5py.File(hfile, "r")
-        print(f"Reading {hfile}...")
         if "/ThermalInfo/Temperatures" not in ph:
             raise KeyError(
-                "❓ No thermal info in datafile, you probably gave a wrong phonon.h5 file"
+                f"No thermal info in {absfile}, you probably gave a wrong phonon.h5 file"
             )
         temp = np.array(ph["/ThermalInfo/Temperatures"])
         entropy = np.array(ph["/ThermalInfo/Entropy"])
         heat_capacity = np.array(ph["/ThermalInfo/HeatCapacity"])
         helmholts_free_energy = np.array(ph["/ThermalInfo/HelmholtzFreeEnergy"])
-    elif datafile.endswith(".json"):
-        jfile = datafile
+    elif absfile.endswith(".json"):
+        jfile = absfile
         with open(jfile, "r") as f:
             data = json.load(f)
-        print(f"Reading {jfile}...")
         temp = np.array(data["ThermalInfo"]["Temperatures"])
         entropy = np.array(data["ThermalInfo"]["Entropy"])
         heat_capacity = np.array(data["ThermalInfo"]["HeatCapacity"])
         helmholts_free_energy = np.array(data["ThermalInfo"]["HelmholtzFreeEnergy"])
     else:
-        raise TypeError("仅支持读取h5或json文件！")
+        raise TypeError("Only support h5/json file")
 
     if raw:
         pd.DataFrame(
             {
                 "temp": temp,
                 "entropy": entropy,
                 "heat_capacity": heat_capacity,
@@ -546,17 +494,18 @@
     plt.grid(alpha=0.2)
     plt.legend()
     plt.title("Thermal")
 
     plt.tight_layout()
     # save and show
     if figname:
-        os.makedirs(os.path.dirname(os.path.abspath(figname)), exist_ok=True)
-        plt.savefig(figname, dpi=300)
-        print(f"--> 图片已保存为 {os.path.abspath(figname)}")
+        absfig = os.path.abspath(figname)
+        os.makedirs(os.path.dirname(absfig), exist_ok=True)
+        plt.savefig(absfig, dpi=300)
+        print(f"==> {absfig}")
     if show:
         plt.show()
 
 
 def plot_polarization_figure(
     directory: str,
     repetition: int = 2,
@@ -588,19 +537,19 @@
     axes: matplotlib.axes._subplots.AxesSubplot
         可传递给其他函数进行进一步处理
 
     Examples
     --------
     >>> from dspawpy.plot import plot_polarization_figure
     >>> plot_polarization_figure(directory='/data/home/hzw1002/dspawpy_repo/test/2.20', figname='/data/home/hzw1002/dspawpy_repo/test/out/pol.png', show=False)
-    --> 图片已保存为 /data/home/hzw1002/dspawpy_repo/test/out/pol.png
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/pol.png
     array([<Axes: title={'center': 'Px'}>, <Axes: title={'center': 'Py'}>,
            <Axes: title={'center': 'Pz'}>], dtype=object)
     """
-    assert repetition >= 0, "重复次数必须是自然数"
+    assert repetition >= 0, "The number of repetitions must be a natural number"
     subfolders, quantum, totals = _get_subfolders_quantum_totals(directory)
     number_sfs = [int(sf) for sf in subfolders]
     fig, axes = plt.subplots(1, 3, sharey=True)
     xyz = ["x", "y", "z"]
     for j in range(3):  # x, y, z
         ys = np.empty(shape=(len(subfolders), repetition * 2 + 1))
         for r in range(repetition + 1):
@@ -668,17 +617,18 @@
 
         if raw:
             pd.DataFrame(ys, index=subfolders).to_csv(f"pol_{xyz[j]}.csv")
 
     plt.tight_layout()
     # save and show
     if figname:
-        os.makedirs(os.path.dirname(os.path.abspath(figname)), exist_ok=True)
-        plt.savefig(figname, dpi=300)
-        print(f"--> 图片已保存为 {os.path.abspath(figname)}")
+        absfig = os.path.abspath(figname)
+        os.makedirs(os.path.dirname(absfig), exist_ok=True)
+        plt.savefig(absfig, dpi=300)
+        print(f"==> {absfig}")
     if show:
         plt.show()
 
     return axes
 
 
 def _get_subfolders_quantum_totals(directory: str):
@@ -696,59 +646,54 @@
     subfolders : list
         子目录列表
     quantum : np.ndarray
         量子数，xyz三个方向, shape=(1, 3)
     totals : np.ndarray
         极化总量，xyz三个方向, shape=(len(subfolders), 3)
     """
-
-    raw_subfolders = next(os.walk(directory))[1]
+    absdir = os.path.abspath(directory)
+    raw_subfolders = next(os.walk(absdir))[1]
     subfolders = []
     for subfolder in raw_subfolders:
         assert (
             0 <= int(subfolder) < 100
         ), f"--> You should rename subfolders to 0~99, but {subfolder} found"
         try:
             assert 0 <= int(subfolder) < 100
             subfolders.append(subfolder)
         except:
             pass
     subfolders.sort()  # 从小到大排序
-    if os.path.exists(f"{os.path.join(directory, subfolders[0])}/scf.h5"):
-        # quantum number if constant across the whole calculation,
-        # so, read only once
-        quantum = np.array(
-            h5py.File(f"{os.path.join(directory, subfolders[0])}/scf.h5").get(
-                "/PolarizationInfo/Quantum"
-            )
-        )
-        # the Total number is not constant
-        totals = np.empty(shape=(len(subfolders), 3))
-        for i, fd in enumerate(subfolders):
-            data = h5py.File(f"{os.path.join(directory, fd)}/scf.h5")
-            total = np.array(data.get("/PolarizationInfo/Total"))
-            totals[i] = total
-
-    elif os.path.exists(f"{os.path.join(directory, subfolders[0])}/polarization.json"):
-        # quantum number if constant across the whole calculation,
-        # so, read only once
-        with open(
-            f"{os.path.join(directory, subfolders[0])}/polarization.json", "r"
-        ) as f:
-            quantum = json.load(f)["PolarizationInfo"]["Quantum"]
-        # the Total number is not constant
-        totals = np.empty(shape=(len(subfolders), 3))
-        for i, fd in enumerate(subfolders):
-            with open(f"{os.path.join(directory, fd)}/polarization.json", "r") as f:
-                data = json.load(f)
-            total = data["PolarizationInfo"]["Total"]
-            totals[i] = np.array(total, dtype=float)
 
+    # quantum number if constant across the whole calculation, read only once
+    absh5 = f"{os.path.join(absdir, subfolders[0])}/scf.h5"
+    absjs = f"{os.path.join(absdir, subfolders[0])}/polarization.json"
+    if os.path.isfile(absjs):
+        quantum = np.array(h5py.File(absh5).get("/PolarizationInfo/Quantum"))
+    elif os.path.isfile(absjs):
+        with open(absjs, "r") as f:
+            quantum = np.array(json.load(f)["PolarizationInfo"]["Quantum"])
     else:
-        raise ValueError("no polarization.json or scf.h5 file found")
+        raise FileNotFoundError(f"No {absh5}/{absjs}")
+
+    totals = np.empty(shape=(len(subfolders), 3))
+    # the Total number is not constant, read for each subfolder
+    for i, fd in enumerate(subfolders):
+        absh5 = f"{os.path.join(absdir, fd)}/scf.h5"
+        absjs = f"{os.path.join(absdir, fd)}/polarization.json"
+        if os.path.isfile(absh5):
+            data = h5py.File(f"{os.path.join(absdir, fd)}/scf.h5")
+            total = np.array(data.get("/PolarizationInfo/Total"))
+        elif os.path.isfile(absjs):
+            with open(absjs, "r") as f:
+                data = json.load(f)
+            total = np.array(data["PolarizationInfo"]["Total"], dtype=float)
+        else:
+            raise FileNotFoundError(f"No {absh5}/{absjs}")
+        totals[i] = total
 
     return subfolders, quantum, totals
 
 
 def getEwtData(nk, nb, celtot, proj_wt, ef, de, dele):
     emin = np.min(celtot) - de
     emax = np.max(celtot) - de
@@ -814,53 +759,45 @@
             xs.extend(x)
             ys.extend(y)
         xs = np.linspace(1, len(xs), len(xs))
         return xs, ys
 
     # search datafile in the given directory
     elif isinstance(datafile, str):
-        if os.path.isdir(datafile):  # 如果是文件夹
-            directory = datafile  # specified datafile is actually a directory
-            print(f"您指定了一个文件夹，正在{directory}中自动查找aimd.h5...")
-            if os.path.exists(os.path.join(directory, "aimd.h5")):
-                datafile = os.path.join(directory, "aimd.h5")
-                print("Reading aimd.h5...")
-            else:
-                raise FileNotFoundError("未找到aimd.h5文件！")
-
-        elif datafile.endswith(".h5"):  # 如果是h5文件
-            hf = h5py.File(datafile)  # 加载h5文件
-            print(f" reading {os.path.abspath(datafile)}...")
-            Nstep = len(np.array(hf.get("/Structures"))) - 2  # 步数（可能存在未完成的）
-            ys = np.empty(Nstep)  # 准备一个空数组
-            # 开始读取
-            if index == "5":
-                for i in range(1, Nstep + 1):
-                    ys[i - 1] = np.linalg.det(hf.get("/Structures/Step-%d/Lattice" % i))
-            else:
-                map = {
-                    "1": "IonsKineticEnergy",
-                    "2": "TotalEnergy0",
-                    "3": "PressureKinetic",
-                    "4": "Temperature",
-                }
-                for i in range(1, Nstep + 1):
-                    # 如果计算中断，则没有PressureKinetic这个键
-                    try:
-                        ys[i - 1] = np.array(
-                            hf.get("/AimdInfo/Step-%d/%s" % (i, map[index]))
-                        )
-                    except:
-                        ys[i - 1] = 0
-                        ys = np.delete(ys, -1)
-                        print(f"-> 计算中断于第 {Nstep} 步，未读取到第 {i} 步的 {map[index]} 数据！")
-                        break
+        absfile = get_absfile(datafile, task="aimd", only_h5=True)
+        hf = h5py.File(absfile)  # 加载h5文件
+        print(f"Reading {absfile}...")
+        Nstep = len(np.array(hf.get("/Structures"))) - 2  # 步数（可能存在未完成的）
+        ys = np.empty(Nstep)  # 准备一个空数组
+        # 开始读取
+        if index == "5":
+            for i in range(1, Nstep + 1):
+                ys[i - 1] = np.linalg.det(hf.get("/Structures/Step-%d/Lattice" % i))
+        else:
+            map = {
+                "1": "IonsKineticEnergy",
+                "2": "TotalEnergy0",
+                "3": "PressureKinetic",
+                "4": "Temperature",
+            }
+            for i in range(1, Nstep + 1):
+                # 如果计算中断，则没有PressureKinetic这个键
+                try:
+                    ys[i - 1] = np.array(
+                        hf.get("/AimdInfo/Step-%d/%s" % (i, map[index]))
+                    )
+                except:
+                    ys[i - 1] = 0
+                    ys = np.delete(ys, -1)
+                    warnings.warn(
+                        "-> AIMD task stopped at Nstep=%s, failed to read its %s value"
+                        % (Nstep, map[index])
+                    )
+                    break
 
-            Nstep = len(ys)  # 步数更新为实际完成的步数
+        Nstep = len(ys)  # 步数更新为实际完成的步数
 
-            # 返回xs，ys两个数组
-            return np.linspace(1, Nstep, Nstep), np.array(ys)
+        # 返回xs，ys两个数组
+        return np.linspace(1, Nstep, Nstep), np.array(ys)
 
-        else:
-            raise TypeError("仅支持读取h5文件！")
     else:
-        raise TypeError("datafile必须是字符串或列表！")
+        raise TypeError("datafile must be str or list")
```

## dspawpy/analysis/aimdtools.py

```diff
@@ -1,11 +1,14 @@
 # -*- coding: utf-8 -*-
+import json
 import os
+import warnings
 from typing import List, Union
 
+import h5py
 import matplotlib.pyplot as plt
 import numpy as np
 from dspawpy.io.structure import build_Structures_from_datafile
 from pymatgen.core import Structure
 from scipy.ndimage import gaussian_filter1d
 
 
@@ -106,15 +109,15 @@
         ngrid (int): number of grid points, defaults to 101
         sigma (float): smooth parameter
         """
         if isinstance(structures, Structure):
             structures = [structures]
         self.structures = structures
         # Number of atoms in all structures should be the same
-        assert len({len(i) for i in self.structures}) == 1, "不同构型的原子数不等！"
+        assert len({len(i) for i in self.structures}) == 1, "Different configurations have different numbers of atoms!"
         elements = [[i.specie for i in j.sites] for j in self.structures]
         unique_elements_on_sites = [len(set(i)) == 1 for i in list(zip(*elements))]
 
         # For the same site index, all structures should have the same element there
         if not all(unique_elements_on_sites):
             raise RuntimeError("Elements are not the same at least for one site")
 
@@ -287,30 +290,32 @@
         return np.sqrt(result)
 
 
 def get_lagtime_msd(
     datafile: Union[str, List[str]],
     select: Union[str, List[int]] = "all",
     msd_type: str = "xyz",
-    timestep: float = 1.0,
+    timestep: float = None,
 ):
     r"""计算不同时间步长下的均方差
 
     Parameters
     ----------
     datafile : str or list of str
-        aimd.h5或aimd.json文件或包含这两个文件之一的文件夹；
-        写成列表的话将依次读取数据并合并到一起
+        - aimd.h5/aimd.json文件路径或包含这些文件的文件夹路径（优先寻找aimd.h5）
+        - 写成列表的话将依次读取数据并合并到一起
+        - 例如['aimd1.h5', 'aimd2.h5', '/data/home/my_aimd_task']
     select : str or list of int
         原子序号列表，原子序号从0开始编号；默认为'all'，计算所有原子
         暂不支持计算多个元素的MSD
     msd_type : str
         计算MSD的类型，可选xyz,xy,xz,yz,x,y,z，默认为'xyz'，即计算所有分量
     timestep : float
-        时间间隔，单位为fs，默认1.0fs
+        相邻结构的时间间隔，单位为fs，默认None，将从datafile中读取，失败则设为1.0fs；
+        若不为None，则将使用该值计算时间序列
 
     Returns
     -------
     lagtime : np.ndarray
         时间序列
     result : np.ndarray
         均方差序列
@@ -324,35 +329,47 @@
     >>> lagtime
     array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.997e+03, 1.998e+03,
            1.999e+03])
     >>> msd
     array([0.00000000e+00, 8.80447550e-02, 1.83768134e-01, ...,
            9.66185452e+02, 9.66812755e+02, 9.67357702e+02])
     """
-    strs = build_Structures_from_datafile(datafile)
+    strs = build_Structures_from_datafile(datafile, task="aimd")
+    if timestep is None:
+        if isinstance(datafile, str) or len(datafile) == 1:
+            ts = _get_time_step(datafile)
+        else:
+            warnings.warn(
+                "For multiple datafiles, you must manually specify the timestep. It will default to 1.0fs."
+            )
+            ts = 1.0
+    else:
+        ts = timestep
 
     msd = MSD(strs, select, msd_type)
     result = msd.run()
 
     nframes = msd.n_frames
-    lagtime = np.arange(nframes) * timestep  # make the lag-time axis
+    lagtime = np.arange(nframes) * ts  # make the lag-time axis
 
     return lagtime, result
 
 
-def get_lagtime_rmsd(datafile: Union[str, List[str]], timestep: float = 1.0):
+def get_lagtime_rmsd(datafile: Union[str, List[str]], timestep: float = None):
     r"""
 
     Parameters
     ----------
     datafile : str or list of str
-        aimd.h5或aimd.json文件或包含这两个文件之一的文件夹；
-        写成列表的话将依次读取数据并合并到一起
+        - aimd.h5/aimd.json文件路径或包含这些文件的文件夹路径（优先寻找aimd.h5）
+        - 写成列表的话将依次读取数据并合并到一起
+        - 例如['aimd1.h5', 'aimd2.h5', '/data/home/my_aimd_task']
     timestep : float
-        时间步长，单位fs，默认1fs
+        相邻结构的时间间隔，单位为fs，默认None，将从datafile中读取，失败则设为1.0fs；
+        若不为None，则将使用该值计算时间序列
 
     Returns
     -------
     lagtime : numpy.ndarray
         时间序列
     rmsd : numpy.ndarray
         均方根序列
@@ -366,22 +383,32 @@
     >>> lagtime
     array([0.000e+00, 1.000e-01, 2.000e-01, ..., 1.997e+02, 1.998e+02,
            1.999e+02])
     >>> rmsd
     array([ 0.        ,  0.04849931,  0.09181907, ..., 31.09991413,
            31.10077061, 31.10237454])
     """
-    strs = build_Structures_from_datafile(datafile)
+    strs = build_Structures_from_datafile(datafile, task="aimd")
+    if timestep is None:
+        if isinstance(datafile, str) or len(datafile) == 1:
+            ts = _get_time_step(datafile)
+        else:
+            warnings.warn(
+                "For multiple datafiles, you must manually specify the timestep. It will default to 1.0fs."
+            )
+            ts = 1.0
+    else:
+        ts = timestep
 
     rmsd = RMSD(structures=strs)
     result = rmsd.run()
 
     # Plot
     nframes = rmsd.n_frames
-    lagtime = np.arange(nframes) * timestep  # make the lag-time axis
+    lagtime = np.arange(nframes) * ts  # make the lag-time axis
 
     return lagtime, result
 
 
 def get_rs_rdfs(
     datafile: Union[str, List[str]],
     ele1: str,
@@ -392,16 +419,17 @@
     sigma: float = 0,
 ):
     r"""计算rdf分布函数
 
     Parameters
     ----------
     datafile : str or list of str
-        aimd.h5或aimd.json文件路径或包含这两个文件之一的文件夹；
-        写成列表的话将依次读取数据并合并到一起
+        - aimd.h5/aimd.json文件路径或包含这些文件的文件夹路径（优先寻找aimd.h5）
+        - 写成列表的话将依次读取数据并合并到一起
+        - 例如['aimd1.h5', 'aimd2.h5', '/data/home/my_aimd_task']
     ele1 : list
         中心元素
     ele2 : list
         相邻元素
     rmin : float
         径向分布最小值，默认为0
     rmax : float
@@ -448,17 +476,15 @@
            0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
            0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
            0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
            0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
            0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
            0.00000000e+00])
     """
-    strs = build_Structures_from_datafile(datafile)
-    # print(strs[0]) # check pbc
-    # raise ValueError
+    strs = build_Structures_from_datafile(datafile, task="aimd")
 
     # 计算rdf并绘制主要曲线
     obj = RDF(structures=strs, rmin=rmin, rmax=rmax, ngrid=ngrid, sigma=sigma)
 
     rs, rdfs = obj.get_rdf(ele1, ele2)
     return rs, rdfs
 
@@ -507,37 +533,38 @@
     >>> lagtime, msd = get_lagtime_msd('/data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5', select=[0])
     Reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
     Calculating MSD...
 
     用获取的数据画图并保存
 
     >>> plot_msd(lagtime, msd, figname='/data/home/hzw1002/dspawpy_repo/test/out/MSD.png', show=False)
-    MSD图片保存在 /data/home/hzw1002/dspawpy_repo/test/out/MSD.png
-    <Axes: xlabel='Time (fs)', ylabel='MSD (Å)'>
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/MSD.png
+    <Axes: xlabel='Time (fs)', ylabel='MSD ($Å^2$)'>
     """
     if ax:
         ishow = False
         ax.plot(lagtime, result, c="black", ls="-", **kwargs)
     else:
         ishow = True
         fig, ax = plt.subplots()
         ax.plot(lagtime, result, c="black", ls="-", **kwargs)
         ax.set_xlabel("Time (fs)")
-        ax.set_ylabel("MSD (Å)")
+        ax.set_ylabel(r"MSD ($Å^2$)")
 
     if xlim:
         ax.set_xlim(xlim)
     if ylim:
         ax.set_ylim(ylim)
 
     plt.tight_layout()
     if figname:
-        os.makedirs(os.path.dirname(os.path.abspath(figname)), exist_ok=True)
-        plt.savefig(figname, dpi=300)
-        print("MSD图片保存在", os.path.abspath(figname))
+        absfig = os.path.abspath(figname)
+        os.makedirs(os.path.dirname(absfig), exist_ok=True)
+        plt.savefig(absfig, dpi=300)
+        print(f"==> {absfig}")
     if show and ishow:  # 画子图的话，不应每个子图都show
         plt.show()  # show会自动清空图片
 
     return ax
 
 
 def plot_rdf(
@@ -590,15 +617,15 @@
     >>> rs, rdfs = get_rs_rdfs('/data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5', 'H', 'O', rmax=6)
     Reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
     Calculating RDF...
 
     将xy轴数据传入plot_rdf函数绘图
 
     >>> plot_rdf(rs, rdfs, 'H','O', figname='/data/home/hzw1002/dspawpy_repo/test/out/RDF.png', show=False)
-    图片已保存到 /data/home/hzw1002/dspawpy_repo/test/out/RDF.png
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/RDF.png
     """
 
     if ax:
         ishow = False
         ax.plot(
             rs,
             rdfs,
@@ -625,17 +652,18 @@
     if xlim:
         ax.set_xlim(xlim)
     if ylim:
         ax.set_ylim(ylim)
 
     plt.tight_layout()
     if figname:
-        os.makedirs(os.path.dirname(os.path.abspath(figname)), exist_ok=True)
-        plt.savefig(figname, dpi=300)
-        print(f"图片已保存到 {os.path.abspath(figname)}")
+        absfig = os.path.abspath(figname)
+        os.makedirs(os.path.dirname(absfig), exist_ok=True)
+        plt.savefig(absfig, dpi=300)
+        print(f"==> {absfig}")
     if show and ishow:  # 画子图的话，不应每个子图都show
         plt.show()  # show会自动清空图片
 
 
 def plot_rmsd(
     lagtime: np.ndarray,
     result: np.ndarray,
@@ -680,15 +708,15 @@
     >>> lagtime, rmsd = get_lagtime_rmsd(datafile='/data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5', timestep=0.1)
     Reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
     Calculating RMSD...
 
     直接保存为RMSD.png图片
 
     >>> plot_rmsd(lagtime, rmsd, figname='/data/home/hzw1002/dspawpy_repo/test/out/RMSD.png', show=False)
-    图片已保存到 /data/home/hzw1002/dspawpy_repo/test/out/RMSD.png
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/RMSD.png
     <Axes: xlabel='Time (fs)', ylabel='RMSD (Å)'>
     """
     # 参数初始化
     if not ax:
         ishow = True
     else:
         ishow = False
@@ -704,14 +732,42 @@
     if xlim:
         ax.set_xlim(xlim)
     if ylim:
         ax.set_ylim(ylim)
 
     plt.tight_layout()
     if figname:
-        os.makedirs(os.path.dirname(os.path.abspath(figname)), exist_ok=True)
-        plt.savefig(figname, dpi=300)
-        print(f"图片已保存到 {os.path.abspath(figname)}")
+        absfig = os.path.abspath(figname)
+        os.makedirs(os.path.dirname(absfig), exist_ok=True)
+        plt.savefig(absfig, dpi=300)
+        print(f"==> {absfig}")
     if show and ishow:  # 画子图的话，不应每个子图都show
         plt.show()  # show会自动清空图片
 
     return ax
+
+
+def _get_time_step(datafile):
+    absfile = os.path.abspath(datafile)
+    if absfile.endswith(".h5"):
+        hpath = os.path.abspath(absfile)
+        hf = h5py.File(hpath)
+        try:
+            t = np.array(hf["/Structures/TimeStep"])[0]
+            timestep = float(t)
+        except Exception:
+            print(str(Exception))
+            timestep = 1.0
+    elif absfile.endswith(".json"):
+        jpath = os.path.abspath(absfile)
+        with open(jpath, "r") as f:
+            jdata = json.load(f)
+        try:
+            t = jdata["Structures"][0]["TimeStep"]
+            timestep = float(t)
+        except Exception:
+            print(str(Exception))
+            timestep = 1.0
+    else:
+        raise ValueError(f"{absfile} must be .h5 or .json")
+
+    return timestep
```

## dspawpy/diffusion/neb.py

```diff
@@ -90,25 +90,27 @@
     >>> from dspawpy.diffusion.neb import NEB,write_neb_structures
     >>> neb = NEB(init_struct,final_struct,8)
     >>> structures = neb.linear_interpolate()   #线性插值
 
     插值完成的构型可指定保存到neb文件夹下
 
     >>> write_neb_structures(structures, fmt="as", path="/data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures")
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/00/structure00.as
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/01/structure01.as
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/02/structure02.as
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/03/structure03.as
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/04/structure04.as
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/05/structure05.as
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/06/structure06.as
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/07/structure07.as
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/00/structure00.as
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/01/structure01.as
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/02/structure02.as
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/03/structure03.as
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/04/structure04.as
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/05/structure05.as
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/06/structure06.as
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/11neb_interpolate_structures/07/structure07.as
     """
-    assert fmt is not None
+    if fmt is None:
+        fmt = "as"
+    absdir = os.path.abspath(path)
     N = len(str(len(structures)))
     if N <= 2:
         N = 2
     for i, structure in enumerate(structures):
         path_name = str(i).zfill(N)
-        os.makedirs(os.path.join(path, path_name), exist_ok=True)
-        filename = os.path.join(path, path_name, "%s%s.%s" % (prefix, path_name, fmt))
+        os.makedirs(os.path.join(absdir, path_name), exist_ok=True)
+        filename = os.path.join(absdir, path_name, "%s%s.%s" % (prefix, path_name, fmt))
         to_file(structure, filename, fmt, coords_are_cartesian)
```

## dspawpy/diffusion/nebtools.py

```diff
@@ -1,31 +1,34 @@
 # -*- coding: utf-8 -*-
 import json
 import os
 import shutil
+import warnings
 
 import h5py
 import numpy as np
 import pandas as pd
 
 np.set_printoptions(suppress=True)  # 不使用科学计数法
 import zipfile
 
 import matplotlib.pyplot as plt
+from dspawpy.io.read import get_ele_from_h5
 from dspawpy.io.structure import build_Structures_from_datafile
-from dspawpy.io.utils import get_ele_from_h5
+from dspawpy.io.utils import get_absfile
 
 
 def _zip_folder(folder_path, output_path):
-    with zipfile.ZipFile(output_path, "w", zipfile.ZIP_DEFLATED) as zipf:
-        for root, _, files in os.walk(folder_path):
+    absdir1 = os.path.abspath(folder_path)
+    absdir2 = os.path.abspath(output_path)
+    with zipfile.ZipFile(absdir2, "w", zipfile.ZIP_DEFLATED) as zipf:
+        for root, _, files in os.walk(absdir1):
             for file in files:
                 file_path = os.path.join(root, file)
-                zipf.write(file_path, os.path.relpath(file_path, folder_path))
-    print(f"已将{folder_path}压缩到{output_path}")
+                zipf.write(file_path, os.path.relpath(file_path, absdir1))
 
 
 def get_distance(
     spo1: np.ndarray, spo2: np.ndarray, lat1: np.ndarray, lat2: np.ndarray
 ):
     r"""根据两个结构的分数坐标和晶胞计算距离
 
@@ -91,27 +94,27 @@
     Examples
     --------
     >>> from dspawpy.diffusion.nebtools import get_neb_subfolders
     >>> directory = '/data/home/hzw1002/dspawpy_repo/test/2.15'
     >>> get_neb_subfolders(directory)
     ['00', '01', '02', '03', '04']
     """
-    raw_subfolders = next(os.walk(directory))[1]
+    absdir = os.path.abspath(directory)
+    raw_subfolders = next(os.walk(absdir))[1]
     subfolders = []
     for subfolder in raw_subfolders:
         try:
             assert 0 <= int(subfolder) < 100
             subfolders.append(subfolder)
         except:
             pass
     subfolders.sort()  # 从小到大排序
     if return_abs:
         subfolders = [
-            os.path.abspath(os.path.join(directory, subfolder))
-            for subfolder in subfolders
+            os.path.abspath(os.path.join(absdir, subfolder)) for subfolder in subfolders
         ]
     return subfolders
 
 
 def plot_barrier(
     datafile: str = "neb.h5",
     directory: str = None,
@@ -157,53 +160,54 @@
     ValueError
         传递给插值算法的参数不符合该算法要求
 
     Examples
     --------
     >>> from dspawpy.diffusion.nebtools import plot_barrier
     >>> import matplotlib.pyplot as plt
+
+    对比不同插值算法
+
     >>> plot_barrier(directory='/data/home/hzw1002/dspawpy_repo/test/2.15', method='interp1d', kind=2, figname=None, show=False)
     >>> plot_barrier(directory='/data/home/hzw1002/dspawpy_repo/test/2.15', method='interp1d', kind=3, figname=None, show=False)
     >>> plot_barrier(directory='/data/home/hzw1002/dspawpy_repo/test/2.15', method='CubicSpline', figname=None, show=False)
-    >>> plot_barrier(directory='/data/home/hzw1002/dspawpy_repo/test/2.15', method='pchip', figname=None, show=False)
+    >>> plot_barrier(directory='/data/home/hzw1002/dspawpy_repo/test/2.15', method='pchip', figname='../out/barrier_comparison.png', show=False)
+
+    尝试读取neb.h5文件或neb.json文件
+
+    >>> plot_barrier(datafile='/data/home/hzw1002/dspawpy_repo/test/2.15/neb.h5', method='pchip', figname='../out/barrier_h5.png', show=False)
+    >>> plot_barrier(datafile='/data/home/hzw1002/dspawpy_repo/test/2.15/neb.json', method='pchip', figname='../out/barrier_json.png', show=False)
     """
     if directory is not None:
         # read data
-        subfolders, resort_mfs, rcs, ens, dEs = _getef(directory)
+        subfolders, resort_mfs, rcs, ens, dEs = _getef(os.path.abspath(directory))
 
     elif datafile:
-        assert os.path.exists(datafile), f"文件{datafile}不存在"
-        if datafile.endswith(".h5"):
+        absfile = get_absfile(datafile, task="neb")  # -> return either .h5 or .json
+        if absfile.endswith(".h5"):
             from dspawpy.io.read import load_h5
 
-            neb = load_h5(datafile)
+            neb = load_h5(absfile)
             if "/BarrierInfo/ReactionCoordinate" in neb.keys():
                 reaction_coordinate = neb["/BarrierInfo/ReactionCoordinate"]
                 energy = neb["/BarrierInfo/TotalEnergy"]
             else:  # old version
                 reaction_coordinate = neb["/Distance/ReactionCoordinate"]
                 energy = neb["/Energy/TotalEnergy"]
-        elif datafile.endswith(".json"):
-            with open(datafile, "r") as fin:
+        elif absfile.endswith(".json"):
+            with open(absfile, "r") as fin:
                 neb = json.load(fin)
             if "BarrierInfo" in neb.keys():
                 reaction_coordinate = neb["BarrierInfo"]["ReactionCoordinate"]
                 energy = neb["BarrierInfo"]["TotalEnergy"]
             else:  # old version
                 reaction_coordinate = neb["Distance"]["ReactionCoordinate"]
                 energy = neb["Energy"]["TotalEnergy"]
-        else:
-            raise TypeError("datafile 必须是 .h5 或 .json 文件格式")
 
-        x = []
-        for c in reaction_coordinate:
-            if len(x) > 0:
-                x.append(x[-1] + c)
-            else:
-                x.append(c)
+        x = reaction_coordinate # 从neb.h5/json 读取的不需要累加
 
         y = [x - energy[0] for x in energy]
         # initial and final info
         if ri is not None:  # add initial reaction coordinate
             x.insert(0, ri)
         if rf is not None:  # add final reaction coordinate
             x.append(rf)
@@ -212,32 +216,29 @@
             y.insert(0, ei)
         if ef is not None:  # add final energy
             y.append(ef)
 
         rcs = np.array(x)
         dEs = np.array(y)
 
-        print(f"如果NEB任务不计算初末态的自洽，{datafile}中将缺失相关信息，需要手动输入")
-        os.getcwd()
-
     else:
-        raise ValueError("请指定datafile或directory！")
+        raise ValueError("Please specify directory or datafile!")
 
     # import scipy interpolater
     try:
         interpolate_method = getattr(
             __import__("scipy.interpolate", fromlist=[method]), method
         )
     except:
-        raise ImportError(f"无法找到 scipy.interpolate.{method} 算法！")
+        raise ImportError(f"No scipy.interpolate.{method} method！")
     # call the interpolater to interpolate with given kwargs
     try:
         inter_f = interpolate_method(rcs, dEs, **kwargs)
     except:
-        raise ValueError(f"插值失败，请检查{kwargs}参数设置是否有误！")
+        raise ValueError(f"Please check whether {kwargs} is valid for {method}！")
 
     xnew = np.linspace(rcs[0], rcs[-1], 100)
     ynew = inter_f(xnew)
 
     if raw:
         pd.DataFrame({"x_raw": rcs, "y_raw": dEs}).to_csv("raw_xy.csv", index=False)
         pd.DataFrame({"x_interpolated": xnew, "y_interpolated": ynew}).to_csv(
@@ -253,17 +254,18 @@
     plt.xlabel("Reaction Coordinate (Å)")
     plt.ylabel("Energy (eV)")
     plt.legend()
 
     plt.tight_layout()
     # save and show
     if figname:
-        os.makedirs(os.path.dirname(os.path.abspath(figname)), exist_ok=True)
-        plt.savefig(figname, dpi=300)
-        print(f"--> 图片已保存为 {os.path.abspath(figname)}")
+        absfig = os.path.abspath(figname)
+        os.makedirs(os.path.dirname(absfig), exist_ok=True)
+        plt.savefig(absfig, dpi=300)
+        print(f"==> {absfig}")
     if show:
         plt.show()
 
 
 def plot_neb_converge(
     neb_dir: str,
     image_key: str = "01",
@@ -272,15 +274,15 @@
     raw=False,
 ):
     """指定NEB计算路径，绘制NEB收敛过程图
 
     Parameters
     ----------
     neb_dir : str
-        NEB计算路径
+        neb.h5 / neb.json 文件路径或者包含 neb.h5 / neb.json 文件的文件夹路径
     image_key : str
         第几个构型，默认 "01"
     show : bool
         是否交互绘图
     image_name : str
         NEB收敛图名称，默认 "neb_conv.png"
     raw : bool
@@ -291,21 +293,20 @@
     ax1, ax2 : matplotlib.axes.Axes
         两个子图的Axes对象
 
     Examples
     --------
     >>> from dspawpy.diffusion.nebtools import plot_neb_converge
     >>> plot_neb_converge(neb_dir='/data/home/hzw1002/dspawpy_repo/test/2.15', image_key='01', figname='/data/home/hzw1002/dspawpy_repo/test/out/neb_converge1.png',show=False)
-    --> 图片已保存为 /data/home/hzw1002/dspawpy_repo/test/out/neb_converge1.png
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/neb_converge1.png
     (<Axes: xlabel='Number of ionic step', ylabel='Force (eV/Å)'>, <Axes: xlabel='Number of ionic step', ylabel='Energy (eV)'>)
     """
-    assert os.path.isdir(neb_dir), f"目录{neb_dir}不存在"
-
-    if os.path.exists(os.path.join(neb_dir, "neb.h5")):
-        neb_total = h5py.File(os.path.join(neb_dir, "neb.h5"))
+    absfile = get_absfile(neb_dir, "neb")
+    if os.path.isfile(absfile):
+        neb_total = h5py.File(absfile)
         # new output (>=2022B)
         if "/LoopInfo/01/MaxForce" in neb_total.keys():
             maxforce = np.array(neb_total.get("/LoopInfo/" + image_key + "/MaxForce"))
         else:  # old output
             maxforce = np.array(neb_total.get("/Iteration/" + image_key + "/MaxForce"))
 
         if "/LoopInfo/01/TotalEnergy" in neb_total.keys():  # new output (>=2022B)
@@ -313,35 +314,30 @@
                 neb_total.get("/LoopInfo/" + image_key + "/TotalEnergy")
             )
         else:  # old output
             total_energy = np.array(
                 neb_total.get("/Iteration/" + image_key + "/TotalEnergy")
             )
 
-    elif os.path.exists(os.path.join(neb_dir, "neb.json")):
-        with open(os.path.join(neb_dir, "neb.json"), "r") as fin:
+    elif os.path.isfile(absfile):
+        with open(absfile, "r") as fin:
             neb_total = json.load(fin)
         if "LoopInfo" in neb_total.keys():
             neb = neb_total["LoopInfo"][image_key]
         else:
             neb = neb_total["Iteration"][image_key]
         maxforce = []
         total_energy = []
         for n in neb:
             maxforce.append(n["MaxForce"])
             total_energy.append(n["TotalEnergy"])
 
         maxforce = np.array(maxforce)
         total_energy = np.array(total_energy)
 
-    else:
-        print(
-            f"请检查{os.path.join(neb_dir, 'neb.h5')}或{os.path.join(neb_dir, 'neb.h5')}是否都存在！"
-        )
-
     x = np.arange(len(maxforce))
 
     force = maxforce
     energy = total_energy
 
     if raw:
         pd.DataFrame({"x": x, "force": force, "energy": energy}).to_csv(
@@ -359,17 +355,18 @@
     ax2.set_ylabel("Energy (eV)")
     ax2.ticklabel_format(useOffset=False)  # y轴坐标显示绝对值而不是相对值
     fig.legend(loc=1, bbox_to_anchor=(1, 1), bbox_transform=ax1.transAxes)
 
     plt.tight_layout()
     # save and show
     if figname:
-        os.makedirs(os.path.dirname(os.path.abspath(figname)), exist_ok=True)
-        plt.savefig(figname, dpi=300)
-        print(f"--> 图片已保存为 {os.path.abspath(figname)}")
+        absfig = os.path.abspath(figname)
+        os.makedirs(os.path.dirname(absfig), exist_ok=True)
+        plt.savefig(absfig, dpi=300)
+        print(f"==> {absfig}")
     if show:
         plt.show()
 
     return ax1, ax2
 
 
 def printef(directory):
@@ -416,65 +413,59 @@
         备份文件夹路径，默认将在当前路径新建一个bakfile文件夹用于备份；
         也可以任意指定一个路径，但不能与当前路径相同
 
     Examples
     ----------
     >>> from dspawpy.diffusion.nebtools import restart
     >>> restart(directory='/data/home/hzw1002/dspawpy_repo/test/neb_temp_back', output='/data/home/hzw1002/dspawpy_repo/test/out/neb_backup')
-    已将/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/00压缩到/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/00.zip
-    已将/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/01压缩到/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/01.zip
-    已将/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/02压缩到/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/02.zip
-    已将/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/03压缩到/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/03.zip
-    已将/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/04压缩到/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/04.zip
-    已将/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/tmp压缩到/data/home/hzw1002/dspawpy_repo/test/out/neb_backup/neb_data.zip
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/neb_backup
 
     续算准备工作可能需要较长时间才能完成，请耐心等待
     """
+    absout = os.path.abspath(output)
+    absdir = os.path.abspath(directory)
+
     while True:
-        if os.path.isdir(output):
-            if os.path.abspath(output) == os.getcwd():
-                raise ValueError("备份文件夹不能与当前路径相同！")
-            else:
-                output += "_new"
-                continue
+        if os.path.isdir(absout):
+            absout += "_new"
+            continue
         else:
             break
 
-    subfolders = get_neb_subfolders(directory, return_abs=True)  # 获取子文件夹路径
-    os.makedirs(output, exist_ok=True)  # 创建bakfile文件夹
+    subfolders = get_neb_subfolders(absdir, return_abs=True)  # 获取子文件夹路径
+    os.makedirs(absout, exist_ok=True)  # 创建bakfile文件夹
     # 先处理子文件夹00，01...
     for subfolder_old in subfolders:
         folder_index = subfolder_old.split("/")[-1]  # 00，01...
-        subfolder_back = os.path.join(output, folder_index)  # 子文件夹备份到此
+        subfolder_back = os.path.join(absout, folder_index)  # 子文件夹备份到此
         shutil.move(subfolder_old, subfolder_back)
         os.makedirs(subfolder_old, exist_ok=True)  # 原文件夹清空了
 
         latestStructureFile = f"{subfolder_back}/latestStructure{folder_index}.as"
         structureFile = f"{subfolder_back}/structure{folder_index}.as"
 
         # 将结构文件复制到原路径下用于续算，有ls则用之，否则用s代替，都没有则报错
         s_in_old = f"{subfolder_old}/structure{folder_index}.as"
         if os.path.isfile(latestStructureFile):
             shutil.copy(latestStructureFile, s_in_old)
         elif os.path.isfile(structureFile):
-            print(f"未找到{latestStructureFile}，复用{structureFile}续算")
             shutil.copy(structureFile, s_in_old)
         else:
             raise FileNotFoundError(f"{latestStructureFile}和{structureFile}都不存在！")
 
         # 暂时放到备份主路径下，如果都没有，前面就已经报错了
-        ls_bk = os.path.join(directory, f"latestStructure{folder_index}.as")
-        s_bk = os.path.join(directory, f"structure{folder_index}.as")
+        ls_bk = os.path.join(absdir, f"latestStructure{folder_index}.as")
+        s_bk = os.path.join(absdir, f"structure{folder_index}.as")
         if os.path.isfile(latestStructureFile):
             shutil.copy(latestStructureFile, ls_bk)
         if os.path.isfile(structureFile):
             shutil.copy(structureFile, s_bk)
 
         # 处理备份路径下的子文件夹
-        zf = f"{os.path.abspath(output)}/{folder_index}.zip"
+        zf = f"{absout}/{folder_index}.zip"
         _zip_folder(subfolder_back, zf)  # 压缩子文件夹
         # 清空备份子文件夹
         for file in os.listdir(subfolder_back):
             os.remove(os.path.join(subfolder_back, file))
 
         # 将压缩包、结构文件移入
         shutil.move(zf, f"{subfolder_back}/{folder_index}.zip")
@@ -482,40 +473,36 @@
             shutil.move(ls_bk, f"{subfolder_back}/latestStructure{folder_index}.as")
             shutil.move(s_bk, f"{subfolder_back}/structure{folder_index}.as")
         elif os.path.isfile(ls_bk):
             shutil.move(ls_bk, f"{subfolder_back}/latestStructure{folder_index}.as")
         elif os.path.isfile(s_bk):
             shutil.move(s_bk, f"{subfolder_back}/structure{folder_index}.as")
         else:
-            raise FileNotFoundError(f"{ls_bk}和{s_bk}都不存在！")
+            raise FileNotFoundError(f"No {ls_bk}/{s_bk}")
 
     # 再处理老NEB文件夹主目录下的单个文件
     # 备份neb.h5,neb.json和DS-PAW.log
-    tmp_dir = os.path.join(output, "tmp")
+    tmp_dir = os.path.join(absout, "tmp")
     os.makedirs(tmp_dir, exist_ok=True)
-    if os.path.isfile(f"{directory}/neb.h5"):
-        shutil.move(f"{directory}/neb.h5", f"{tmp_dir}/neb.h5")
-    else:
-        print("未找到neb.h5，将不会备份")
+    if os.path.isfile(f"{absdir}/neb.h5"):
+        shutil.move(f"{absdir}/neb.h5", f"{tmp_dir}/neb.h5")
 
-    if os.path.isfile(f"{directory}/neb.json"):
-        shutil.move(f"{directory}/neb.json", f"{tmp_dir}/neb.json")
-    else:
-        print("未找到neb.json，将不会备份")
+    if os.path.isfile(f"{absdir}/neb.json"):
+        shutil.move(f"{absdir}/neb.json", f"{tmp_dir}/neb.json")
 
     if len(os.listdir(tmp_dir)) > 0:  # 如果有数据文件
-        _zip_folder(tmp_dir, f"{output}/neb_data.zip")
+        _zip_folder(tmp_dir, f"{absout}/neb_data.zip")
         for f in os.listdir(tmp_dir):
             os.remove(os.path.join(tmp_dir, f))
         os.removedirs(tmp_dir)
 
-    if os.path.isfile(f"{directory}/DS-PAW.log"):
-        shutil.move(f"{directory}/DS-PAW.log", f"{output}/DS-PAW.log")
-    else:
-        print("未找到DS-PAW.log，将不会备份")
+    if os.path.isfile(f"{absdir}/DS-PAW.log"):
+        shutil.move(f"{absdir}/DS-PAW.log", f"{absout}/DS-PAW.log")
+
+    print(f"==> {absout}")
 
 
 def set_pbc(spo):
     """根据周期性边界条件将分数坐标分量移入 [-0.5, 0.5) 区间
 
     Parameters
     ----------
@@ -562,197 +549,221 @@
         传递给plot_barrier的参数
 
     Examples
     --------
     >>> from dspawpy.diffusion.nebtools import summary
     >>> directory = '/data/home/hzw1002/dspawpy_repo/test/2.15' # NEB计算路径，默认当前路径
     >>> summary(directory, show=False)
-    --> 1. 打印NEB计算时各构型的能量和受力...
         Force(eV/Å)     RC(Å)    Energy(eV)  E-E0(eV)
     00     0.180272  0.000000 -39637.098409  0.000000
     01     0.026337  0.542789 -39637.018595  0.079814
     02     0.024798  1.086800 -39636.880144  0.218265
     03     0.234429  1.588367 -39636.998366  0.100043
     04     0.014094  2.089212 -39637.089994  0.008414
-    <BLANKLINE>
-    --> 2. 绘制能垒图...
-    --> 图片已保存为 /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_barrier.png
-    <BLANKLINE>
-    --> 3. 绘制收敛过程图到各构型文件夹中...
-    ----> /data/home/hzw1002/dspawpy_repo/test/2.15/01/converge.png...
-    --> 图片已保存为 /data/home/hzw1002/dspawpy_repo/test/2.15/01/converge.png
-    ----> /data/home/hzw1002/dspawpy_repo/test/2.15/02/converge.png...
-    --> 图片已保存为 /data/home/hzw1002/dspawpy_repo/test/2.15/02/converge.png
-    ----> /data/home/hzw1002/dspawpy_repo/test/2.15/03/converge.png...
-    --> 图片已保存为 /data/home/hzw1002/dspawpy_repo/test/2.15/03/converge.png
-    <BLANKLINE>
-    完成!
+    ==> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_barrier.png
+    ==> /data/home/hzw1002/dspawpy_repo/test/2.15/01/converge.png...
+    ==> /data/home/hzw1002/dspawpy_repo/test/2.15/01/converge.png
+    ==> /data/home/hzw1002/dspawpy_repo/test/2.15/02/converge.png...
+    ==> /data/home/hzw1002/dspawpy_repo/test/2.15/02/converge.png
+    ==> /data/home/hzw1002/dspawpy_repo/test/2.15/03/converge.png...
+    ==> /data/home/hzw1002/dspawpy_repo/test/2.15/03/converge.png
 
     若inifin=false，用户必须将自洽的scf.h5或system.json放到初末态子文件夹中
     """
     # 1. 绘制能垒图
-    print("--> 1. 打印NEB计算时各构型的能量和受力...")
-    printef(directory)
+    absdir = os.path.abspath(directory)
+    printef(absdir)
 
     # 2. 打印各构型受力、反应坐标、能量、与初始构型的能量差
-    print("\n--> 2. 绘制能垒图...")
     plt.clf()  # 清空画布再画图
-    plot_barrier(directory=directory, raw=raw, **kwargs)
+    plot_barrier(directory=absdir, raw=raw, **kwargs)
 
     # 3. 绘制并保存结构优化过程的能量和受力收敛过程图到各构型文件夹中
-    print("\n--> 3. 绘制收敛过程图到各构型文件夹中...")
-    subfolders = get_neb_subfolders(directory)
+    subfolders = get_neb_subfolders(absdir)
     for subfolder in subfolders[1 : len(subfolders) - 1]:
         if outdir:
-            os.makedirs(os.path.join(outdir, subfolder), exist_ok=True)
-            pngfile = f"{outdir}/{subfolder}/converge.png"
+            absout = os.path.abspath(outdir)
+            os.makedirs(os.path.join(absout, subfolder), exist_ok=True)
+            pngfile = f"{absout}/{subfolder}/converge.png"
         else:
-            pngfile = f"{directory}/{subfolder}/converge.png"
+            pngfile = f"{absdir}/{subfolder}/converge.png"
 
-        print(f"----> {pngfile}...")
+        print(f"==> {pngfile}...")
         plot_neb_converge(
-            neb_dir=directory,
+            neb_dir=absdir,
             image_key=subfolder,
             figname=pngfile,
             raw=raw,
             show=show_converge,
         )
     plt.clf()
-    print("\n完成!")
 
 
-def write_movie_json(preview: bool = False, directory: str = ".", step: int = -1):
-    r"""NEB计算或者初始插值后，读取信息，保存为 neb_movie*.json 文件
+def write_movie_json(
+    preview: bool = False, directory: str = ".", step: int = -1, dst: str = None
+):
+    DeprecationWarning("Please use write_json_chain() instead")
+    write_json_chain(preview=preview, directory=directory, step=step, dst=dst)
+
+
+def write_json_chain(
+    preview: bool = False, directory: str = ".", step: int = -1, dst: str = None
+):
+    r"""NEB计算或者初始插值后，读取信息，保存为 neb_chain*.json 文件
 
     用 Device Studio 打开该文件可以观察结构等信息
 
     Parameters
     ----------
     preview : bool
         是否预览模式，默认否
     directory : str
         计算结果所在目录. 默认当前路径
     step: int
         离子步编号. 默认-1，读取整个NEB计算过程信息。
         0表示初插结构（未完成离子步）；
-        1表示第一个离子步，以此类推。
+        1表示第一个离子步，以此类推
+    dst : str
+        保存路径，默认为directory
 
     Examples
     ----------
-    >>> from dspawpy.diffusion.nebtools import write_movie_json
+    >>> from dspawpy.diffusion.nebtools import write_json_chain
 
     NEB计算完成后要观察轨迹变化全过程，只需指定NEB计算路径即可
 
-    >>> write_movie_json(directory='/data/home/hzw1002/dspawpy_repo/test/2.15')
-    正在读取最后一个离子步信息...
-    --> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_movie_last.json 写入成功！
+    >>> write_json_chain(directory='/data/home/hzw1002/dspawpy_repo/test/2.15')
+    ==> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_chain_last.json
 
     NEB计算完成后要观察第n离子步结构，请设置step为n，注意step从1开始计数
 
-    >>> write_movie_json(directory='/data/home/hzw1002/dspawpy_repo/test/2.15', step=1)
-    正在读取第1个离子步信息...
-    --> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_movie_1.json 写入成功！
+    >>> write_json_chain(directory='/data/home/hzw1002/dspawpy_repo/test/2.15', step=1)
+    ==> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_chain_1.json
 
     如果您指定的step数超过NEB实际完成的离子步，将会自动修改为最后一步，实际效果等同于上一行代码
 
-    >>> write_movie_json(directory='/data/home/hzw1002/dspawpy_repo/test/2.15', step=10)
-    正在读取第10个离子步信息...
-    --> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_movie_10.json 写入成功！
+    >>> write_json_chain(directory='/data/home/hzw1002/dspawpy_repo/test/2.15', step=10)
+    ==> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_chain_10.json
 
     另外，如需预览初插结构，请将preview设置为True，并将directory指定为NEB计算主路径
 
-    >>> write_movie_json(preview=True, directory='/data/home/hzw1002/dspawpy_repo/test/2.15')
-    正在根据初插结构保存neb_movie_init.json...
-    --> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_movie_init.json 写入成功！
+    >>> write_json_chain(preview=True, directory='/data/home/hzw1002/dspawpy_repo/test/2.15')
+    ==> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_chain_init.json
     """
-
-    if preview:  # preview mode, write neb_movie_init.json from structure.as
-        print("正在根据初插结构保存neb_movie_init.json...")
+    absdir = os.path.abspath(directory)
+    if preview:  # preview mode, write neb_chain_init.json from structure.as
         try:
-            raw = _from_structures(directory)
+            raw = _from_structures(absdir)
         except FileNotFoundError:
-            print("未找到初始插值结构！")
+            print("No structure file！")
         except Exception as e:
-            print("初始插值结构读取失败！", e)
+            print(e)
     else:
         if step == 0:  # try preview mode to save time
             try:
-                raw = _from_structures(directory)
+                raw = _from_structures(absdir)
             except FileNotFoundError:
-                print("未找到初始插值结构，将从计算结果h5或json文件中读取！")
+                print("No structure file")
             except Exception as e:
-                print("初始插值结构读取失败！", e)
+                print(e)
         else:
             try:  # read from h5 file
-                raw = _from_h5(directory, step)
+                raw = _from_h5(absdir, step)
             except FileNotFoundError:
                 try:  # read from json file
-                    raw = _from_json(directory, step)
+                    raw = _from_json(absdir, step)
                 except json.decoder.JSONDecodeError:
-                    print("json文件格式错误！")
+                    print("json decode error!")
                 except Exception as e:
                     print(e)
             except Exception as e:
-                print("h5文件内容读取失败！", e)
-    _dump_neb_movie_json(raw)
+                print(e)
+
+    new = []
+    if dst is not None:
+        abs_dst = os.path.abspath(dst)
+        os.makedirs(abs_dst, exist_ok=True)
+        new.append(f"{abs_dst}/{raw[0]}")
+        for i in range(1, len(raw)):
+            new.append(raw[i])
+        _dump_neb_chain_json(new)
+    else:
+        _dump_neb_chain_json(raw)
 
 
-def write_xyz(preview: bool = False, directory: str = ".", step: int = -1):
-    """
+def write_xyz(
+    preview: bool = False, directory: str = ".", step: int = -1, dst: str = None
+):
+    DeprecationWarning("Please use write_xyz_chain() instead")
+    write_xyz_chain(preview=preview, directory=directory, step=step, dst=dst)
+
+
+def write_xyz_chain(
+    preview: bool = False, directory: str = ".", step: int = -1, dst: str = None
+):
+    r"""
     将NEB结构链条写成xyz轨迹文件用于可视化
 
     Parameters
     ----------
     preview : bool
         是否预览模式，默认否
     directory : str
         计算结果所在目录. 默认当前路径
     step: int
         离子步编号. 默认-1，读取整个NEB计算过程信息。
         0表示初插结构（未完成离子步）；
-        1表示第一个离子步，以此类推。
+        1表示第一个离子步，以此类推
+    dst : str
+        保存路径，默认为directory
 
     Examples
     ----------
-    >>> from dspawpy.diffusion.nebtools import write_xyz
-    >>> write_xyz(directory='/data/home/hzw1002/dspawpy_repo/test/2.15')
-    正在读取最后一个离子步信息...
-    --> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_movie_last.xyz 写入成功！
-    <BLANKLINE>
+    >>> from dspawpy.diffusion.nebtools import write_xyz_chain
+    >>> write_xyz_chain(directory='/data/home/hzw1002/dspawpy_repo/test/2.15')
+    ==> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/neb_chain_last.xyz
     """
-
-    if preview:  # preview mode, write neb_movie_init.xyz from structure.as
-        print("正在根据初插结构保存neb_movie_init.xyz...")
+    absdir = os.path.abspath(directory)
+    if preview:  # preview mode, write neb_chain_init.xyz from structure.as
         try:
-            raw = _from_structures(directory)
+            raw = _from_structures(absdir)
         except FileNotFoundError:
-            print("未找到初始插值结构！")
+            print("No structure file")
         except Exception as e:
-            print("初始插值结构读取失败！", e)
+            print(e)
     else:
         if step == 0:  # try preview mode to save time
             try:
-                raw = _from_structures(directory)
+                raw = _from_structures(absdir)
             except FileNotFoundError:
-                print("未找到初始插值结构，将从计算结果h5或json文件中读取！")
+                print("No structure file")
             except Exception as e:
-                print("初始插值结构读取失败！", e)
+                print(e)
         else:
             try:  # read from h5 file
-                raw = _from_h5(directory, step)
+                raw = _from_h5(absdir, step)
             except FileNotFoundError:
                 try:  # read from json file
-                    raw = _from_json(directory, step)
+                    raw = _from_json(absdir, step)
                 except json.decoder.JSONDecodeError:
-                    print("json文件格式错误！")
+                    print("json decode error!")
                 except Exception as e:
                     print(e)
             except Exception as e:
-                print("h5文件内容读取失败！", e)
-    _dump_neb_xyz(raw)
+                print(e)
+    new = []
+    if dst is not None:
+        abs_dst = os.path.abspath(dst)
+        os.makedirs(abs_dst, exist_ok=True)
+        new.append(f"{abs_dst}/{raw[0]}")
+        for i in range(1, len(raw)):
+            new.append(raw[i])
+        _dump_neb_xyz(new)
+    else:
+        _dump_neb_xyz(raw)
 
 
 def _dump_neb_xyz(raw):
     """根据之前收集到的各数据列表，dump json文件到output"""
     (
         output,
         subfolders,
@@ -768,16 +779,17 @@
         maxForces,
         tangents,
         iDirects,
     ) = raw
 
     # 写入文件
     xyzfile = output[:-5] + ".xyz"
+    absout = os.path.abspath(xyzfile)
     Nstep = len(subfolders)  # 选定离子步，展示构型链
-    with open(xyzfile, "w") as f:
+    with open(absout, "w") as f:
         # Nstep
         for n in range(Nstep):
             eles = Elems[n]  # 针对每个构型
             # 原子数不会变，就是不合并的元素总数
             f.write("%d\n" % len(eles))
             # lattice
             f.write(
@@ -796,68 +808,70 @@
             )
             # position and element
             for i in range(len(eles)):
                 f.write(
                     "%s %f %f %f\n"
                     % (eles[i], Poses[n, i, 0], Poses[n, i, 1], Poses[n, i, 2])
                 )
-    print(f"--> {os.path.abspath(xyzfile)} 写入成功！\n")
+    print(f"==> {absout}")
 
 
 def _from_structures(directory: str):
     """从structure00.as，structure01.as，...，中读取结构信息，
-    写入neb_movie_init，以便用DeviceStudio打开观察
+    写入neb_chain_init，以便用DeviceStudio打开观察
 
     Parameters
     ----------
     directory : str
         NEB计算路径，默认当前路径
 
     Returns
     -------
     用于json文件的各个数组
     """
-    output = "neb_movie_init.json"
+    absdir = os.path.abspath(directory)
+    output = "neb_chain_init.json"
     step = 0
 
-    subfolders = get_neb_subfolders(directory)
-    # print(subfolders)
+    subfolders = get_neb_subfolders(absdir)
     nimage = len(subfolders)
     reactionCoordinates = np.zeros(shape=nimage)  # optional
     totalEnergies = np.zeros(shape=nimage)  # optional
     maxForces = np.zeros(shape=nimage - 2)  # optional
     tangents = np.zeros(shape=nimage - 2)  # optional
     MaxForces = np.zeros(shape=(nimage - 2, step + 1))  # optional
     TotalEnergies = np.zeros(shape=(nimage - 2, step + 1))  # optional
 
     Poses = []  # nimage x Natom x 3 , read
     Elems = []  # nimage x Natom, read
     Latvs = []  # nimage x 9, read
 
     iDirects = []  # read coordinate type
     for i, folder in enumerate(subfolders):
-        structure_path = os.path.join(directory, folder, f"structure{folder}.as")
-        if not os.path.exists(structure_path):
-            raise FileNotFoundError(f"请检查{structure_path}是否存在！")
-        structure = build_Structures_from_datafile(structure_path)[0]
+        structure_path = os.path.join(absdir, folder, f"structure{folder}.as")
+        if not os.path.isfile(structure_path):
+            raise FileNotFoundError(f"No {structure_path}！")
+        structure = build_Structures_from_datafile(structure_path, task="free")[0]
         pos = structure.cart_coords
         ele = [str(i) for i in structure.species]
         lat = structure.lattice.matrix
         Poses.append(pos)
         Elems.append(ele)
         Latvs.append(lat)
         with open(structure_path, "r") as f:
             lines = f.readlines()
             coordinateType = lines[6].split()[0]
             if coordinateType == "Direct":
                 iDirect = True
             elif coordinateType == "Cartesian":
                 iDirect = False
             else:
-                raise ValueError(f"请检查{structure_path}中的坐标类型！")
+                raise ValueError(
+                    f"coordinateType in {structure_path} is neither Direct nor Cartesian!"
+                )
             iDirects.append(iDirect)
     Natom = len(Elems[0])
 
     # reshape data
     Poses = np.array(Poses).reshape((nimage, Natom, 3))
     Elems = np.array(Elems).reshape((nimage, Natom))
     Latvs = np.array(Latvs).reshape((nimage, 9))
@@ -894,43 +908,45 @@
     step : int
         step数，默认-1，读取最后一个构型
 
     Returns
     -------
     用于json文件的各个数组
     """
+    absdir = os.path.abspath(directory)
     # ^ 前期设置
-    neb_h5 = os.path.join(directory, "01", "neb01.h5")
+    neb_h5 = os.path.abspath(os.path.join(absdir, "01", "neb01.h5"))
     ele = get_ele_from_h5(hpath=neb_h5)
     Natom = len(ele)
     data = h5py.File(neb_h5)
     try:
         total_steps = np.array(data.get("/NebSize"))[0]
     except:
-        print("NEB计算未正常结束，正在尝试实时读取结构信息...")
+        print("Reading latest info for unfinished NEB task...")
         try:
             total_steps = np.array(data.get("/Structures/FinalStep"))[0]
         except:
-            raise ValueError("尚未完成第一个离子步，请检查计算是否出错，否则请耐心等待离子步完成至少一个后再尝试读取！")
+            raise ValueError(
+                f"No finished ionic step detected, please check {neb_h5} file or wait for NEB task to finished at least one ionic step."
+            )
 
     if step == -1:
-        output = "neb_movie_last.json"
+        output = "neb_chain_last.json"
         step = total_steps
-        print("正在读取最后一个离子步信息...")
     elif step > total_steps:
-        output = "neb_movie_last.json"
+        output = "neb_chain_last.json"
         step = total_steps
-        print(f"指定的step数大于NEB计算实际完成的总离子步数{total_steps}")
-        print("正在读取最后一个离子步信息...")
+        warnings.warn(
+            "specified %s > %s, reading last step info..." % (step, total_steps)
+        )
     else:
-        output = "neb_movie_{}.json".format(step)
-        print(f"正在读取第{step}个离子步信息...")
+        output = "neb_chain_{}.json".format(step)
 
     # ^ 读取前，准备好json文件所需数组框架
-    subfolders = get_neb_subfolders(directory)
+    subfolders = get_neb_subfolders(absdir)
     nimage = len(subfolders)
     reactionCoordinates = np.zeros(shape=nimage)  # optional
     totalEnergies = np.zeros(shape=nimage)  # optional，每个构型最终能量
     maxForces = np.zeros(shape=nimage - 2)  # optional
     tangents = np.zeros(shape=nimage - 2)  # optional
     MaxForces = np.zeros(shape=(nimage - 2, step))  # optional
     TotalEnergies = np.zeros(shape=(nimage - 2, step))  # optional，中间构型每个离子步能量
@@ -943,60 +959,60 @@
     for folder in subfolders:
         """如果是首尾两个构型，最多只有scf.h5文件，没有neb.h5文件
         用户如果算NEB的时候，不计算首尾构型的自洽，
          或者在别处算完了但是没有复制到首尾文件夹中并命名为scf.h5，
           便不能使用第一个功能
         """
         if folder == subfolders[0] or folder == subfolders[-1]:
-            h5_path = os.path.join(directory, folder, "scf.h5")
-            spath = os.path.join(directory, folder, f"structure{folder}.as")
-            assert os.path.exists(h5_path) or os.path.exists(
+            h5_path = os.path.join(absdir, folder, "scf.h5")
+            spath = os.path.join(absdir, folder, f"structure{folder}.as")
+            assert os.path.isfile(h5_path) or os.path.isfile(
                 spath
-            ), f"请确认{h5_path}或{spath}至少存在一个！"
+            ), f"{h5_path} and {spath} are both missing!"
         else:
-            h5_path = os.path.join(directory, folder, f"neb{folder}.h5")
-            assert os.path.exists(h5_path), f"请确认{h5_path}是否存在！"
+            h5_path = os.path.join(absdir, folder, f"neb{folder}.h5")
+            assert os.path.isfile(h5_path), f"No {h5_path}!"
 
     # ^ 开始分功能读取数据
     for i, folder in enumerate(subfolders):
         if folder == subfolders[0] or folder == subfolders[-1]:
-            h5_path = os.path.join(directory, folder, "scf.h5")
-            if os.path.exists(h5_path):
+            h5_path = os.path.join(absdir, folder, "scf.h5")
+            if os.path.isfile(h5_path):
                 data = h5py.File(h5_path)
                 # 不影响可视化，直接定为0
                 if folder == subfolders[0]:
                     reactionCoordinates[i] = 0
                 pos = np.array(data.get("/Structures/Step-1/Position")).reshape(
                     -1, 3
                 )  # scaled
                 lat = np.array(data.get("/Structures/Step-1/Lattice"))
                 ele = get_ele_from_h5(hpath=h5_path)
                 totalEnergies[i] = np.array(data.get("/Energy/TotalEnergy0"))
             else:
-                structure = build_Structures_from_datafile(spath)[0]
+                structure = build_Structures_from_datafile(spath, task="neb")[0]
                 pos = structure.frac_coords
                 ele = [str(i) for i in structure.species]
                 lat = structure.lattice.matrix
         else:
-            h5_path = os.path.join(directory, folder, f"neb{folder}.h5")
+            h5_path = os.path.join(absdir, folder, f"neb{folder}.h5")
             data = h5py.File(h5_path)
             # reading...
             try:
                 reactionCoordinates[i - 1] = np.array(data.get("/Distance/Previous"))[
                     -1
                 ]
                 maxForces[i - 1] = np.array(data.get("/MaxForce"))[-1]
                 tangents[i - 1] = np.array(data.get("/Tangent"))[-1]
                 if folder == subfolders[-2]:
                     reactionCoordinates[i + 1] = np.array(data.get("/Distance/Next"))[
                         -1
                     ]
                 # read MaxForces and TotalEnergies
                 nionStep = np.array(data.get("/MaxForce")).shape[0]
-                assert step <= nionStep, f"总共只完成了{nionStep}个离子步!"
+                assert step <= nionStep, f"The number of finished ionic steps is {nionStep}"
                 for j in range(step):
                     MaxForces[i - 1, j] = np.array(data.get("/MaxForce"))[j]
                     TotalEnergies[i - 1, j] = np.array(data.get("/TotalEnergy"))[j]
                 totalEnergies[i] = np.array(data.get("/Energy/TotalEnergy0"))
             except:
                 pass  # 还没完成NEB计算，不影响读取结构信息用于可视化
             # read the latest structure for visualization
@@ -1006,27 +1022,27 @@
             lat = np.array(data.get(f"/Structures/Step-{step}/Lattice"))
             ele = get_ele_from_h5(hpath=h5_path)
 
         Elems.append(ele)
         Sposes[i, :, :] = pos
         Latvs.append(lat)
 
-    if os.path.exists(os.path.join(directory, "neb.h5")):
-        tdata = h5py.File(os.path.join(directory, "neb.h5"))
+    if os.path.isfile(os.path.join(absdir, "neb.h5")):
+        tdata = h5py.File(os.path.join(absdir, "neb.h5"))
         # atom fix, not lattice
         # ignore this trivial message because it is not necessary for the visualization
         if "/UnrelaxStructure/Image00/Fix" in tdata:
             fix_array = np.array(tdata.get("/UnrelaxStructure/Image00/Fix"))
             for fix in fix_array:
                 if fix == 0.0:
                     F = False
                 elif fix == 1.0:
                     F = True
                 else:
-                    raise ValueError("Fix值只能为0或1")
+                    raise ValueError("Fix must be 0/1")
                 Fixs.append(F)
         else:
             Fixs = np.full(shape=(Natom, 3), fill_value=False)
     else:
         Fixs = np.full(shape=(Natom, 3), fill_value=False)
 
     Elems = np.array(Elems).reshape((nimage, Natom))
@@ -1064,35 +1080,35 @@
         step数，默认-1，读取最后一个构型
 
     Returns
     -------
     用于json文件的各个数组
     """
 
+    absdir = os.path.abspath(directory)
     # ^ 前期设置
-    neb_js = os.path.join(directory, "01/neb01.json")
+    neb_js = os.path.join(absdir, "01/neb01.json")
     with open(neb_js, "r") as f:
         data = json.load(f)
     total_steps = len(data)
 
     if step == -1:
-        output = "neb_movie_last.json"
+        output = "neb_chain_last.json"
         step = total_steps
-        print("正在读取最后一个离子步信息（h5文件不存在，尝试从json文件读取数据）...")
     elif step > total_steps:
-        output = "neb_movie_last.json"
+        output = "neb_chain_last.json"
         step = total_steps
-        print(f"您指定的step数大于NEB计算实际完成的总离子步数{total_steps}")
-        print("正在读取最后一个离子步信息（h5文件不存在，尝试从json文件读取数据）...")
+        warnings.warn(
+            f"specified %s > %s, reading last step info..." % (step, total_steps)
+        )
     else:
-        output = f"neb_movie_{step}.json"
-        print(f"正在读取第{step}个离子步信息...")
+        output = f"neb_chain_{step}.json"
 
     # ^ 读取前，准备好json文件所需数组框架
-    subfolders = get_neb_subfolders(directory)
+    subfolders = get_neb_subfolders(absdir)
     nimage = len(subfolders)
     reactionCoordinates = np.zeros(shape=nimage)  # optional
     totalEnergies = np.zeros(shape=nimage)  # optional，每个构型最终能量
     maxForces = np.zeros(shape=nimage - 2)  # optional
     tangents = np.zeros(shape=nimage - 2)  # optional
     MaxForces = np.zeros(shape=(nimage - 2, step))  # optional
     TotalEnergies = np.zeros(shape=(nimage - 2, step))  # optional，中间构型每个离子步能量
@@ -1104,70 +1120,67 @@
     for folder in subfolders:
         """如果是首尾两个构型，最多只有system.json文件，没有neb*.json文件
         用户如果算NEB的时候，不计算首尾构型的自洽，
          或者在别处算完了但是没有复制到首尾文件夹中并命名为system.json，
           便不能使用第一个功能
         """
         if folder == subfolders[0] or folder == subfolders[-1]:
-            js_path = os.path.join(directory, folder, "system.json")
+            js_path = os.path.join(absdir, folder, "system.json")
         else:
-            js_path = os.path.join(directory, folder, f"neb{folder}.json")
-        assert os.path.exists(js_path), f"请确认{js_path}是否存在！"
+            js_path = os.path.join(absdir, folder, f"neb{folder}.json")
+        assert os.path.isfile(js_path), f"No {js_path}"
 
     # ^ 开始分功能读取数据
     for i, folder in enumerate(subfolders):
         if i == 0:  # 初末态在NEB计算过程中不会优化结构
             # 1. 外部自洽后移动system.json
-            js_path = os.path.join(directory, folder, "system.json")
+            js_path = os.path.join(absdir, folder, "system.json")
             # 2. 直接NEB计算，得到system00.json
-            neb_js_path = os.path.join(directory, folder, f"system{folder}.json")
-            if os.path.exists(neb_js_path):  # 优先读取neb计算得到的system00.json
+            neb_js_path = os.path.join(absdir, folder, f"system{folder}.json")
+            if os.path.isfile(neb_js_path):  # 优先读取neb计算得到的system00.json
                 with open(neb_js_path, "r") as f:
                     data = json.load(f)
 
-            elif os.path.exists(js_path):
+            elif os.path.isfile(js_path):
                 with open(js_path, "r") as f:
                     data = json.load(f)
 
             else:
-                raise FileNotFoundError(
-                    f"{os.path.abspath(js_path)}和{os.path.abspath(neb_js_path)}均不存在！"
-                )
+                raise FileNotFoundError(f"No {js_path}/{neb_js_path}")
 
             lat = data["AtomInfo"]["Lattice"]
             Latvs.append(lat)
 
             Natom = len(data["AtomInfo"]["Atoms"])  # 读取原子数
             for j in range(Natom):
                 pos = data["AtomInfo"]["Atoms"][j]["Position"]  # scaled
                 Sposes.append(pos)
 
             totalEnergies[i] = data["Energy"]["TotalEnergy0"]
             reactionCoordinates[i] = 0.0
 
         elif i > 0 and i < nimage - 1:  # 中间构型会优化结构
             # 读取晶胞矢量、原子坐标
-            relax_json = os.path.join(directory, folder, "relax.json")
-            assert os.path.exists(relax_json), f"{relax_json}不存在！"
+            relax_json = os.path.join(absdir, folder, "relax.json")
+            assert os.path.isfile(relax_json), f"No {relax_json}!"
 
             with open(relax_json, "r") as f:
                 rdata = json.load(f)
 
             lat = rdata[step - 1]["Lattice"]  # 第step步优化后的晶胞
             Latvs.append(lat)
 
             Natom = len(rdata[0]["Atoms"])
             for j in range(Natom):  # for each atom
                 pos = rdata[step - 1]["Atoms"][j]["Position"]  # 第step步优化后的原子坐标
                 Sposes.append(pos)  # ! 输出的都是分数坐标
 
             # 读取能量和反应坐标
-            nj = os.path.join(directory, folder, f"neb{folder}.json")
+            nj = os.path.join(absdir, folder, f"neb{folder}.json")
             with open(nj, "r") as f:
-                print(f"Reading {os.path.abspath(nj)}...")
                 ndata = json.load(f)
 
             totalEnergies[i] = ndata[step - 1]["TotalEnergy"]  # 读取第step步优化后的能量
 
             # 读取与前一个构型相比的反应坐标
             reactionCoordinates[i - 1] = ndata[step - 1]["ReactionCoordinate"][-2]
             tangents[i - 1] = ndata[step - 1]["Tangent"]
@@ -1175,42 +1188,40 @@
                 reactionCoordinates[i + 1] = ndata[step - 1]["ReactionCoordinate"][-1]
             for j in range(step):
                 MaxForces[i - 1, j] = ndata[j]["MaxForce"]
                 # neb01.json中不存在TotalEnergy0，暂时读取TotalEnergy
                 TotalEnergies[i - 1, j] = ndata[j]["TotalEnergy"]
 
         else:  # 末态构型
-            js_path = os.path.join(directory, folder, "system.json")
-            neb_js_path = os.path.join(directory, folder, f"system{folder}.json")
-            if os.path.exists(neb_js_path):  # 优先读取neb计算得到的json文件
+            js_path = os.path.join(absdir, folder, "system.json")
+            neb_js_path = os.path.join(absdir, folder, f"system{folder}.json")
+            if os.path.isfile(neb_js_path):  # 优先读取neb计算得到的json文件
                 with open(neb_js_path, "r") as f:
                     data = json.load(f)
 
-            elif os.path.exists(js_path):
+            elif os.path.isfile(js_path):
                 with open(js_path, "r") as f:
                     data = json.load(f)
 
             else:
-                raise FileNotFoundError(
-                    f"{os.path.abspath(js_path)}和{os.path.abspath(neb_js_path)}均不存在！"
-                )
+                raise FileNotFoundError(f"No {js_path}/{neb_js_path}")
 
             lat = data["AtomInfo"]["Lattice"]
             Latvs.append(lat)
 
             Natom = len(data["AtomInfo"]["Atoms"])  # 读取原子数
             for j in range(Natom):
                 pos = data["AtomInfo"]["Atoms"][j]["Position"]  # scaled
                 Sposes.append(pos)
 
             energy = data["Energy"]["TotalEnergy0"]
             totalEnergies[i] = energy
 
     # 读取原子元素
-    tneb_js = os.path.join(directory, "neb.json")
+    tneb_js = os.path.join(absdir, "neb.json")
     with open(tneb_js, "r") as f:
         tdata = json.load(f)
 
     Natom = len(tdata["UnrelaxStructure"][0]["Atoms"])
     elems = []
     for k in range(Natom):
         ele = tdata["UnrelaxStructure"][0]["Atoms"][k]["Element"]
@@ -1225,15 +1236,15 @@
             fix_array = [0.0, 0.0, 0.0]
         for fix in fix_array:
             if fix == 0.0:
                 F = False
             elif fix == 1.0:
                 F = True
             else:
-                raise ValueError("Fix值只能为 0.0 或 1.0")
+                raise ValueError("Fix should be 0.0/1.0 in json file!")
             Fixs.append(F)
 
     # 累加reactionCoordinates中的元素
     for i in range(1, len(reactionCoordinates)):
         reactionCoordinates[i] += reactionCoordinates[i - 1]
 
     # reshape data
@@ -1257,15 +1268,15 @@
         totalEnergies,
         maxForces,
         tangents,
         iDirects,
     )
 
 
-def _dump_neb_movie_json(raw):
+def _dump_neb_chain_json(raw):
     """根据之前收集到的各数据列表，dump json文件到output"""
     (
         output,
         subfolders,
         step,
         MaxForces,
         TotalEnergies,
@@ -1333,21 +1344,22 @@
         "Force": {"MaxForce": maxForces.tolist(), "Tangent": tangents.tolist()},
         "Iteration": IterDict,
         "RelaxedStructure": RSList,
         "UnrelaxedStructure": URSList,
     }
 
     # ^ 将字典写入json文件
-    with open(output, "w") as f:
+    absout = os.path.abspath(output)
+    with open(absout, "w") as f:
         json.dump(data, f, indent=4)
 
-    print(f"--> {os.path.abspath(output)} 写入成功！")
+    print(f"==> {absout}")
 
 
-def _getef(directory: str = "."):
+def _getef(directory: str = ".") -> list:
     """读取NEB计算时各构型的能量和受力，NEB计算可以未收敛
     但如果初末态自洽在别处完成，请手动将其移入00等文件夹中！
 
     Parameters
     ----------
     directory: str
         NEB计算的路径，默认当前路径
@@ -1361,128 +1373,238 @@
     rcs: list
         反应坐标列表
     ens: list
         电子总能列表
     dEs: list
         与初始构型的能量差列表
     """
-
-    subfolders = get_neb_subfolders(directory)
+    absdir = os.path.abspath(directory)
+    subfolders = get_neb_subfolders(absdir)
     Nimage = len(subfolders)
 
     ens = []
     dEs = np.zeros(Nimage)
     rcs = [0]
     mfs = []
 
     # read energies
     count = 1
     for i, subfolder in enumerate(subfolders):
         if i == 0 or i == Nimage - 1:
-            jsf = os.path.join(directory, subfolder, f"system{subfolder}.json")
-            old_jsf = os.path.join(directory, subfolder, "system.json")
-            hf = os.path.join(directory, subfolder, "scf.h5")
+            jsf = os.path.join(absdir, subfolder, f"system{subfolder}.json")
+            old_jsf = os.path.join(absdir, subfolder, "system.json")
+            hf = os.path.join(absdir, subfolder, "scf.h5")
 
-            if os.path.exists(hf):  # 优先读取h5文件内容
+            if os.path.isfile(hf):  # 优先读取h5文件内容
                 data = h5py.File(hf)
                 en = np.array(data.get("/Energy/TotalEnergy0"))[0]
                 if i == 0 or i == Nimage - 1:
                     mf = np.max(np.abs(np.array(data.get("/Force/ForceOnAtoms"))))
                     mfs.append(mf)
 
-            elif os.path.exists(jsf):  # 其次读取json文件内容
+            elif os.path.isfile(jsf):  # 其次读取json文件内容
                 with open(jsf, "r") as f:
                     data = json.load(f)
                 en = data["Energy"]["TotalEnergy0"]
                 if i == 0 or i == Nimage - 1:
                     mf = np.max(np.abs(data["Force"]["ForceOnAtoms"]))
                     mfs.append(mf)
 
-            elif os.path.exists(old_jsf):  # 兼容老json
+            elif os.path.isfile(old_jsf):  # 兼容老json
                 with open(old_jsf, "r") as f:
                     data = json.load(f)
                 en = data["Energy"]["TotalEnergy0"]
                 if i == 0 or i == Nimage - 1:
                     mf = np.max(np.abs(data["Force"]["ForceOnAtoms"]))
                     mfs.append(mf)
 
             else:
-                raise FileNotFoundError(
-                    "无法找到记录构型%s的能量和受力的system.json或scf.h5文件" % subfolder
-                )
+                raise FileNotFoundError(f"No {jsf}/{old_jsf}/{hf} for {subfolder}")
             ens.append(en)
 
         else:
-            jsf = os.path.join(directory, subfolder, f"neb{subfolder}.json")
-            sysjsf = os.path.join(directory, subfolder, f"system{subfolder}.json")
-            old_sysjsf = os.path.join(directory, subfolder, "system.json")
-            hf = os.path.join(directory, subfolder, f"neb{subfolder}.h5")
+            jsf = os.path.join(absdir, subfolder, f"neb{subfolder}.json")
+            sysjsf = os.path.join(absdir, subfolder, f"system{subfolder}.json")
+            old_sysjsf = os.path.join(absdir, subfolder, "system.json")
+            hf = os.path.join(absdir, subfolder, f"neb{subfolder}.h5")
 
-            if os.path.exists(hf):  # 优先读取h5文件内容
+            if os.path.isfile(hf):  # 优先读取h5文件内容
                 data = h5py.File(hf)
                 en = np.array(data.get("/Energy/TotalEnergy0"))[0]
                 mf = np.array(data.get("/MaxForce"))[-1]
                 # the key may change depends on your DS-PAW version
                 if "/Distance/Previous" in data:
                     rc = np.array(data.get("/Distance/Previous"))[-1]
                 elif "/ReactionCoordinate" in data:
                     rc = np.array(data.get("/ReactionCoordinate"))[-2]
                 else:
-                    raise KeyError("找不到/Distance/Previous或/ReactionCoordinate键！")
+                    raise KeyError(
+                        f"Neither /Distance/Previous nor /ReactionCoordinate in {hf}"
+                    )
                 rcs.append(rc)
                 if count == Nimage - 2:  # before final image
                     if "/Distance/Next" in data:
                         rc = np.array(data.get("/Distance/Next"))[-1]
                     elif "/ReactionCoordinate" in data:
                         rc = np.array(data.get("/ReactionCoordinate"))[-1]
                     else:
-                        raise KeyError("找不到/Distance/Next或/ReactionCoordinate键！")
+                        raise KeyError(
+                            f"Neither /Distance/Next nor /ReactionCoordinate in {hf}"
+                        )
                     rcs.append(rc)
 
-            elif os.path.exists(jsf):
-                if os.path.exists(sysjsf):
+            elif os.path.isfile(jsf):
+                if os.path.isfile(sysjsf):
                     with open(sysjsf, "r") as f:
                         data = json.load(f)
                     en = data["Energy"]["TotalEnergy0"]
-                elif os.path.exists(old_sysjsf):  # 兼容旧版DS-PAW
+                elif os.path.isfile(old_sysjsf):  # 兼容旧版DS-PAW
                     with open(old_sysjsf, "r") as f:
                         data = json.load(f)
                     en = data["Energy"]["TotalEnergy0"]
                 else:
-                    raise FileNotFoundError(f"无法找到{sysjsf}或{old_sysjsf}")
+                    raise FileNotFoundError(f"No {sysjsf}/{old_sysjsf}")
 
                 with open(jsf, "r") as f:
                     data = json.load(f)
                 Nion_step = len(data)
                 # en = data[Nion_step - 1]["TotalEnergy"] # invalid
                 mf = data[Nion_step - 1]["MaxForce"]  # 最后一步的最大受力
                 rc = data[Nion_step - 1]["ReactionCoordinate"][0]  # 最后一步的反应坐标
                 rcs.append(rc)
                 if count == Nimage - 2:  # before final image
                     rc = data[Nion_step - 1]["ReactionCoordinate"][1]  # 最后一步的反应坐标
                     rcs.append(rc)
 
             else:
-                raise FileNotFoundError(f"无法找到{hf}或{jsf}")
+                raise FileNotFoundError(f"No {hf}/{jsf}")
 
             ens.append(en)
             mfs.append(mf)
 
             # get dE
             dE = ens[count] - ens[0]
             dEs[i] = dE
             count += 1
     dEs[-1] = ens[Nimage - 1] - ens[0]
 
-    # rcs 改成累加值
+    # 从 nebXX.h5/json 读取的 rcs 需要改成累加值
     for i in range(1, len(rcs)):
         rcs[i] += rcs[i - 1]
 
     rcs = np.array(rcs)
 
     resort_mfs = [mfs[0]]
     final_mf = mfs[1]
     for j in range(2, len(mfs)):
         resort_mfs.append(mfs[j])
     resort_mfs.append(final_mf)
 
     return subfolders, resort_mfs, rcs, ens, dEs
+
+def plot_barrier_old(
+    datafile: str = "neb.h5",
+    directory: str = None,
+    ri: float = None,
+    rf: float = None,
+    ei: float = None,
+    ef: float = None,
+    method: str = "PchipInterpolator",
+    figname: str = "neb_barrier.png",
+    show: bool = True,
+    raw=False,
+    **kwargs,
+):
+    r"""与plot_barrier()唯一的区别在于反应坐标视为累加值，而不是单个值
+    """
+    if directory is not None:
+        # read data
+        subfolders, resort_mfs, rcs, ens, dEs = _getef(os.path.abspath(directory))
+
+    elif datafile:
+        absfile = get_absfile(datafile, task="neb")  # -> return either .h5 or .json
+        if absfile.endswith(".h5"):
+            from dspawpy.io.read import load_h5
+
+            neb = load_h5(absfile)
+            if "/BarrierInfo/ReactionCoordinate" in neb.keys():
+                reaction_coordinate = neb["/BarrierInfo/ReactionCoordinate"]
+                energy = neb["/BarrierInfo/TotalEnergy"]
+            else:  # old version
+                reaction_coordinate = neb["/Distance/ReactionCoordinate"]
+                energy = neb["/Energy/TotalEnergy"]
+        elif absfile.endswith(".json"):
+            with open(absfile, "r") as fin:
+                neb = json.load(fin)
+            if "BarrierInfo" in neb.keys():
+                reaction_coordinate = neb["BarrierInfo"]["ReactionCoordinate"]
+                energy = neb["BarrierInfo"]["TotalEnergy"]
+            else:  # old version
+                reaction_coordinate = neb["Distance"]["ReactionCoordinate"]
+                energy = neb["Energy"]["TotalEnergy"]
+
+        x = []
+        for c in reaction_coordinate:
+            if len(x) > 0: # add previous reaction coordinate
+                x.append(x[-1] + c)
+            else:
+                x.append(c)
+
+        y = [x - energy[0] for x in energy]
+        # initial and final info
+        if ri is not None:  # add initial reaction coordinate
+            x.insert(0, ri)
+        if rf is not None:  # add final reaction coordinate
+            x.append(rf)
+
+        if ei is not None:  # add initial energy
+            y.insert(0, ei)
+        if ef is not None:  # add final energy
+            y.append(ef)
+
+        rcs = np.array(x)
+        dEs = np.array(y)
+
+    else:
+        raise ValueError("Please specify directory or datafile!")
+
+    # import scipy interpolater
+    try:
+        interpolate_method = getattr(
+            __import__("scipy.interpolate", fromlist=[method]), method
+        )
+    except:
+        raise ImportError(f"No scipy.interpolate.{method} method！")
+    # call the interpolater to interpolate with given kwargs
+    try:
+        inter_f = interpolate_method(rcs, dEs, **kwargs)
+    except:
+        raise ValueError(f"Please check whether {kwargs} is valid for {method}！")
+
+    xnew = np.linspace(rcs[0], rcs[-1], 100)
+    ynew = inter_f(xnew)
+
+    if raw:
+        pd.DataFrame({"x_raw": rcs, "y_raw": dEs}).to_csv("raw_xy.csv", index=False)
+        pd.DataFrame({"x_interpolated": xnew, "y_interpolated": ynew}).to_csv(
+            "raw_interpolated_xy.csv", index=False
+        )
+
+    # plot
+    if kwargs:
+        plt.plot(xnew, ynew, label=method + str(kwargs))
+    else:
+        plt.plot(xnew, ynew, label=method)
+    plt.scatter(rcs, dEs, c="r")
+    plt.xlabel("Reaction Coordinate (Å)")
+    plt.ylabel("Energy (eV)")
+    plt.legend()
+
+    plt.tight_layout()
+    # save and show
+    if figname:
+        absfig = os.path.abspath(figname)
+        os.makedirs(os.path.dirname(absfig), exist_ok=True)
+        plt.savefig(absfig, dpi=300)
+        print(f"==> {absfig}")
+    if show:
+        plt.show()
```

## dspawpy/io/read.py

```diff
@@ -1,14 +1,16 @@
 # -*- coding: utf-8 -*-
 import json
 import os
 import re
+import warnings
 
 import h5py
 import numpy as np
+from dspawpy.io.utils import get_absfile
 from pymatgen.core.lattice import Lattice
 from pymatgen.core.structure import Structure
 from pymatgen.electronic_structure.bandstructure import BandStructureSymmLine
 from pymatgen.electronic_structure.core import Orbital, Spin
 from pymatgen.electronic_structure.dos import CompleteDos, Dos
 from pymatgen.phonon.bandstructure import PhononBandStructureSymmLine
 from pymatgen.phonon.dos import PhononDos
@@ -21,15 +23,16 @@
     zero_to_efermi: bool = False,
 ) -> BandStructureSymmLine:
     """读取h5或json文件中的能带数据，构建BandStructureSymmLine对象
 
     Parameters
     ----------
     band_dir : str
-        能带文件路径，band.h5 / band.json
+        - 能带文件路径，band.h5 / band.json 或包含band.h5 / band.json的文件夹
+        - 注意，wannier.h5 也可以使用此函数读取，但band_dir不支持文件夹类型
     syst_dir : str
         system.json 路径，仅为辅助处理 Wannier 数据而准备（从中读取结构和费米能级）
     efermi : float, optional
         费米能级，如果h5文件中的费米能级不正确，可以通过此参数指定费米能级
     zero_to_efermi : bool, optional
         是否将费米能级移动到0
 
@@ -46,17 +49,19 @@
 
     >>> band = get_band_data(band_dir='/data/home/hzw1002/dspawpy_repo/test/2.30/wannier.json', syst_dir='/data/home/hzw1002/dspawpy_repo/test/2.30/system.json')
     """
     if efermi is not None and zero_to_efermi:
         raise ValueError(
             "efermi and zero_to_efermi should not be set at the same time!"
         )
-    if band_dir.endswith(".h5"):
-        band = load_h5(band_dir)
-        raw = h5py.File(band_dir, "r").keys()
+
+    absfile = get_absfile(band_dir, task="band")  # give wannier.h5 also works
+    if absfile.endswith(".h5"):
+        band = load_h5(absfile)
+        raw = h5py.File(absfile, "r").keys()
         if "/WannBandInfo/NumberOfBand" in raw:
             (
                 structure,
                 kpoints,
                 eigenvals,
                 rEf,
                 labels_dict,
@@ -70,16 +75,16 @@
                 rEf,
                 labels_dict,
                 projections,
             ) = _get_band_data_h5(band, iwan=False, zero_to_efermi=zero_to_efermi)
         else:
             print("BandInfo or WannBandInfo key not found in h5file!")
             return
-    elif band_dir.endswith(".json"):
-        with open(band_dir, "r") as fin:
+    elif absfile.endswith(".json"):
+        with open(absfile, "r") as fin:
             band = json.load(fin)
         if "WannBandInfo" in band.keys():
             assert (
                 syst_dir is not None
             ), "system.json is required for processing wannier band info!"
             with open(syst_dir) as system_json:
                 syst = json.load(system_json)
@@ -99,18 +104,19 @@
                 kpoints,
                 eigenvals,
                 rEf,
                 labels_dict,
                 projections,
             ) = _get_band_data_json(band, iwan=False, zero_to_efermi=zero_to_efermi)
         else:
-            print(f"BandInfo or WannBandInfo key not found in {band_dir} file!")
-            return
+            raise ValueError(
+                f"BandInfo or WannBandInfo key not found in {absfile} file!"
+            )
     else:
-        raise TypeError(f"{os.path.abspath(band_dir)} must be h5 or json file!")
+        raise TypeError(f"{absfile} must be h5 or json file!")
 
     if efermi:  # 从h5直接读取的费米能级可能是错的，此时需要用户自行指定
         rEf = efermi  # 这只是个临时解决方案
 
     lattice_new = Lattice(structure.lattice.reciprocal_lattice.matrix)
     return BandStructureSymmLine(
         kpoints=kpoints,
@@ -125,49 +131,50 @@
 
 def get_dos_data(dos_dir: str, return_dos=False) -> CompleteDos or Dos:
     """读取h5或json文件中的态密度数据，构建CompleteDos或DOS对象
 
     Parameters
     ----------
     dos_dir : str
-        态密度文件路径，dos.h5 / dos.json
+        态密度文件路径，dos.h5 / dos.json 或包含dos.h5 / dos.json的文件夹
     return_dos : bool, optional
         是否返回DOS对象，如果为False，则统一返回CompleteDos对象（无论计算时是否开了投影）
 
     Returns
     -------
     CompleteDos or Dos
 
     Examples
     --------
     >>> from dspawpy.io.read import get_dos_data
     >>> dos = get_dos_data(dos_dir='/data/home/hzw1002/dspawpy_repo/test/2.5/dos.h5')
     """
-    if dos_dir.endswith(".h5"):
-        dos = load_h5(dos_dir)
+    absfile = get_absfile(dos_dir, task="dos")
+    if absfile.endswith(".h5"):
+        dos = load_h5(absfile)
         if return_dos:
             if dos["/DosInfo/Project"][0]:
                 return _get_complete_dos(dos)
             else:
                 return _get_total_dos(dos)
         else:
             return _get_complete_dos(dos)
 
-    elif dos_dir.endswith(".json"):
-        with open(dos_dir, "r") as fin:
+    elif absfile.endswith(".json"):
+        with open(absfile, "r") as fin:
             dos = json.load(fin)
         if return_dos:
             if dos["DosInfo"]["Project"]:
                 return _get_complete_dos_json(dos)
             else:
                 return _get_total_dos_json(dos)
         return _get_complete_dos_json(dos)
 
     else:
-        raise TypeError(f"{os.path.abspath(dos_dir)} must be h5 or json file!")
+        raise TypeError(f"{absfile} must be h5 or json file!")
 
 
 def get_ele_from_h5(hpath: str = "aimd.h5"):
     """从h5文件中读取元素列表；
     多离子步并不会在每个离子步的Structure中保存元素信息，只能读取初始结构的元素信息
 
     Parameters
@@ -183,15 +190,16 @@
     Examples
     --------
     >>> from dspawpy.io.read import get_ele_from_h5
     >>> ele = get_ele_from_h5(hpath='/data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5')
     >>> ele
     ['H', 'H_1', 'O']
     """
-    data = h5py.File(hpath)
+    absh5 = os.path.abspath(hpath)
+    data = h5py.File(absh5)
     Elements_bytes = np.array(data.get("/AtomInfo/Elements"))
     tempdata = np.array([i.decode() for i in Elements_bytes])
     ele = "".join(tempdata).split(";")
 
     return ele
 
 
@@ -202,16 +210,16 @@
     --------
     >>> from dspawpy.io.read import get_lines_without_comment
     >>> lines = get_lines_without_comment(filename='/data/home/hzw1002/dspawpy_repo/test/2.15/01/structure01.as', comment='#')
     >>> lines
     ['Total number of atoms', '13', 'Lattice', '5.60580000 0.00000000 0.00000000', '0.00000000 5.60580000 0.00000000', '0.00000000 0.00000000 16.81740000', 'Cartesian', 'H 2.48700709 3.85367720 6.93461994', 'Pt 1.40145000 1.40145000 1.98192999', 'Pt 4.20434996 1.40145000 1.98192999', 'Pt 1.40145000 4.20434996 1.98192999', 'Pt 4.20434996 4.20434996 1.98192999', 'Pt 0.00843706 0.00042409 3.91500875', 'Pt 0.00881029 2.80247953 3.91551673', 'Pt 2.81216310 -0.00105882 3.91807627', 'Pt 2.81156629 2.80392163 3.91572506', 'Pt 1.41398585 1.39603492 5.85554462', 'Pt 4.22886663 1.39820574 5.84677553', 'Pt 1.40485707 4.20963461 5.89521929', 'Pt 4.23788559 4.20753128 5.88625580']
     """
     lines = []
-    """Filter out comment lines"""
-    with open(filename) as file:
+    absfile = os.path.abspath(filename)
+    with open(absfile) as file:
         while True:
             line = file.readline()
             if line:
                 line = re.sub(comment + r".*$", "", line)  # remove comment
                 line = line.strip()
                 if line:
                     lines.append(line)
@@ -223,46 +231,48 @@
 
 def get_phonon_band_data(phonon_band_dir: str) -> PhononBandStructureSymmLine:
     """读取h5或json文件中的声子能带数据，构建PhononBandStructureSymmLine对象
 
     Parameters
     ----------
     phonon_band_dir : str
-        能带文件路径，phonon.h5 / phonon.json
+        能带文件路径，phonon.h5 / phonon.json 或包含这两个文件的文件夹
 
     Returns
     -------
     PhononBandStructureSymmLine
 
     Examples
     --------
     >>> from dspawpy.io.read import get_phonon_band_data
     >>> band_data = get_phonon_band_data("/data/home/hzw1002/dspawpy_repo/test//2.16/phonon.h5") # 读取声子能带
     """
-    if phonon_band_dir.endswith(".h5"):
-        band = load_h5(phonon_band_dir)
+    absfile = get_absfile(phonon_band_dir, task="phonon")
+
+    if absfile.endswith(".h5"):
+        band = load_h5(absfile)
         (
             symmmetry_kpoints,
             symmetry_kPoints_index,
             kpoints,
             structure,
             frequencies,
         ) = _get_phonon_band_data_h5(band)
-    elif phonon_band_dir.endswith(".json"):
-        with open(phonon_band_dir, "r") as fin:
+    elif absfile.endswith(".json"):
+        with open(absfile, "r") as fin:
             band = json.load(fin)
         (
             symmmetry_kpoints,
             symmetry_kPoints_index,
             kpoints,
             structure,
             frequencies,
         ) = _get_phonon_band_data_json(band)
     else:
-        raise TypeError(f"{os.path.abspath(phonon_band_dir)} must be h5 or json file")
+        raise TypeError(f"{absfile} must be h5 or json file")
 
     labels_dict = {}
     for i, s in enumerate(symmmetry_kpoints):
         labels_dict[s] = kpoints[symmetry_kPoints_index[i] - 1]
     lattice_new = Lattice(structure.lattice.reciprocal_lattice.matrix)
 
     return PhononBandStructureSymmLine(
@@ -277,15 +287,15 @@
 
 def get_phonon_dos_data(phonon_dos_dir: str) -> PhononDos:
     """读取h5或json文件中的声子态密度数据，构建PhononDos对象
 
     Parameters
     ----------
     phonon_dos_dir : str
-        声子态密度文件路径，phonon_dos.h5 / phonon_dos.json
+        声子态密度文件路径，phonon_dos.h5 / phonon_dos.json 或包含这两个文件的文件夹
 
     Returns
     -------
     PhononDos
 
     Examples
     --------
@@ -308,25 +318,26 @@
            14.3, 14.4, 14.5, 14.6, 14.7, 14.8, 14.9, 15. , 15.1, 15.2, 15.3,
            15.4, 15.5, 15.6, 15.7, 15.8, 15.9, 16. , 16.1, 16.2, 16.3, 16.4,
            16.5, 16.6, 16.7, 16.8, 16.9, 17. , 17.1, 17.2, 17.3, 17.4, 17.5,
            17.6, 17.7, 17.8, 17.9, 18. , 18.1, 18.2, 18.3, 18.4, 18.5, 18.6,
            18.7, 18.8, 18.9, 19. , 19.1, 19.2, 19.3, 19.4, 19.5, 19.6, 19.7,
            19.8, 19.9, 20. ])
     """
-    if phonon_dos_dir.endswith(".h5"):
-        dos = load_h5(phonon_dos_dir)
+    absfile = get_absfile(phonon_dos_dir, task="phonon_dos")
+    if absfile.endswith(".h5"):
+        dos = load_h5(absfile)
         frequencies = np.asarray(dos["/DosInfo/DosEnergy"])
         densities = dos["/DosInfo/Spin1/Dos"]
-    elif phonon_dos_dir.endswith(".json"):
-        with open(phonon_dos_dir, "r") as fin:
+    elif absfile.endswith(".json"):
+        with open(absfile, "r") as fin:
             dos = json.load(fin)
         frequencies = np.asarray(dos["DosInfo"]["DosEnergy"])
         densities = dos["DosInfo"]["Spin1"]["Dos"]
     else:
-        raise TypeError(f"{os.path.abspath(phonon_dos_dir)} must be h5 or json file")
+        raise TypeError(f"{absfile} must be h5 or json file")
 
     return PhononDos(frequencies, densities)
 
 
 def get_sinfo(datafile: str, scaled=False, si=None, ele=None, ai=None):
     r"""从datafile中读取结构信息
 
@@ -365,30 +376,26 @@
     --------
 
     >>> from dspawpy.io.read import get_sinfo
     >>> Nstep, eles, pos, latv, D_mag_fix = get_sinfo(datafile='/data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5', scaled=False, si=None, ele=None, ai=None)
     Reading /data/home/hzw1002/dspawpy_repo/test/2.18/aimd.h5...
     >>> Nstep, eles, pos, latv, D_mag_fix = get_sinfo(datafile='/data/home/hzw1002/dspawpy_repo/test/2.1/relax.json', scaled=False, si=None, ele=None, ai=None)
     Reading /data/home/hzw1002/dspawpy_repo/test/2.1/relax.json...
-     json所含数据默认仅保留到小数点后四位，与h5或log文件中所记载的数据存在一定误差，可能导致后续保存的结构文件不一致！可以考虑使用io.jsonPrec参数调整精度！
-    Warning: mag and fix info are not available for relax.json and nebXX.json yet, trying read info...
     >>> Nstep, eles, pos, latv, D_mag_fix = get_sinfo(datafile='/data/home/hzw1002/dspawpy_repo/test/2.2/rho.json', scaled=False)
     Reading /data/home/hzw1002/dspawpy_repo/test/2.2/rho.json...
-     json所含数据默认仅保留到小数点后四位，与h5或log文件中所记载的数据存在一定误差，可能导致后续保存的结构文件不一致！可以考虑使用io.jsonPrec参数调整精度！
 
     这些信息可以用于进一步构建Structure对象，
     具体参考 dspawpy.io.structure.build_Structures_from_datafile 函数
     """
-    assert ele is None or ai is None, "不能同时选择元素和原子序号"
+    assert ele is None or ai is None, "Cannot select element and atomic number at the same time"
 
-    if datafile.endswith(".h5"):
-        assert os.path.exists(datafile), f"{os.path.abspath(datafile)} does not exist!"
-        hpath = datafile
-        print(f"Reading {os.path.abspath(hpath)}...")
-        hf = h5py.File(hpath)  # 加载h5文件
+    absfile = get_absfile(datafile, task="free")
+    print(f"Reading {absfile}...")
+    if absfile.endswith(".h5"):
+        hf = h5py.File(absfile)  # 加载h5文件
 
         # decide task type by check the internal key
         if "/Structures" in hf.keys():  # multi-steps
             Total_step = np.array(hf.get("/Structures/FinalStep"))[0]  # 总步数
             if si is not None:  # 步数
                 if isinstance(si, int):  # 1
                     indices = [si]
@@ -396,23 +403,23 @@
                 elif isinstance(si, list) or isinstance(ai, np.ndarray):  # [1,2,3]
                     indices = si
 
                 elif isinstance(si, str):  # ':', '-3:'
                     indices = __parse_indices(si, Total_step)
 
                 else:
-                    raise ValueError("请输入正确格式的index")
+                    raise ValueError("si=%s is invalid" % si)
 
                 Nstep = len(indices)
             else:
                 Nstep = Total_step
                 indices = list(range(1, Nstep + 1))
 
             # 读取元素列表，这个列表不会随步数改变，也不会“合并同类项”
-            Elements = np.array(get_ele_from_h5(hpath), dtype=object)
+            Elements = np.array(get_ele_from_h5(absfile), dtype=object)
 
             # 开始读取晶胞和原子位置
             lattices = np.empty((Nstep, 3, 3))  # Nstep x 3 x 3
             location = []
             if ele is not None:  # 如果用户指定元素
                 if isinstance(ele, str):  # 单个元素符号，例如 'Fe'
                     ele_list = np.array(ele, dtype=object)
@@ -420,41 +427,40 @@
                 # 多个元素符号组成的列表，例如 ['Fe', 'O']
                 elif isinstance(ele, list) or isinstance(ele, np.ndarray):
                     for e in ele:
                         loc = np.where(Elements == e)[0]
                         location.append(loc)
                     location = np.concatenate(location)
                 else:
-                    raise TypeError("请输入正确的元素或元素列表")
+                    raise TypeError("ele=%s is invalid" % ele)
                 elements = Elements[location]
 
             elif ai is not None:  # 如果用户指定原子序号
                 if isinstance(ai, int):  # 1
                     ais = [ai]
                 elif isinstance(ai, list) or isinstance(ai, np.ndarray):  # [1,2,3]
                     ais = ai
                 elif isinstance(ai, str):  # ':', '-3:'
                     ais = __parse_indices(ai, Total_step)
                 else:
-                    raise ValueError("请输入正确格式的ai")
+                    raise ValueError("ai=%s is invalid" % ai)
                 ais = [i - 1 for i in ais]  # python从0开始计数，但是用户从1开始计数
                 elements = Elements[ais]
                 location = ais
 
             else:  # 如果都没指定
                 elements = Elements
                 location = list(range(len(Elements)))
 
             elements = elements.tolist()  # for pretty output
             Natom = len(elements)
 
             poses = np.empty(shape=(len(indices), Natom, 3))
             wrapped_poses = np.empty(shape=(len(indices), 3, Natom))
             for i, ind in enumerate(indices):  # 步数
-                # print(f'{ind=}')
                 lats = np.array(hf.get("/Structures/Step-" + str(ind) + "/Lattice"))
                 lattices[i] = lats
                 # [x1,y1,z1,x2,y2,z2,x3,y3,z3], ...
                 # 结构优化时输出的都是分数坐标，不管CoordinateType写的是啥！
                 pos = np.array(hf.get("/Structures/Step-" + str(ind) + "/Position"))
                 wrapped_pos = pos - np.floor(pos)  # wrap into [0,1)
                 wrapped_pos = (
@@ -635,17 +641,17 @@
                         poses[k, j, :] = np.dot(poses[k, :, sli], np.eye(3, 3))
             else:  # Cartesian coordinates
                 for k, ind in enumerate(indices):  # 步数
                     for j, sli in enumerate(location):
                         poses[k, j, :] = np.dot(poses[k, :, sli], lats)
 
         elif "/UnitAtomInfo" in hf.keys():  # phonon 仅读取单胞信息
-            hfDict = load_h5(hpath)
+            hfDict = load_h5(absfile)
             s = _get_structure(hfDict, "/UnitAtomInfo")
-            elements = s.species
+            elements = np.array(get_ele_from_h5(absfile), dtype=object)
             Natom = len(elements)
             poses = [s.cart_coords]
             lattices = [s.lattice.matrix]
             Nstep = 1
 
             atomFixs = np.empty(shape=(N_images, Natom, 3))
             atomFix = np.full(shape=(Natom, 3), fill_value="False")
@@ -697,38 +703,37 @@
                         poses[k, j, :] = np.dot(wrapped_poses[k, :, sli], np.eye(3, 3))
             else:  # Cartesian coordinates
                 for k, ind in enumerate(indices):  # 步数
                     for j, sli in enumerate(location):
                         poses[k, j, :] = np.dot(wrapped_poses[k, :, sli], lats)
 
         else:  # rho, potential, elf, pcharge
-            hfDict = load_h5(hpath)
+            hfDict = load_h5(absfile)
             s = _get_structure(hfDict, "/AtomInfo")
-            elements = s.species
+            elements = np.array(get_ele_from_h5(absfile), dtype=object)
             poses = [s.cart_coords]
             lattices = [s.lattice.matrix]
             Nstep = 1
             D_mag_fix = None
-            print("--> rho/potential/elf/pcharge.h5 has no mag or fix info,")
-            print("  you should manually set it before starting new calculations..")
+            warnings.warn(
+                "--> rho/potential/elf/pcharge.h5 has no mag or fix info,\nyou should manually set it before starting new calculations.."
+            )
 
-    elif datafile.endswith(".json"):
-        assert os.path.exists(datafile), f"{os.path.abspath(datafile)} does not exist!"
-        jpath = datafile
-        print(f"Reading {os.path.abspath(jpath)}...")
-        print(
-            f" json所含数据默认仅保留到小数点后四位，与h5或log文件中所记载的数据存在一定误差，可能导致后续保存的结构文件不一致！可以考虑使用io.jsonPrec参数调整精度！"
+    elif absfile.endswith(".json"):
+        warnings.warn(
+            f"float number in json has precision of 4 digits by default, which may cause inconsistency with h5/log file, you may use io.jsonPrec to adjust the precision",
+            category=UserWarning,
         )
-        with open(jpath, "r") as f:
+        with open(absfile, "r") as f:
             data = json.load(f)  # 加载json文件
 
         # decide the task type by checking the internal keys
         if "AtomInfo" in data:  # single-step task
             s = _get_structure_json(data["AtomInfo"])
-            elements = s.species
+            elements = [str(i) for i in s.species]
             poses = [s.cart_coords]
             lattices = [s.lattice.matrix]
             Nstep = 1
             D_mag_fix = None
 
         elif "UnitAtomInfo" in data:  # phonon task
             raise NotImplementedError("Read from phonon.json is not supported yet.")
@@ -740,28 +745,28 @@
         else:  # multi-steps task
             if "Structures" in data:
                 Total_step = len(data["Structures"])  # aimd.json
             else:
                 Total_step = len(data)  # relax.json, neb01.json
 
             if ele is not None and ai is not None:
-                raise ValueError("暂不支持同时指定元素和原子序号")
+                raise ValueError("Cannot specify both ele and ai")
             # 步数
             if si is not None:
                 if isinstance(si, int):  # 1
                     indices = [si]
 
                 elif isinstance(si, list) or isinstance(ai, np.ndarray):  # [1,2,3]
                     indices = si
 
                 elif isinstance(si, str):  # ':', '-3:'
                     indices = __parse_indices(si, Total_step)
 
                 else:
-                    raise ValueError("请输入正确格式的index")
+                    raise ValueError("si=%s is invalid" % si)
 
                 Nstep = len(indices)
             else:
                 Nstep = Total_step
                 indices = list(range(1, Nstep + 1))  # [1,Nstep+1)
 
             # 预先读取全部元素的总列表，这个列表不会随步数改变，也不会“合并同类项”
@@ -790,28 +795,28 @@
                 location = []
                 if isinstance(ele, str):  # 单个元素符号，例如 'Fe'
                     ele_list = list(ele)
                 # 多个元素符号组成的列表，例如 ['Fe', 'O']
                 elif isinstance(ele, list) or isinstance(ele, np.ndarray):
                     ele_list = ele
                 else:
-                    raise TypeError("请输入正确的元素或元素列表")
+                    raise TypeError("ele=%s is invalid" % ele)
                 for e in ele_list:
                     location.append(np.where(total_elements == e)[0])
                 location = np.concatenate(location)
 
             elif ai is not None:  # 如果用户指定原子序号，也要据此筛选元素列表
                 if isinstance(ai, int):  # 1
                     ais = [ai]
                 elif isinstance(ai, list) or isinstance(ai, np.ndarray):  # [1,2,3]
                     ais = ai
                 elif isinstance(ai, str):  # ':', '-3:'
                     ais = __parse_indices(ai, Total_step)
                 else:
-                    raise ValueError("请输入正确格式的ai")
+                    raise ValueError("ai=%s is invalid" % ai)
                 ais = [i - 1 for i in ais]  # python从0开始计数，但是用户从1开始计数
                 location = ais
                 # read lattices and poses
 
             else:  # 如果都没指定
                 location = list(range(Natom))
 
@@ -862,16 +867,17 @@
 
                     mags.append(mag_for_each_step)
                     Atomfixs.append(fix_for_each_step)
                     if not scaled:
                         poses[i] = np.dot(poses[i], lattices[i])
 
             else:  # relax, neb01
-                print(
-                    "Warning: mag and fix info are not available for relax.json and nebXX.json yet, trying read info..."
+                warnings.warn(
+                    "mag and fix info are not available for relax.json and nebXX.json yet, trying read info...",
+                    category=UserWarning,
                 )
 
                 for i, ind in enumerate(indices):  # for every ionic step
                     lat = data[ind - 1]["Lattice"]
                     lattices[i] = np.array(lat).reshape(3, 3)
                     mag_for_each_step = []
                     fix_for_each_step = []
@@ -961,15 +967,15 @@
                 string = ""
                 for char in byte2str:
                     string += char
                 data = np.array([elem for elem in string.strip().split(";")])
             # "/group1/group2/.../groupN/dataset" : value
             datas[h5_object.name] = data.tolist()
 
-    with h5py.File(dir_h5, "r") as fin:
+    with h5py.File(os.path.abspath(dir_h5), "r") as fin:
         names = []
         datas = {}
         fin.visititems(get_names)
         fin.visititems(get_datas)
 
         return datas
 
@@ -1009,31 +1015,31 @@
     """解析用户输入的原子序号字符串
 
     输入：
         - index: 用户输入的原子序号/元素字符串，例如 '1:3,5,7:10'
     输出：
         - indices: 解析后的原子序号列表，例如 [1,2,3,4,5,6,7,8,9,10]
     """
-    assert ":" in index, "如果不想切片索引，请输入整数或者列表"
+    assert ":" in index, "If you don't want to slice the index, please enter an integer or a list"
     blcs = index.split(",")
     indices = []
     for blc in blcs:
         if ":" in blc:  # 切片
             low = blc.split(":")[0]
             if not low:
                 low = 1  # 从1开始
             else:
                 low = int(low)
-                assert low > 0, "索引从1开始！"
+                assert low > 0, "Index start at 1!"
             high = blc.split(":")[1]
             if not high:
                 high = total_step
             else:
                 high = int(high)
-                assert high <= total_step, "索引超出范围！"
+                assert high <= total_step, "Index too large!"
 
             for i in range(low, high + 1):
                 indices.append(i)
         else:  # 单个数字
             indices.append(int(blc))
     return indices
 
@@ -1463,15 +1469,16 @@
         structure = _get_structure_json(band["AtomInfo"])
 
     return symmmetry_kpoints, symmetry_kPoints_index, kpoints, structure, frequencies
 
 
 def pel_from_as(spath: str, scaled=False):
     """backup here for compatibility"""
-    with open(spath, "r") as f:
+    absfile = os.path.abspath(spath)
+    with open(absfile, "r") as f:
         lines = f.readlines()
         Natom = int(lines[1])  # 原子总数
         ele = [line.split()[0] for line in lines[7 : 7 + Natom]]  # 元素列表
 
         # 晶格矢量
         latv = np.array([line.split()[0:3] for line in lines[3:6]], dtype=float)
         # xyz坐标分量
@@ -1480,15 +1487,15 @@
         )
         # coordinates type
         if lines[6].startswith("C"):  # 笛卡尔 --> 分数坐标
             spos = np.linalg.solve(latv.T, np.transpose(coord)).T
         elif lines[6].startswith("D"):
             spos = coord
         else:
-            raise ValueError(f"{spath}中的坐标类型未知！")
+            raise ValueError(f"{absfile} got wrong coordinate type")
 
         if scaled:
             pos = spos
         else:
             pos = np.dot(spos, latv)
 
     return pos, ele, latv
```

## dspawpy/io/structure.py

```diff
@@ -1,25 +1,29 @@
 # -*- coding: utf-8 -*-
+import os
 import re
+import warnings
 from typing import List, Union
 
 import numpy as np
 from dspawpy.io.read import get_lines_without_comment, get_sinfo
+from dspawpy.io.utils import get_absfile
 from pymatgen.core import Structure
 
 
 def build_Structures_from_datafile(
-    datafile: Union[str, List[str]], si=None, ele=None, ai=None, fmt=None
+    datafile: Union[str, List[str]], si=None, ele=None, ai=None, fmt=None, task="scf"
 ) -> List[Structure]:
     r"""读取一/多个h5/json文件，返回pymatgen的Structures列表
 
     Parameters
     ----------
     datafile : str or list
         - h5/json/as/hzw/cif/poscar/cssr/xsf/mcsqs/prismatic/yaml/fleur-inpgen文件路径;
+        - 若给定文件夹路径，可配合task参数读取内部的 {task}.h5/json 文件
         - 若给定字符串列表，将依次读取数据并合并成一个Structures列表
     si: int, list or str
         - 构型编号，从 1 开始
 
             - si=1, 读取第一个构型
             - si=[1,2], 读取第一个和第二个构型
             - si=':', 读取所有构型
@@ -34,14 +38,17 @@
         - 原子编号，从 1 开始
         - 用法同si
         - 若为空，将读取所有原子信息
         - 此参数仅对 h5/json 文件有效
     fmt: str
         - 文件格式，包括 'h5', 'json', 'as', 'hzw' 四种，其他值将被忽略。
         - 若为空，文件类型将依据文件名称惯例判断。
+    task: str
+        - 用于当 datafile 为文件夹路径时，寻找内部的 {task}.h5/json 文件。
+        - 计算任务类型，包括 'scf', 'relax', 'neb', 'aimd' 四种，其他值将被忽略。
 
     Returns
     -------
     pymatgen_Structures : List[Structure]
         结构列表
 
     Examples
@@ -53,23 +60,20 @@
 
     >>> pymatgen_Structures = bs(datafile='/data/home/hzw1002/dspawpy_repo/test/2.1/relax.h5')
     Reading /data/home/hzw1002/dspawpy_repo/test/2.1/relax.h5...
     >>> len(pymatgen_Structures)
     3
     >>> pymatgen_Structures = bs(datafile='/data/home/hzw1002/dspawpy_repo/test/2.1/relax.json')
     Reading /data/home/hzw1002/dspawpy_repo/test/2.1/relax.json...
-     json所含数据默认仅保留到小数点后四位，与h5或log文件中所记载的数据存在一定误差，可能导致后续保存的结构文件不一致！可以考虑使用io.jsonPrec参数调整精度！
-    Warning: mag and fix info are not available for relax.json and nebXX.json yet, trying read info...
     >>> len(pymatgen_Structures)
     3
     >>> pymatgen_Structures = bs(datafile='/data/home/hzw1002/dspawpy_repo/test/supplement/PtH.as')
     >>> len(pymatgen_Structures)
     1
     >>> pymatgen_Structures = bs(datafile='/data/home/hzw1002/dspawpy_repo/test/supplement/PtH.hzw')
-    build from hzw file may lack mag & fix info!
     >>> len(pymatgen_Structures)
     1
 
     注意pymatgen_Structures是由多个 Structure 对象组成的列表，每个 Structure 对象分别对应一个构型。如果只有一个构型，也会返回列表，请使用 pymatgen_Structures[0] 获取 Structure 对象
 
     当datafile为列表时，将依次读取多个文件，合并成一个Structures列表
 
@@ -82,48 +86,55 @@
         dfs = datafile
     else:  # 单次计算模式，处理单个文件
         dfs.append(datafile)
 
     # 读取结构数据
     pymatgen_Structures = []
     for df in dfs:
-        structure_list = _get_structure_list(df, si, ele, ai, fmt)
+        structure_list = _get_structure_list(df, si, ele, ai, fmt, task)
         pymatgen_Structures.extend(structure_list)
 
     return pymatgen_Structures
 
 
 def _get_structure_list(
-    df: str, si=None, ele=None, ai=None, fmt=None
+    df: str, si=None, ele=None, ai=None, fmt=None, task="scf"
 ) -> List[Structure]:
     """get pymatgen structures from single datafile
 
     Parameters
     ----------
     df : str
-        datafile
+        数据文件路径或包含数据文件的文件夹路径
 
     Returns
     -------
     List[Structure] : list of pymatgen structures
     """
+    if task is None:
+        task = "scf"
+
+    if os.path.isdir(df) or df.endswith(".h5") or df.endswith(".json"):
+        absfile = get_absfile(df, task=task)
+    else:  # for other type of datafile, such as .as, .hzw, POSCAR
+        absfile = os.path.abspath(df)
 
     if fmt is None:
-        fmt = df.split(".")[-1]
+        fmt = absfile.split(".")[-1]
     else:
         assert isinstance(fmt, str), "fmt must be str"
 
     if fmt == "as":
-        strs = [_from_dspaw_as(df)]
+        strs = [_from_dspaw_as(absfile)]
     elif fmt == "hzw":
-        print("build from hzw file may lack mag & fix info!")
-        strs = [_from_hzw(df)]
+        warnings.warn("build from .hzw may lack mag & fix info!", category=UserWarning)
+        strs = [_from_hzw(absfile)]
     elif fmt == "h5" or fmt == "json":
         Nstep, elements, positions, lattices, D_mag_fix = get_sinfo(
-            datafile=df, si=si, ele=ele, ai=ai
+            datafile=absfile, si=si, ele=ele, ai=ai
         )  # returned positions, not scaled-positions
         # remove _ from elements
         elements = [re.sub(r"_", "", e) for e in elements]
 
         strs = []
         for i in range(Nstep):
             if D_mag_fix:
@@ -142,15 +153,15 @@
                         lattices[i],
                         elements,
                         positions[i],
                         coords_are_cartesian=True,
                     )
                 )
     else:
-        strs = [Structure.from_file(df)]
+        strs = [Structure.from_file(absfile)]
 
     return strs
 
 
 def _from_dspaw_as(as_file: str = "structure.as") -> Structure:
     """从DSPAW的as结构文件中读取结构信息
 
@@ -160,16 +171,16 @@
         DSPAW的as结构文件, 默认'structure.as'
 
     Returns
     -------
     Structure
         pymatgen的Structure对象
     """
-
-    lines = get_lines_without_comment(as_file, "#")
+    absfile = os.path.abspath(as_file)
+    lines = get_lines_without_comment(absfile, "#")
     N = int(lines[1])  # number of atoms
 
     # parse lattice info
     lattice = []  # lattice matrix
     for line in lines[3:6]:
         vector = line.split()
         lattice.extend([float(vector[0]), float(vector[1]), float(vector[2])])
@@ -202,32 +213,33 @@
     for i in range(N):
         atom = lines[i + 7].strip().split()
         elements.append(atom[0])
         positions.extend([float(atom[1]), float(atom[2]), float(atom[3])])
 
     mf_info = None
     l6 = lines[6].strip()  # str, 'Cartesian/Direct Mag Fix_x ...'
-    if l6 == "Direct":
+    if l6.split()[0] == "Direct":
         is_direct = True
-    elif l6 == "Cartesian":
+    elif l6.split()[0] == "Cartesian":
         is_direct = False
     else:
-        is_direct = l6.split()[0] == "Direct"
-        mf_info = l6.split()[1:]  # ['Mag', 'Fix_x', 'Fix_y', 'Fix_z']
-        for item in mf_info:
-            assert item in [
-                "Mag",
-                "Mag_x",
-                "Mag_y",
-                "Mag_z",
-                "Fix",
-                "Fix_x",
-                "Fix_y",
-                "Fix_z",
-            ], "Mag/Fix info error!"
+        raise ValueError("Structure file format error!")
+
+    mf_info = l6.split()[1:]  # ['Mag', 'Fix_x', 'Fix_y', 'Fix_z']
+    for item in mf_info:
+        assert item in [
+            "Mag",
+            "Mag_x",
+            "Mag_y",
+            "Mag_z",
+            "Fix",
+            "Fix_x",
+            "Fix_y",
+            "Fix_z",
+        ], "Mag/Fix info error!"
 
     mag_fix_dict = {}
     if mf_info is not None:
         for mf_index, item in enumerate(mf_info):
             values = []
             for i in range(N):
                 atom = lines[i + 7].strip().split()
@@ -273,15 +285,16 @@
         hzw结构文件，以 .hzw 结尾
 
     Returns
     -------
     Structure
         pymatgen的Structure对象
     """
-    lines = get_lines_without_comment(hzw_file, "%")
+    absfile = os.path.abspath(hzw_file)
+    lines = get_lines_without_comment(absfile, "%")
     number_of_probes = int(lines[0])
     if number_of_probes != 0:
         raise ValueError("dspaw only support 0 probes hzw file")
     lattice = []
     for line in lines[1:4]:
         vector = line.split()
         lattice.extend([float(vector[0]), float(vector[1]), float(vector[2])])
```

## dspawpy/io/utils.py

```diff
@@ -1,17 +1,17 @@
 # -*- coding: utf-8 -*-
-# ! some functions are copied from ase
+# ! some functions are extracted from ase
 # see https://wiki.fysik.dtu.dk/ase/index.html
 
 import os
+import re
 from typing import List
 
 import numpy as np
 import pandas as pd
-from dspawpy.io.read import get_ele_from_h5
 from pymatgen.electronic_structure.core import OrbitalType
 from pymatgen.electronic_structure.dos import CompleteDos
 from scipy import integrate
 
 Na = 6.02214179e23  # 阿伏伽德罗常数 单位 /mol
 h = 6.6260696e-34  # 普朗克常数 单位J*s
 kB = 1.3806503e-23  # 玻尔兹曼常数 J/K
@@ -623,62 +623,56 @@
     TSgas : float
         理想气体近似下，计算熵的能量贡献，单位eV
 
     Examples
     --------
     >>> from dspawpy.io.utils import getTSgas
     >>> TSgas = getTSgas(fretxt='/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt', datafile='/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.h5', potentialenergy=-0.0,  geometry='linear', symmetrynumber=1, spin=1, temperature=298.15, pressure=101325.0)
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.13/frequency.h5...
     >>> print(TSgas)
     0.8515317035550232
     >>> TSgas = getTSgas(fretxt='/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt', datafile='/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.h5', potentialenergy=-0.0,  geometry='linear', symmetrynumber=1, spin=1, temperature=298.15, pressure=101325.0)
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.13/frequency.h5...
     >>> TSgas
     0.8515317035550232
     """
+    abstxt = os.path.abspath(fretxt)
     ve = []
-    with open(fretxt) as ft:
+    with open(abstxt) as ft:
         lines = ft.readlines()
         for i in range(2, len(lines)):
             if lines[i].strip()[1] == "f/i":
                 ve.append(complex(lines[i].split()[-1]) / 1000)
             else:
                 ve.append(float(lines[i].split()[-1]) / 1000)
+    if datafile is not None:
+        absfile = get_absfile(datafile, task="frequency")
+        print(f"Reading {absfile}...")
+        if absfile.endswith(".h5"):
+            from dspawpy.io.read import get_ele_from_h5
 
-    if datafile:  # skip if datafile is None
-        # search datafile in the given directory
-        if os.path.isdir(datafile):
-            directory = datafile  # specified datafile is actually a directory
-            print("您指定了一个文件夹，正在查找相关h5或json文件...")
-            if os.path.exists(os.path.join(directory, "frequency.h5")):
-                datafile = os.path.join(directory, "frequency.h5")
-                print("Reading frequency.h5...")
-            elif os.path.exists(os.path.join(directory, "frequency.json")):
-                datafile = os.path.join(directory, "frequency.json")
-                print("Reading frequency.json...")
-            else:
-                raise FileNotFoundError("未找到frequency.h5/frequency.json文件！")
-        if datafile.endswith(".h5"):
-            eles = get_ele_from_h5(datafile)
+            eles = get_ele_from_h5(absfile)
             import h5py
 
-            data = h5py.File(datafile)
+            data = h5py.File(absfile)
             poses = np.array(data.get("/AtomInfo/Position")).reshape(-1, 3)
 
-        elif datafile.endswith(".json"):
+        elif absfile.endswith(".json"):
             import json
 
-            with open(datafile) as f:
+            with open(absfile) as f:
                 data = json.load(f)
             atoms = data["AtomInfo"]["Atoms"]
             eles = []
             poses = []
             for i in range(len(atoms)):
                 eles.append(atoms[i]["Element"])
                 poses.append(atoms[i]["Position"])
         else:
-            raise TypeError("仅支持读取h5或json文件！")
+            raise TypeError("Only support h5/json file")
     else:
         eles = elements
         poses = positions
 
     # 计算熵的能量贡献
     thermo = IdealGasThermo(
         vib_energies=ve,  # eV
@@ -755,61 +749,65 @@
     ZPE: float
         零点能
 
     Examples
     --------
     >>> from dspawpy.io.utils import getZPE
     >>> ZPE= getZPE(fretxt='/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt')
-    === 从/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt中读取到的相关如下 ===
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt ...
        Frequency (meV)
     0       284.840033
     <BLANKLINE>
-    正在写入ZPE.dat文件...
+    ==> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/ZPE.dat...
     <BLANKLINE>
     --> Zero-point energy,  ZPE (eV): 0.1424200165
     >>> ZPE
     0.1424200165
     """
-
+    abstxt = os.path.abspath(fretxt)
+    absout = os.path.abspath(outfile)
     # 1. read data
     data_get_ZPE = []
-    with open(fretxt, "r") as f:
+    with open(abstxt, "r") as f:
         for line in f.readlines():
             data_line = line.strip().split()
             if len(data_line) != 6:
                 continue
             if data_line[1] == "f":
                 data_get_ZPE.append(float(data_line[5]))
 
     data_get_ZPE = np.array(data_get_ZPE)
 
     # 2. printout to check
-    print(f"=== 从{fretxt}中读取到的相关如下 ===")
+    print(f"Reading {abstxt} ...")
     dt = pd.DataFrame({"Frequency (meV)": data_get_ZPE}, index=None)
     print(dt)
+    print()
 
     if len(data_get_ZPE) == 0:
-        raise ValueError("全是虚频，请考虑重新优化结构...")
+        raise ValueError(
+            "Only imaginary frequencies, please consider re-optimizing the structure"
+        )
     else:
-        print(f"\n正在写入{outfile}文件...")
+        print(f"==> {absout}...")
         np.savetxt(
-            outfile,
+            absout,
             np.array(data_get_ZPE).T,
             fmt="%.6f",
             header="Frequency (meV)",
-            comments=f"Data read from {os.path.abspath(fretxt)}\n",
+            comments=f"Data read from {abstxt}\n",
         )
 
     # 3. calculate
     ZPE = 0
     for data in data_get_ZPE:
         ZPE += data / 2000.0
     print("\n--> Zero-point energy,  ZPE (eV):", ZPE)
 
-    with open(outfile, "a") as f:
+    with open(absout, "a") as f:
         f.write(f"\n--> Zero-point energy,  ZPE (eV): {ZPE}")
 
     return ZPE
 
 
 def getTSads(
     fretxt: str = "frequency.txt", T: float = 298.15, outfile: str = "TSads.dat"
@@ -832,49 +830,54 @@
     TS: float
         熵校正
 
     Examples
     --------
     >>> from dspawpy.io.utils import getTSads
     >>> TS = getTSads(fretxt='/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt', T=298.15)
-    === 从/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt中读取到的相关如下 ===
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt ...
        Frequency (THz)
     0        68.873993
     <BLANKLINE>
-    正在写入TSads.dat文件...
-    --> Entropy contribution, T*S (eV)： 4.7566997225177686e-06
-    >>> TS
-    4.7566997225177686e-06
+    ==> /data/home/hzw1002/dspawpy_repo/dspaw-manual-cn/dspawpy_proj/TSads.dat
+    --> T*S (eV): 4.7566997225177686e-06
     """
+    abstxt = os.path.abspath(fretxt)
+    absout = os.path.abspath(outfile)
+
     data_get_TS = []
-    with open(fretxt, "r") as f:
+    with open(abstxt, "r") as f:
         for line in f.readlines():
             data_line = line.strip().split()
             if len(data_line) != 6:
                 continue
             if data_line[1] == "f":
                 data_get_TS.append(float(data_line[2]))
 
     data_get_TS = np.array(data_get_TS)
 
     # 2. printout to check
-    print(f"=== 从{fretxt}中读取到的相关如下 ===")
+    print(f"Reading {abstxt} ...")
     dt = pd.DataFrame({"Frequency (THz)": data_get_TS}, index=None)
     print(dt)
+    print()
 
     if len(data_get_TS) == 0:
-        raise ValueError("全是虚频，请考虑重新优化结构...")
+        raise ValueError(
+            "Only imaginary frequencies, please consider re-optimizing the structure"
+        )
     else:
-        print(f"\n正在写入{outfile}文件...")
+        print(f"==> {absout}")
+        os.makedirs(os.path.dirname(absout), exist_ok=True)
         np.savetxt(
-            outfile,
+            absout,
             np.array(data_get_TS).T,
             fmt="%.6f",
             header="Frequency (THz)",
-            comments=f"Data read from {os.path.abspath(fretxt)}\n",
+            comments=f"Data read from {abstxt}\n",
         )
 
     # 3. calculate
     sum_S = 0
     import math  # 因为要使用 e的多少次方，ln（）对数
 
     for vi_THz in data_get_TS:
@@ -886,70 +889,218 @@
         m5 = 1 - math.exp(-m2)  # math.exp(3) 就是e的3次方
         m6 = math.log(m5, math.e)  # m6= ln(m5)   math.e在python中=e ，以右边为底的对数
         m7 = R * m6
         m8 = m1 / m4 - m7  # S 单位J/(mol*K)
         m9 = (T * m8 / 1000) / 96.49  # T*S,将单位化为KJ/mol, 96.49 kJ/mol = 1 eV 单位eV
         sum_S += m9
 
-    print("--> Entropy contribution, T*S (eV)：", sum_S)
+    print("--> T*S (eV):", sum_S)
 
-    with open(outfile, "a") as f:
-        f.write(f"\n--> Entropy contribution, T*S (eV): {sum_S}\n")
+    with open(absout, "a") as f:
+        f.write(f"\n--> T*S (eV): {sum_S}\n")
 
     return sum_S
 
 
-def thermo_correction(fretxt: str = "frequency.txt", T: float = 298.15):
-    """从fretext中读取数据，计算ZPE和TS
-    将另外保存结果到 ZPE_TS.dat 中
+def get_absfile(datafile: str, task: str, only_h5: bool = False):  # -> absfile
+    """根据给定的datafile，返回所需数据文件的绝对路径
 
     Parameters
     ----------
-    fretxt : str
-        记录频率信息的文件所在路径, 默认当前路径下的'frequency.txt'
-    T : float
-        温度，单位K, 默认298.15
+    datafile: str
+        h5/json数据文件路径或其文件夹路径，可以是相对路径
+    task: str
+        计算任务类型，如 scf, optical 等
+    only_h5: bool
+        是否只寻找h5文件，默认False
+
+    Raises
+    ------
+    FileNotFoundError
+        - 指定的文件夹路径不包含相应h5/json数据文件
+        - 指定的文件路径不存在
 
     Returns
     -------
-    ZPE: float
-        零点能
-    TS: float
-        熵校正
-
-    Examples
-    --------
-    >>> from dspawpy.io.utils import thermo_correction
-    >>> ZPE, TS = thermo_correction(fretxt='/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt', T=298.15)
-    === 从/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt中读取到的相关如下 ===
-       Frequency (meV)
-    0       284.840033
-    <BLANKLINE>
-    正在写入ZPE.dat文件...
-    <BLANKLINE>
-    --> Zero-point energy,  ZPE (eV): 0.1424200165
-    === 从/data/home/hzw1002/dspawpy_repo/test/2.13/frequency.txt中读取到的相关如下 ===
-       Frequency (THz)
-    0        68.873993
-    <BLANKLINE>
-    正在写入TSads.dat文件...
-    --> Entropy contribution, T*S (eV)： 4.7566997225177686e-06
-    >>> ZPE
-    0.1424200165
-    >>> TS
-    4.7566997225177686e-06
+    absfile: str
+        所需数据文件的绝对路径
     """
+    assert datafile is not None, "datafile is None"
+    absfile = os.path.abspath(datafile)
+    if only_h5:
+        if os.path.isdir(absfile):  # specified datafile is actually a directory
+            directory = absfile  # search datafile in the given directory
+            absh5 = os.path.join(directory, f"{task}.h5")
+            if os.path.exists(absh5):
+                absfile = absh5
+            else:
+                raise FileNotFoundError(f"No {absh5}/{absjs}")
+        else:
+            if not os.path.isfile(absfile):
+                raise FileNotFoundError(f"No {absfile}")
+            else:
+                assert absfile.endswith(
+                    ".h5"
+                ), f"Only support h5 file, but got {absfile}"
+    else:
+        if os.path.isdir(absfile):  # specified datafile is actually a directory
+            directory = absfile  # search datafile in the given directory
+            absh5 = os.path.join(directory, f"{task}.h5")
+            absjs = os.path.join(directory, f"{task}.json")
+            if os.path.exists(absh5):
+                absfile = absh5
+            elif os.path.exists(absjs):
+                absfile = absjs
+            else:
+                raise FileNotFoundError(f"No {absh5}/{absjs}")
+        else:
+            if not os.path.isfile(absfile):
+                raise FileNotFoundError(f"No {absfile}")
+            else:
+                assert absfile.endswith(".h5") or absfile.endswith(
+                    ".json"
+                ), f"Only support h5/json file, but got {absfile}"
+
+    return absfile
 
-    ZPE = getZPE(fretxt=fretxt)
-    sum_S = getTSads(fretxt=fretxt, T=T)
 
-    return ZPE, sum_S
+# extract from ASE
+def string2symbols(s: str) -> List[str]:
+    """Convert string to list of chemical symbols."""
+    return list(Formula(s))
 
 
 def _symbols2numbers(symbols) -> List[int]:
+    if isinstance(symbols, str):
+        symbols = string2symbols(symbols)
     numbers = []
     for s in symbols:
         if isinstance(s, str):
             numbers.append(atomic_numbers[s])
         else:
             numbers.append(int(s))
     return numbers
+
+
+class Formula:
+    def __init__(
+        self,
+        formula: str = "",
+        *,
+        strict: bool = False,
+        format: str = "",
+        _tree=None,
+        _count=None,
+    ):
+        """Chemical formula object.
+
+        Parameters
+        ----------
+        formula: str
+            Text string representation of formula.  Examples: ``'6CO2'``,
+            ``'30Cu+2CO'``, ``'Pt(CO)6'``.
+        strict: bool
+            Only allow real chemical symbols.
+        format: str
+            Reorder according to *format*.  Must be one of hill, metal,
+            abc or reduce.
+
+        Examples
+        --------
+        >>> from dspawpy.io.utils import Formula
+        >>> w = Formula('H2O')
+
+        Raises
+        ------
+        ValueError
+            on malformed formula
+        """
+        if format:
+            assert _tree is None and _count is None
+            if format not in {"hill", "metal", "abc", "reduce"}:
+                raise ValueError(f"Illegal format: {format}")
+            formula = Formula(formula).format(format)
+        self._formula = formula
+        self._tree = _tree or parse(formula)
+        self._count = _count or count_tree(self._tree)
+        if strict:
+            for symbol in self._count:
+                if symbol not in atomic_numbers:
+                    raise ValueError("Unknown chemical symbol: " + symbol)
+
+    def __iter__(self, tree=None):
+        if tree is None:
+            tree = self._tree
+        if isinstance(tree, str):
+            yield tree
+        elif isinstance(tree, tuple):
+            tree, N = tree
+            for _ in range(N):
+                yield from self.__iter__(tree)
+        else:
+            for tree in tree:
+                yield from self.__iter__(tree)
+
+
+def parse(f: str):  # -> Tree
+    if not f:
+        return []
+    parts = f.split("+")
+    result = []
+    for part in parts:
+        n, f = strip_number(part)
+        result.append((parse2(f), n))
+    return result
+
+
+def strip_number(s: str):
+    m = re.match("[0-9]*", s)
+    assert m is not None
+    return int(m.group() or 1), s[m.end() :]
+
+
+def parse2(f: str):
+    units = []
+    while f:
+        if f[0] == "(":
+            level = 0
+            for i, c in enumerate(f[1:], 1):
+                if c == "(":
+                    level += 1
+                elif c == ")":
+                    if level == 0:
+                        break
+                    level -= 1
+            else:
+                raise ValueError
+            f2 = f[1:i]
+            n, f = strip_number(f[i + 1 :])
+            unit = (parse2(f2), n)
+        else:
+            m = re.match("([A-Z][a-z]?)([0-9]*)", f)
+            if m is None:
+                raise ValueError
+            symb = m.group(1)
+            number = m.group(2)
+            if number:
+                unit = (symb, int(number))
+            else:
+                unit = symb
+            f = f[m.end() :]
+        units.append(unit)
+    if len(units) == 1:
+        return unit
+    return units
+
+
+def count_tree(tree):
+    if isinstance(tree, str):
+        return {tree: 1}
+    if isinstance(tree, tuple):
+        tree, N = tree
+        return {symb: n * N for symb, n in count_tree(tree).items()}
+    dct = {}
+    for tree in tree:
+        for symb, n in count_tree(tree).items():
+            m = dct.get(symb, 0)
+            dct[symb] = m + n
+    return dct
```

## dspawpy/io/write.py

```diff
@@ -1,15 +1,21 @@
 # -*- coding: utf-8 -*-
 import json
 import os
+import time
+import warnings
 
 import numpy as np
 from dspawpy.io.read import _get_lammps_non_orthogonal_box, load_h5
+from dspawpy.io.structure import build_Structures_from_datafile
+from dspawpy.io.utils import _symbols2numbers
 from pymatgen.core.structure import Structure
 
+Bohr = 0.52917721067  # Angstrom
+
 
 def _write_xyz_traj(
     structures,
     xyzfile="aimdTraj.xyz",
 ):
     r"""保存xyz格式的轨迹文件
 
@@ -18,19 +24,22 @@
     structures: list
         pymatgen的Structures列表
     xyzfile : str
         写入xyz格式的轨迹文件，默认为aimdTraj.xyz
     """
     if not isinstance(structures, list):  # single Structure
         structures = [structures]
-    if os.path.isfile(xyzfile):
-        print("Warning: %s already exists and will be overwritten!" % xyzfile)
-    if os.path.dirname(xyzfile) != "":
-        os.makedirs(os.path.dirname(xyzfile), exist_ok=True)
-    with open(xyzfile, "w") as f:
+    if xyzfile is not None:
+        absxyz = os.path.abspath(xyzfile)
+    if os.path.isfile(absxyz):
+        warnings.warn(
+            f"{absxyz} already exists and will be overwritten!", category=UserWarning
+        )
+    os.makedirs(os.path.dirname(absxyz), exist_ok=True)
+    with open(absxyz, "w") as f:
         # Nstep
         for _, structure in enumerate(structures):
             # 原子数不会变，就是不合并的元素总数
             eles = [s.species_string for s in structure.sites]
             f.write("%d\n" % len(eles))
             # lattice
             lm = structure.lattice.matrix
@@ -51,15 +60,15 @@
             # position and element
             poses = structure.cart_coords
             for j in range(len(eles)):
                 f.write(
                     "%s %f %f %f\n" % (eles[j], poses[j, 0], poses[j, 1], poses[j, 2])
                 )
 
-    print(f"{xyzfile} 文件已保存！")
+    print(f"==> {absxyz}")
 
 
 def _write_dump_traj(
     structures,
     dumpfile="aimdTraj.dump",
 ):
     r"""保存为lammps的dump格式的轨迹文件，暂时只支持正交晶胞
@@ -69,19 +78,20 @@
     structures: list
         pymatgen的Structures列表
     dumpfile : str
         dump格式的轨迹文件名，默认为aimdTraj.dump
     """
     if not isinstance(structures, list):  # single Structure
         structures = [structures]
-    if os.path.isfile(dumpfile):
-        print("Warning: %s already exists and will be overwritten!" % dumpfile)
-    if os.path.dirname(dumpfile) != "":
-        os.makedirs(os.path.dirname(dumpfile), exist_ok=True)
-    with open(dumpfile, "w") as f:
+    if dumpfile is not None:
+        absdump = os.path.abspath(dumpfile)
+    if os.path.isfile(absdump):
+        warnings.warn(f"{absdump} already exists and will be overwritten!")
+    os.makedirs(os.path.dirname(absdump), exist_ok=True)
+    with open(absdump, "w") as f:
         for n, structure in enumerate(structures):
             lat = structure.lattice.matrix
             eles = [s.species_string for s in structure.sites]
             poses = structure.cart_coords
 
             box_bounds = _get_lammps_non_orthogonal_box(lat)
             f.write("ITEM: TIMESTEP\n%d\n" % n)
@@ -109,215 +119,158 @@
                         eles[i],
                         poses[i, 0],
                         poses[i, 1],
                         poses[i, 2],
                         i + 1,
                     )
                 )
-    print(f"{dumpfile} 文件已保存！")
+    print(f"==> {absdump}")
 
 
-def write_VESTA(in_filename: str, data_type, out_filename="DS-PAW.vesta", subtype=None):
+def write_VESTA(
+    in_filename: str,
+    data_type,
+    out_filename="DS-PAW.cube",
+    subtype=None,
+    format="cube",
+):
     """从包含电子体系信息的json或h5文件中读取数据并写入VESTA格式的文件中
 
     Parameters
     ----------
     in_filename : str
         包含电子体系信息的json或h5文件路径
     data_type: str
         数据类型，支持 "rho", "potential", "elf", "pcharge", "rhoBound"
     out_filename : str
-        输出文件路径, 默认 "DS-PAW.vesta"
+        输出文件路径, 默认 "DS-PAW.cube"
     subtype : str
         用于指定data_type的数据子类型，默认为None，将读取 potential 的 TotalElectrostaticPotential 数据
+    format : str
+        输出的数据格式，支持 "cube" 和 "vesta" （"vasp"），默认为 "cube"，大小写不敏感
 
     Returns
     --------
     out_filename : file
         VESTA格式的文件
 
     Examples
     --------
     >>> from dspawpy.io.write import write_VESTA
-    >>> write_VESTA("/data/home/hzw1002/dspawpy_repo/test/2.2/rho.json", "rho", out_filename='/data/home/hzw1002/dspawpy_repo/test/out/rho.json')
+    >>> write_VESTA("/data/home/hzw1002/dspawpy_repo/test/2.2/rho.json", "rho", out_filename='/data/home/hzw1002/dspawpy_repo/test/out/rho.cube')
+    Reading /data/home/hzw1002/dspawpy_repo/test/2.2/rho.json...
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/rho.cube
     """
     if in_filename.endswith(".h5"):
         data = load_h5(in_filename)
+        structure = build_Structures_from_datafile(in_filename)[0]
+        grid = data["/AtomInfo/Grid"]  # get grid array
         if data_type == "rho" or data_type == "rhoBound":
-            _write_VESTA_format(data, ["/Rho/TotalCharge"], out_filename)
+            vd = data["/Rho/TotalCharge"]
         elif data_type == "potential":
             if subtype is None:
                 subtype = "TotalElectrostaticPotential"
-            _write_VESTA_format(
-                data,
-                [
-                    f"/Potential/{subtype}",
-                ],
-                out_filename,
-            )
-            print("--> saved to ", out_filename)
+            vd = data[f"/Potential/{subtype}"]
         elif data_type == "elf":
-            _write_VESTA_format(data, ["/ELF/TotalELF"], out_filename)
+            vd = data["/ELF/TotalELF"]
         elif data_type == "pcharge":
-            _write_VESTA_format(data, ["/Pcharge/1/TotalCharge"], out_filename)
+            vd = data["/Pcharge/1/TotalCharge"]
         else:
-            raise NotImplementedError("仅支持rho/potential/elf/pcharge/rhoBound")
+            raise NotImplementedError("Only support rho/potential/elf/pcharge/rhoBound")
 
     elif in_filename.endswith(".json"):
         with open(in_filename, "r") as fin:
             data = json.load(fin)
+        structure = build_Structures_from_datafile(in_filename)[0]
+        grid = data["AtomInfo"]["Grid"]  # get grid array
         if data_type == "rho" or data_type == "rhoBound":
-            _write_VESTA_format_json(
-                data["AtomInfo"], [data["Rho"]["TotalCharge"]], out_filename
-            )
+            vd = data["Rho"]["TotalCharge"]
         elif data_type == "potential":
             if subtype is None:
                 subtype = "TotalElectrostaticPotential"
-            _write_VESTA_format_json(
-                data["AtomInfo"],
-                [
-                    data["Potential"][subtype],
-                ],
-                out_filename,
-            )
+            vd = data["Potential"][subtype]
         elif data_type == "elf":
-            _write_VESTA_format_json(
-                data["AtomInfo"], [data["ELF"]["TotalELF"]], out_filename
-            )
+            vd = data["ELF"]["TotalELF"]
         elif data_type == "pcharge":
-            _write_VESTA_format_json(
-                data["AtomInfo"], [data["Pcharge"][0]["TotalCharge"]], out_filename
-            )
+            vd = data["Pcharge"][0]["TotalCharge"]
         else:
-            raise NotImplementedError("仅支持rho/potential/elf/pcharge/rhoBound")
+            raise NotImplementedError("Only support rho/potential/elf/pcharge/rhoBound")
 
     else:
-        raise NotImplementedError("仅支持json或h5格式文件")
+        raise NotImplementedError("Only support json/h5 format")
 
+    _write_specific_format(structure, grid, vd, out_filename, format=format)
 
-def write_delta_rho_vesta(total, individuals, output="delta_rho.vesta"):
+
+def write_delta_rho_vesta(total, individuals, output="delta_rho.cube", format="cube"):
     """电荷密度差分可视化
 
     DeviceStudio暂不支持大文件，临时写成可以用VESTA打开的格式
 
     Parameters
     ----------
     total : str
         体系总电荷密度文件路径，可以是h5或json格式
     individuals : list of str
         体系各组分电荷密度文件路径，可以是h5或json格式
     output : str
-        输出文件路径，默认 "delta_rho.vesta"
+        输出文件路径，默认 "delta_rho.cube"
+    format : str
+        输出的数据格式，支持 "cube" 和 "vasp"，默认为 "cube"
 
     Returns
     -------
     output : file
         电荷差分（total-individual1-individual2-...）后的电荷密度文件，
 
     Examples
     --------
     >>> from dspawpy.io.write import write_delta_rho_vesta
     >>> write_delta_rho_vesta(total='/data/home/hzw1002/dspawpy_repo/test/supplement/AB.h5',
     ...     individuals=['/data/home/hzw1002/dspawpy_repo/test/supplement/A.h5', '/data/home/hzw1002/dspawpy_repo/test/supplement/B.h5'],
-    ...     output='/data/home/hzw1002/dspawpy_repo/test/out/delta_rho.vesta')
-    读取/data/home/hzw1002/dspawpy_repo/test/supplement/AB.h5...
-    读取/data/home/hzw1002/dspawpy_repo/test/supplement/A.h5...
-    读取/data/home/hzw1002/dspawpy_repo/test/supplement/B.h5...
-    写入文件/data/home/hzw1002/dspawpy_repo/test/out/delta_rho.vesta...
-    成功写入 /data/home/hzw1002/dspawpy_repo/test/out/delta_rho.vesta
+    ...     output='/data/home/hzw1002/dspawpy_repo/test/out/delta_rho.cube')
+    Reading /data/home/hzw1002/dspawpy_repo/test/supplement/AB.h5...
+    Reading /data/home/hzw1002/dspawpy_repo/test/supplement/A.h5...
+    Reading /data/home/hzw1002/dspawpy_repo/test/supplement/B.h5...
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/delta_rho.cube
     """
-    print(f"读取{total}...")
-    if total.endswith(".h5"):
-        dataAB = load_h5(total)
+    abstotal = os.path.abspath(total)
+    structure = build_Structures_from_datafile(abstotal)[0]
+    if abstotal.endswith(".h5"):
+        dataAB = load_h5(abstotal)
         rho = np.array(dataAB["/Rho/TotalCharge"])
-        nGrids = dataAB["/AtomInfo/Grid"]
-        atom_symbol = dataAB["/AtomInfo/Elements"]
-        atom_pos = dataAB["/AtomInfo/Position"]
-        latticeConstantMatrix = dataAB["/AtomInfo/Lattice"]
-        atom_pos = np.array(atom_pos).reshape(-1, 3)
-    elif total.endswith(".json"):
-        atom_symbol = []
-        atom_pos = []
-        with open(total, "r") as f1:
+        grid = dataAB["/AtomInfo/Grid"]
+    elif abstotal.endswith(".json"):
+        with open(abstotal, "r") as f1:
             dataAB = json.load(f1)
             rho = np.array(dataAB["Rho"]["TotalCharge"])
-            nGrids = dataAB["AtomInfo"]["Grid"]
-        for i in range(len(dataAB["AtomInfo"]["Atoms"])):
-            atom_symbol.append(dataAB["AtomInfo"]["Atoms"][i]["Element"])
-            atom_pos.append(dataAB["AtomInfo"]["Atoms"][i]["Position"])
-        atom_pos = np.array(atom_pos)
+            grid = dataAB["AtomInfo"]["Grid"]
 
-        latticeConstantMatrix = dataAB["AtomInfo"]["Lattice"]
     else:
-        raise ValueError(f"file format must be either h5 or json: {total}")
+        raise ValueError(f"file format must be either h5 or json: {abstotal}")
 
     for individual in individuals:
-        print(f"读取{individual}...")
-        if individual.endswith(".h5"):
-            data_individual = load_h5(individual)
+        absindividual = os.path.abspath(individual)
+        print(f"Reading {individual}...")
+        if absindividual.endswith(".h5"):
+            data_individual = load_h5(absindividual)
             rho_individual = np.array(data_individual["/Rho/TotalCharge"])
-        elif individual.endswith(".json"):
-            with open(individual, "r") as f2:
+        elif absindividual.endswith(".json"):
+            with open(absindividual, "r") as f2:
                 data_individual = json.load(f2)
                 rho_individual = np.array(data_individual["Rho"]["TotalCharge"])
         else:
-            raise ValueError(f"file format must be either h5 or json: {individual}")
+            raise ValueError(f"file format must be either h5 or json: {absindividual}")
 
         rho -= rho_individual
 
-    rho = np.array(rho).reshape(nGrids[0], nGrids[1], nGrids[2])
-    element = list(set(atom_symbol))
-    element = sorted(set(atom_symbol), key=atom_symbol.index)
-    element_num = np.zeros(len(element))
-    for i in range(len(element)):
-        element_num[i] = atom_symbol.count(element[i])
-
-    latticeConstantMatrix = np.array(latticeConstantMatrix)
-    latticeConstantMatrix = latticeConstantMatrix.reshape(3, 3)
-
-    print(f"写入文件{output}...")
-    if os.path.isfile(output):
-        print("Warning: %s already exists and will be overwritten!" % output)
-    if os.path.dirname(output) != "":
-        os.makedirs(os.path.dirname(output), exist_ok=True)
-    with open(output, "w") as out:
-        out.write("DS-PAW_rho\n")
-        out.write("    1.000000\n")
-        for i in range(3):
-            for j in range(3):
-                out.write("    " + str(latticeConstantMatrix[i, j]) + "    ")
-            out.write("\n")
-        for i in range(len(element)):
-            out.write("    " + element[i] + "    ")
-        out.write("\n")
-
-        for i in range(len(element_num)):
-            out.write("    " + str(int(element_num[i])) + "    ")
-        out.write("\n")
-        out.write("Direct\n")
-        for i in range(len(atom_pos)):
-            for j in range(3):
-                out.write("    " + str(atom_pos[i, j]) + "    ")
-            out.write("\n")
-        out.write("\n")
-
-        for i in range(3):
-            out.write("  " + str(nGrids[i]) + "  ")
-        out.write("\n")
-
-        ind = 0
-        for i in range(nGrids[0]):
-            for j in range(nGrids[1]):
-                for k in range(nGrids[2]):
-                    out.write("  " + str(rho[i, j, k]) + "  ")
-                    ind = ind + 1
-                    if ind % 5 == 0:
-                        out.write("\n")
-
-    print(f"成功写入 {output}")
+    volumetricData = np.array(rho)
+    _write_specific_format(
+        structure, grid, volumetricData, filename=output, format=format
+    )
 
 
 def to_file(structure, filename: str, fmt=None, coords_are_cartesian=True, si=None):
     r"""往结构文件中写入信息
 
     Parameters
     ----------
@@ -344,30 +297,28 @@
     >>> len(s)
     17
 
     将结构信息写入文件：
 
     >>> from dspawpy.io.write import to_file
     >>> to_file(s, filename='/data/home/hzw1002/dspawpy_repo/test/out/PtH.json', coords_are_cartesian=True)
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/PtH.json
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/PtH.json
     >>> to_file(s, filename='/data/home/hzw1002/dspawpy_repo/test/out/PtH.as', coords_are_cartesian=True)
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/PtH.as
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/PtH.as
     >>> to_file(s, filename='/data/home/hzw1002/dspawpy_repo/test/out/PtH.hzw', coords_are_cartesian=True)
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/PtH.hzw
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/PtH.hzw
 
     pdb, xyz, dump 三种类型的文件，可以写入多个构型，形成“轨迹”。生成的 xyz 等轨迹文件可使用 OVITO 等可视化软件打开观察。
 
     >>> to_file(s, filename='/data/home/hzw1002/dspawpy_repo/test/out/PtH.pdb', coords_are_cartesian=True)
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/PtH.pdb
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/PtH.pdb
     >>> to_file(s, filename='/data/home/hzw1002/dspawpy_repo/test/out/PtH.xyz', coords_are_cartesian=True)
-    /data/home/hzw1002/dspawpy_repo/test/out/PtH.xyz 文件已保存！
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/PtH.xyz
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/PtH.xyz
     >>> to_file(s, filename='/data/home/hzw1002/dspawpy_repo/test/out/PtH.dump', coords_are_cartesian=True)
-    /data/home/hzw1002/dspawpy_repo/test/out/PtH.dump 文件已保存！
-    --> 成功写入文件 /data/home/hzw1002/dspawpy_repo/test/out/PtH.dump
+    ==> /data/home/hzw1002/dspawpy_repo/test/out/PtH.dump
 
     单结构信息推荐使用 as 格式存储，如果 Structure 中有磁矩或自由度信息，将会按最完整的格式统一写入，形如 Fix_x, Fix_y, Fix_z, Mag_x, Mag_y, Mag_z，自由度信息默认为 F，磁矩默认为 0.0。可视情况自行手动删除生成的 as 文件中的这些默认信息
 
     >>> with open('/data/home/hzw1002/dspawpy_repo/test/out/PtH.as') as f:
     ...     print(f.read())
     ...
     Total number of atoms
@@ -391,211 +342,205 @@
     Pt 1.34667410 4.16198043 5.89298591 F F F 0.0
     Pt 4.17046728 4.15729941 5.89874209 F F F 0.0
     <BLANKLINE>
 
     写成其他类型的结构文件，将忽略磁矩和自由度信息
     """
     if si is not None:
-        assert isinstance(si, int), "si 应当是用于索引列表的整数"
+        assert isinstance(si, int), "si should be an integer used to index the list"
     if isinstance(structure, Structure):
         structure = [structure]
 
+    absfilename = os.path.abspath(filename)
     if fmt is None:
-        fmt = filename.split(".")[-1]
+        fmt = absfilename.split(".")[-1]
 
     if fmt == "pdb":  # 可以是多个构型
         if si:
-            _to_pdb(structure[si], filename)
+            _to_pdb(structure[si], absfilename)
         else:
-            _to_pdb(structure, filename)
+            _to_pdb(structure, absfilename)
     elif fmt == "xyz":  # 可以是多个构型
         if si:
-            _write_xyz_traj(structure[si], filename)
+            _write_xyz_traj(structure[si], absfilename)
         else:
-            _write_xyz_traj(structure, filename)
+            _write_xyz_traj(structure, absfilename)
     elif fmt == "dump":  # 可以是多个构型
         if si:
-            _write_dump_traj(structure[si], filename)
+            _write_dump_traj(structure[si], absfilename)
         else:
-            _write_dump_traj(structure, filename)
+            _write_dump_traj(structure, absfilename)
 
     elif fmt == "json":  # 单个构型
         if si:
-            _to_dspaw_json(structure[si], filename, coords_are_cartesian)
+            _to_dspaw_json(structure[si], absfilename, coords_are_cartesian)
         else:
-            _to_dspaw_json(structure[-1], filename, coords_are_cartesian)
+            _to_dspaw_json(structure[-1], absfilename, coords_are_cartesian)
     elif fmt == "as":
         if si:
-            _to_dspaw_as(structure[si], filename, coords_are_cartesian)
+            _to_dspaw_as(structure[si], absfilename, coords_are_cartesian)
         else:
-            _to_dspaw_as(structure[-1], filename, coords_are_cartesian)
+            _to_dspaw_as(structure[-1], absfilename, coords_are_cartesian)
     elif fmt == "hzw":
         if si:
-            _to_hzw(structure[si], filename)
+            _to_hzw(structure[si], absfilename)
         else:
-            _to_hzw(structure[-1], filename)
+            _to_hzw(structure[-1], absfilename)
 
     elif fmt in [
         "cif",
         "mcif",
         "poscar",
         "cssr",
         "xsf",
         "mcsqs",
         "yaml",
         "fleur-inpgen",
         "prismatic",
         "res",
     ]:
         if si:
-            structure[si].to(filename=filename, fmt=fmt)
+            structure[si].to(filename=absfilename, fmt=fmt)
         else:
-            structure[-1].to(filename=filename, fmt=fmt)
+            structure[-1].to(filename=absfilename, fmt=fmt)
 
     else:
         try:
             if si:
-                structure[si].to(filename=filename)
+                structure[si].to(filename=absfilename)
             else:
-                structure[-1].to(filename=filename)
+                structure[-1].to(filename=absfilename)
         except Exception as e:
             raise NotImplementedError(
-                f"除了 pdb, xyz, dump, json, as, hzw 六种格式外，其他格式一律移交 pymatgen 处理，然而\n--> pymatgen返回错误：{e}"
+                f"formats other that [pdb, xyz, dump, json, as, hzw] are handled by pymatgen, while it returns: {e}"
             )
 
-    print(f"--> 成功写入文件 {os.path.abspath(filename)}")
 
-
-def _write_atoms(fileobj, hdf5):
+def _write_atoms(fileobj, structure, idirect=False):
     fileobj.write("DS-PAW Structure\n")
     fileobj.write("  1.00\n")
-    lattice = np.asarray(hdf5["/AtomInfo/Lattice"]).reshape(-1, 1)  # 将列表lattice下的多个列表整合
-    fileobj.write(
-        "%10.6f %10.6f %10.6f\n" % (lattice[0][0], lattice[1][0], lattice[2][0])
-    )
-    fileobj.write(
-        "%10.6f %10.6f %10.6f\n" % (lattice[3][0], lattice[4][0], lattice[5][0])
-    )
-    fileobj.write(
-        "%10.6f %10.6f %10.6f\n" % (lattice[6][0], lattice[7][0], lattice[8][0])
-    )
+    lattice = structure.lattice.matrix.reshape(-1, 1)
+    fileobj.write("%g %g %g\n" % (lattice[0][0], lattice[1][0], lattice[2][0]))
+    fileobj.write("%g %g %g\n" % (lattice[3][0], lattice[4][0], lattice[5][0]))
+    fileobj.write("%g %g %g\n" % (lattice[6][0], lattice[7][0], lattice[8][0]))
 
-    elements = hdf5["/AtomInfo/Elements"]
+    elements = [s.species_string for s in structure.sites]
     elements_set = []
     elements_number = {}
     for e in elements:
         if e in elements_set:
             elements_number[e] = elements_number[e] + 1
         else:
             elements_set.append(e)
             elements_number[e] = 1
 
     for e in elements_set:
         fileobj.write("  " + e)
     fileobj.write("\n")
 
     for e in elements_set:
-        fileobj.write("%5d" % (elements_number[e]))
+        fileobj.write("%g " % (elements_number[e]))
     fileobj.write("\n")
-    if hdf5["/AtomInfo/CoordinateType"][0] == "Direct":
+    if idirect:
         fileobj.write("Direct\n")
+        for i, p in enumerate(structure.frac_coords):
+            fileobj.write("%g %g %g\n" % (p[0], p[1], p[2]))
     else:
         fileobj.write("Cartesian\n")
-    for i, p in enumerate(hdf5["/AtomInfo/Position"]):
-        fileobj.write("%10.6f" % p)
-        if (i + 1) % 3 == 0:
-            fileobj.write("\n")
-    fileobj.write("\n")
+        for i, p in enumerate(structure.cart_coords):
+            fileobj.write("%g %g %g\n" % (p[0], p[1], p[2]))
 
 
-def _write_VESTA_format(hdf5: dict, datakeys: list, filename):
-    if os.path.isfile(filename):
-        print("Warning: %s already exists and will be overwritten!" % filename)
-    if os.path.dirname(filename) != "":
-        os.makedirs(os.path.dirname(filename), exist_ok=True)
-    with open(filename, "w") as file:
-        _write_atoms(file, hdf5)
-        for key in datakeys:
-            d = np.asarray(hdf5[key]).reshape(-1, 1)  # 将列表hdf5[key]下的多个列表整合
-            file.write("%5d %5d %5d\n" % tuple(hdf5["/AtomInfo/Grid"]))
+def _write_specific_format(structure, grid, volumetricData, filename, format="cube"):
+    """Write to file with specific volumetric data format.
+    structure: Structure
+        Pymatgen Structure specifying the atomic configuration.
+    grid : 3dim numpy array
+        such as 180 x 180 x 180
+    volumetricData : numpy array
+        Array containing volumetric data as e.g. electronic density
+    filename : str
+        Name of the file to write to.
+    format : str
+        Format of the file to write to. Default to cube, can be vesta
+    """
+    absfile = os.path.abspath(filename)
+    if os.path.isfile(absfile):
+        print("Warning: %s already exists and will be overwritten!" % absfile)
+    os.makedirs(os.path.dirname(absfile), exist_ok=True)
+
+    # normalize volumetric data
+    vd = np.asarray(volumetricData)
+    vd /= np.sum(vd)
+
+    if format.lower() == "cube":
+        with open(absfile, "w") as fileobj:
+            # 1+2 注释
+            fileobj.write("Cube file written on " + time.strftime("%c"))
+            fileobj.write("\nOUTER LOOP: X, MIDDLE LOOP: Y, INNER LOOP: Z\n")
+            # 3 原子总数+原点坐标
+            origin = np.zeros(3)
+            fileobj.write(
+                f"{len(structure.sites)} {origin[0]} {origin[1]} {origin[2]}\n"
+            )
+            # 4+5+6 格点数+voxel矢量
+            for i in range(3):
+                # 单位为波尔
+                n = grid[i]
+                d = structure.lattice.matrix[i] / n / Bohr
+                fileobj.write(f"{n} {d[0]} {d[1]} {d[2]}\n")
+
+            # 7,8,... 原子序数+原子坐标
+            positions = structure.cart_coords / Bohr
+            species_string = [s.species_string for s in structure.sites]
+            # remove + and - from species_string
+            species_string = [
+                s.replace("+", "").replace("-", "") for s in species_string
+            ]
+            symbols = "".join(species_string)  # SiH
+            numbers = _symbols2numbers(symbols)
+            for Z, (x, y, z) in zip(numbers, positions):
+                fileobj.write(f"{Z} {0.0} {x} {y} {z}\n")
+
+            # 由于cube格式的特殊规定，数组需要按格点数反向reshape后再转置才对
+            # 后面那个浮点数用于单位转换，尚不清楚物理意义
+            reshaped_vd = (
+                vd.reshape(grid[::-1]).T * 0.0035626635627220541406318925434652
+            )
+
+            if reshaped_vd.dtype == complex:
+                reshaped_vd = np.abs(reshaped_vd)
+            reshaped_vd.tofile(fileobj, sep="\n", format="%e")
+
+    elif format.lower() == "vesta" or format.lower() == "vasp":
+        with open(absfile, "w") as file:
+            _write_atoms(file, structure, idirect=True)  # 默认直角坐标
+            file.write(f"{grid[0]} {grid[1]} {grid[2]}\n")
             i = 0
-            while i < len(d):
-                for j in range(10):
-                    file.write("%10.5f " % d[i])
+            while i < len(vd):
+                for j in range(10):  # 比一行只写一个似乎能让文件更小
+                    file.write(f"{vd[i]} ")
                     i += 1
-                    if i >= len(d):
+                    if i >= len(vd):
                         break
-                file.write("\n")
-
             file.write("\n")
 
-
-def _write_atoms_json(fileobj, atom_info):
-    fileobj.write("DS-PAW Structure\n")
-    fileobj.write("  1.00\n")
-    lattice = atom_info["Lattice"]
-
-    fileobj.write("%10.6f %10.6f %10.6f\n" % (lattice[0], lattice[1], lattice[2]))
-    fileobj.write("%10.6f %10.6f %10.6f\n" % (lattice[3], lattice[4], lattice[5]))
-    fileobj.write("%10.6f %10.6f %10.6f\n" % (lattice[6], lattice[7], lattice[8]))
-
-    elements = [atom["Element"] for atom in atom_info["Atoms"]]
-    elements_set = []
-    elements_number = {}
-    for e in elements:
-        if e in elements_set:
-            elements_number[e] = elements_number[e] + 1
-        else:
-            elements_set.append(e)
-            elements_number[e] = 1
-
-    for e in elements_set:
-        fileobj.write("  " + e)
-    fileobj.write("\n")
-
-    for e in elements_set:
-        fileobj.write("%5d" % (elements_number[e]))
-    fileobj.write("\n")
-    if atom_info["CoordinateType"] == "Direct":
-        fileobj.write("Direct\n")
     else:
-        fileobj.write("Cartesian\n")
-    for atom in atom_info["Atoms"]:
-        fileobj.write("%10.6f %10.6f %10.6f\n" % tuple(atom["Position"]))
-    fileobj.write("\n")
-
-
-def _write_VESTA_format_json(atom_info: dict, data: list, filename):
-    if os.path.isfile(filename):
-        print("Warning: %s already exists and will be overwritten!" % filename)
-    if os.path.dirname(filename) != "":
-        os.makedirs(os.path.dirname(filename), exist_ok=True)
-    with open(filename, "w") as file:
-        _write_atoms_json(file, atom_info)
-        for d in data:
-            file.write("%5d %5d %5d\n" % tuple(atom_info["Grid"]))
-            i = 0
-            while i < len(d):
-                for j in range(10):
-                    file.write("%10.5f " % d[i])
-                    i += 1
-                    if i >= len(d):
-                        break
-                file.write("\n")
+        raise NotImplementedError(' only "cube" and "vesta" are supported.')
 
-            file.write("\n")
+    print(f"==> {absfile}")
 
 
 def _to_dspaw_as(structure, filename: str, coords_are_cartesian=True):
     """write dspaw structure file of .as type"""
-    if os.path.isfile(filename):
-        print("Warning: %s already exists and will be overwritten!" % filename)
-    if os.path.dirname(filename) != "":
-        os.makedirs(os.path.dirname(filename), exist_ok=True)
-    with open(filename, "w", encoding="utf-8") as file:
+    absfile = os.path.abspath(filename)
+    if os.path.isfile(absfile):
+        warnings.warn("%s already exists and will be overwritten!" % absfile)
+    os.makedirs(os.path.dirname(absfile), exist_ok=True)
+    with open(absfile, "w", encoding="utf-8") as file:
         file.write("Total number of atoms\n")
         file.write("%d\n" % len(structure))
 
         # ^ write lattice info
         if "LatticeFixs" in structure.sites[0].properties:
             lfinfo = structure.sites[0].properties["LatticeFixs"]
             if len(lfinfo) == 3:
@@ -652,15 +597,14 @@
                     file.write(f"Direct {keys_str}\n")
             i += 1
 
             coords = site.coords if coords_are_cartesian else site.frac_coords
             raw = []
             for sortted_key in keys:  # site.properties is a dictionary
                 raw_values = site.properties[sortted_key]
-                # print(f'{raw_values=}')
                 if isinstance(raw_values, list):  # single True or False
                     values = raw_values
                 else:
                     values = [raw_values]
                 for v in values:
                     if v == "True":
                         value_str = "T"
@@ -671,22 +615,25 @@
                     raw.append(value_str)
 
             final_strs = " ".join(raw)  # sth like '0.0 T
             file.write(
                 "%s %.8f %.8f %.8f %s\n"
                 % (site.species_string, coords[0], coords[1], coords[2], final_strs)
             )
+    print(f"==> {absfile}")
 
 
 def _to_hzw(structure, filename: str):
-    if os.path.isfile(filename):
-        print("Warning: %s already exists and will be overwritten!" % filename)
-    if os.path.dirname(filename) != "":
-        os.makedirs(os.path.dirname(filename), exist_ok=True)
-    with open(filename, "w", encoding="utf-8") as file:
+    """write hzw structure file of .hzw type"""
+    absfile = os.path.abspath(filename)
+
+    if os.path.isfile(absfile):
+        warnings.warn("%s already exists and will be overwritten!" % absfile)
+    os.makedirs(os.path.dirname(absfile), exist_ok=True)
+    with open(absfile, "w", encoding="utf-8") as file:
         file.write("% The number of probes \n")
         file.write("0\n")
         file.write("% Uni-cell vector\n")
 
         for v in structure.lattice.matrix:
             file.write("%.6f %.6f %.6f\n" % (v[0], v[1], v[2]))
 
@@ -695,41 +642,45 @@
         file.write("% Atom site\n")
 
         for site in structure:
             file.write(
                 "%s %.6f %.6f %.6f\n"
                 % (site.species_string, site.coords[0], site.coords[1], site.coords[2])
             )
+    print(f"==> {absfile}")
 
 
 def _to_dspaw_json(structure, filename: str, coords_are_cartesian=True):
+    """write dspaw structure file of .json type"""
+    absfile = os.path.abspath(filename)
     lattice = structure.lattice.matrix.flatten().tolist()
     atoms = []
     for site in structure:
         coords = site.coords if coords_are_cartesian else site.frac_coords
         atoms.append({"Element": site.species_string, "Position": coords.tolist()})
 
     coordinate_type = "Cartesian" if coords_are_cartesian else "Direct"
     d = {"Lattice": lattice, "CoordinateType": coordinate_type, "Atoms": atoms}
-    if os.path.isfile(filename):
-        print("Warning: %s already exists and will be overwritten!" % filename)
-    if os.path.dirname(filename) != "":
-        os.makedirs(os.path.dirname(filename), exist_ok=True)
-    with open(filename, "w", encoding="utf-8") as file:
+    if os.path.isfile(absfile):
+        warnings.warn("%s already exists and will be overwritten!" % absfile)
+    os.makedirs(os.path.dirname(absfile), exist_ok=True)
+    with open(absfile, "w", encoding="utf-8") as file:
         json.dump(d, file, indent=4)
+    print(f"==> {absfile}")
 
 
 def _to_pdb(structures, filename: str):
+    """write pdb structure file of .pdb type"""
+    absfile = os.path.abspath(filename)
     if not isinstance(structures, list):
         structures = [structures]
-    if os.path.isfile(filename):
-        print("Warning: %s already exists and will be overwritten!" % filename)
-    if os.path.dirname(filename) != "":
-        os.makedirs(os.path.dirname(filename), exist_ok=True)
-    with open(filename, "w", encoding="utf-8") as file:
+    if os.path.isfile(absfile):
+        warnings.warn("%s already exists and will be overwritten!" % absfile)
+    os.makedirs(os.path.dirname(absfile), exist_ok=True)
+    with open(absfile, "w", encoding="utf-8") as file:
         for i, s in enumerate(structures):
             file.write("MODEL         %d\n" % (i + 1))
             file.write("REMARK   Converted from Structures\n")
             file.write("REMARK   Converted using dspawpy\n")
             lengths = s.lattice.lengths
             angles = s.lattice.angles
             file.write(
@@ -753,7 +704,9 @@
                         1.0,
                         0.0,
                         site.species_string,
                     )
                 )
             file.write("TER\n")
             file.write("ENDMDL\n")
+
+    print(f"==> {absfile}")
```

## Comparing `dspawpy-1.0.2.dist-info/METADATA` & `dspawpy-1.0.3.dist-info/METADATA`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dspawpy
-Version: 1.0.2
+Version: 1.0.3
 Summary: Tools for dspaw
 Home-page: http://www.hzwtech.com/
 Author: Hzwtech
 Author-email: ZhengZhilin@hzwtech.com
 License: MIT
 Requires-Python: >=3
 Description-Content-Type: text/markdown
@@ -32,14 +32,28 @@
 
 再重新用pip安装。
 
 详见 https://stackoverflow.com/questions/75542688/conda-installed-pip-failed-to-find-packages/75542962#75542962
 
 ## 版本更新简述
 
+### 1.0.3
+
+- BUG修复： 解决浮点数过大时volumetricData相关文件浮点数粘在一起的问题
+- BUG修复： plot_barrier()读取neb.h5/json绘制能垒图时，反应坐标依旧累加
+- BUG修复： plot_bandunfolding()能带反折叠费米能级被默认置零
+- 功能强化： 新增cube格式用于保存volumetricData
+- 功能强化： 全局支持相对路径与绝对路径混写
+- 功能强化： datafile参数以及io.read以及diffusion.nebtools模块中的相应参数，可以是文件位置，也可以是文件所在的文件夹路径
+- 功能强化： build_Structures_from_datafile()增加task参数，用于配合datafile为文件夹路径的情况
+- 重要变更： 移除中文提示语句，精简提示信息
+- 重要变更： volumetricData默认使用cube格式写入
+- 重要变更： 移除thermo_correction()，一个单纯的外包装函数
+- 细节修改： 保存图片或文件时，统一使用 ==> 标记文件绝对路径
+
 ### 1.0.2
 
 - BUG修复：  当存在Fix或Mag信息时，structure.as 坐标类型可能解析错误的问题
 - 功能强化： 预览NEB链条函数改名 write_xyz(json)_chain，增加dst参数制定保存路径
 - 功能强化： potential 中数据集不预作限制
 - 功能强化： get_lagtime_msd, get_lagtime_rmsd 自动从数据文件中读取timestep（以前必须手动指定）
 - 细节修改： 优化部分提示语句
```

## Comparing `dspawpy-1.0.2.dist-info/RECORD` & `dspawpy-1.0.3.dist-info/RECORD`

 * *Files 23% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-dspawpy/__init__.py,sha256=EI-j10hLYbIvV2PUEKJKO7nzOR5uw3i_irbSGbHJOVw,48
-dspawpy/plot.py,sha256=djlwo_8uj5G6buvY0iiZqjhnC8a8DqpdgsLq3GwuztE,32126
+dspawpy/__init__.py,sha256=4njkx-4qaR982ghpK_whXu_0JWYXRvTkXbRrpbLg7ec,48
+dspawpy/plot.py,sha256=CprusttTy2H6zK47khNiJzFUNTXyKEa1WZAJZ6JRS2c,28329
 dspawpy/analysis/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dspawpy/analysis/aimdtools.py,sha256=cseRcOApPIPZ1BSDEfLAkSwkVbf8Fm4eD11w0cUCh7c,24227
+dspawpy/analysis/aimdtools.py,sha256=yOP3pzIXp63lENoxddCMq-xND2RfOLxvacs5C6TVXX0,26263
 dspawpy/analysis/vacf.py,sha256=Jj6t7D3FoxBKrjqkV4MVATcucKVW0mRG8aBAKdR6MQk,20177
 dspawpy/diffusion/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dspawpy/diffusion/neb.py,sha256=axFwZTg5HV_RIbZ1welrZAH_ayAH-4tswzjgkJZXugU,3986
-dspawpy/diffusion/nebtools.py,sha256=i__YpW33JQlyRZsxNPgK8uDoF-r6b7YlS1ESwpyzaCY,56885
+dspawpy/diffusion/neb.py,sha256=R5ZmGcYY9_5oXHVrGiLjbIjT65_0KNtDHzJi8xZ2uJ8,3887
+dspawpy/diffusion/nebtools.py,sha256=T8eBdUjTOyl446aT1fjv-2o77P3du8dKOmre76keSlc,58897
 dspawpy/diffusion/pathfinder.py,sha256=HhCVoh42Q2qIksBAruZ1atULfR5D55uzZvbaCtUxSig,11045
 dspawpy/io/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-dspawpy/io/read.py,sha256=tgcUjawulYsaR0x9aAsdvtNKlovUq7jLARYYQQ6v1DE,62556
-dspawpy/io/structure.py,sha256=RlNQ4Up7YAguu7hUhKUN4mm7xwojRW0wF9MwCIrwWg0,10546
-dspawpy/io/utils.py,sha256=uEH9JQQWp8odP0FGKqFeJ5veSzPq3RzvOskHtOitkW8,27763
-dspawpy/io/write.py,sha256=3_KA9gK7bIKa6iz8dlYDDjWqByCKzcCK0tz2Y5Cl-nY,29654
-dspawpy-1.0.2.dist-info/METADATA,sha256=y3MdwM2h2Q6aUNzunb2uHqO1b2jTMsmVzYd8FOxL-Ys,6022
-dspawpy-1.0.2.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-dspawpy-1.0.2.dist-info/top_level.txt,sha256=esEMNTnd880qHE4wkZVKM3gzqZMuOobS886owAyaUmA,8
-dspawpy-1.0.2.dist-info/RECORD,,
+dspawpy/io/read.py,sha256=iGhCOI-DUc62nHm9If9headEV23tzDzaoAAvHFSFusw,62357
+dspawpy/io/structure.py,sha256=pmhRoNqW1ix60LJromdLnA8EYNc05Oarw5QxPzktTQs,11015
+dspawpy/io/utils.py,sha256=uEWIBNslXGpQVhHzXnsPpEV7H8tQrxlLllNEW-ljTLE,32031
+dspawpy/io/write.py,sha256=esjqtilnhkAEc61qOuABB2GCIxyNMUmYgB6mIw0631s,27999
+dspawpy-1.0.3.dist-info/METADATA,sha256=ehHSBPqxXXaMLw_2sFHfEXNtGZBUqs1pex8I7whUrzc,7008
+dspawpy-1.0.3.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+dspawpy-1.0.3.dist-info/top_level.txt,sha256=esEMNTnd880qHE4wkZVKM3gzqZMuOobS886owAyaUmA,8
+dspawpy-1.0.3.dist-info/RECORD,,
```

